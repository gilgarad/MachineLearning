{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoderTest.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gilgarad/mldl4automation/blob/master/code_tests/AutoEncoderTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jsD6YZ-U0m17",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 참조: https://keraskorea.github.io/posts/2018-10-23-keras_autoencoder/\n",
        "# This is mostly copied from someone else, the purpose is to understand and test (could be changed a bit)"
      ]
    },
    {
      "metadata": {
        "id": "mgxHU6N40q_M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "metadata": {
        "id": "GQf_nsh3u6zt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a4bb116-2f6b-447f-d6cc-1b5ee3b5eb2f"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.layers import LSTM, RepeatVector\n",
        "from keras.models import Model\n",
        "\n",
        "from keras import regularizers\n",
        "from keras.callbacks import TensorBoard\n",
        "import keras.backend.tensorflow_backend as K\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib 사용\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_J2r8p5l0tgM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Download Data and set default variables"
      ]
    },
    {
      "metadata": {
        "id": "VMN1RaTF0xqQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "aa190f5f-f005-4f87-a5ac-502a082079d1"
      },
      "cell_type": "code",
      "source": [
        "LOG_DIR = 'drive/data/tb_logs' # Save in google drive path\n",
        "# LOG_DIR = '/content/gdrive/data/tb_logs' # Save in google drive path\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "import os\n",
        "if not os.path.exists(LOG_DIR):\n",
        "    os.makedirs(LOG_DIR)\n",
        "\n",
        "get_ipython().system_raw(\n",
        "  'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "  .format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "  \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-09 00:46:30--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.204.136.9, 34.206.253.53, 52.86.186.182, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.204.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14977695 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  14.28M  36.7MB/s    in 0.4s    \n",
            "\n",
            "2019-04-09 00:46:31 (36.7 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [14977695/14977695]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "http://0927783a.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nR0gbCNLvLQy",
        "colab_type": "code",
        "outputId": "a75c5e7a-92d3-4053-d2bb-629be8493668",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print('Original x_train.shape:', x_train.shape)\n",
        "print('Original x_train.shape:', x_test.shape)\n",
        "      \n",
        "# Make all data to be between 0 to 1 \n",
        "x_train_flat = x_train / 255\n",
        "x_train_flat = x_train_flat.reshape(x_train_flat.shape[0], np.prod(x_train_flat.shape[1:]))\n",
        "x_test_flat = x_test / 255\n",
        "x_test_flat = x_test_flat.reshape(x_test_flat.shape[0], np.prod(x_test_flat.shape[1:]))\n",
        "\n",
        "print('Changed Shape (Flattened shape and normalize data as between 0 to 1)')\n",
        "print('Flattened x_train_flat.shape:', x_train_flat.shape)\n",
        "print('Flattened x_test_flat.shape:', x_test_flat.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Original x_train.shape: (60000, 28, 28)\n",
            "Original x_train.shape: (10000, 28, 28)\n",
            "Changed Shape (Flattened shape and normalize data as between 0 to 1)\n",
            "Flattened x_train_flat.shape: (60000, 784)\n",
            "Flattened x_test_flat.shape: (10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YeeN_9Jq3h21",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tester Class for train and test"
      ]
    },
    {
      "metadata": {
        "id": "JmPo6VPMx10O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AutoEncoderTester:\n",
        "    def __init__(self, model):\n",
        "        \n",
        "        self.model = model\n",
        "       \n",
        "    def train(self, x_train, y_train, x_test, y_test, epochs=50, batch_size=256, \n",
        "              verbose=1):\n",
        "        \n",
        "        self.model.autoencoder.fit(x_train, y_train, \n",
        "                                   validation_data=(x_test, y_test), \n",
        "                                   epochs=epochs, batch_size=batch_size, \n",
        "                                   shuffle=True, \n",
        "                                   verbose=verbose,\n",
        "                                  callbacks=[\n",
        "                                      TensorBoard(log_dir=LOG_DIR, \n",
        "                                                  histogram_freq=0,\n",
        "                                                  write_graph=True,\n",
        "                                                  write_grads=True,\n",
        "#                                                   batch_size=batch_size,\n",
        "#                                                   write_images=True\n",
        "                                                 )\n",
        "                                  ])\n",
        "        \n",
        "    def test(self, x_test):\n",
        "        encoded_imgs = self.model.encoder.predict(x_test)\n",
        "        decoded_imgs = self.model.decoder.predict(encoded_imgs)\n",
        "        \n",
        "        n = 10  # 몇 개의 숫자를 나타낼 것인지\n",
        "        plt.figure(figsize=(20, 4))\n",
        "        for i in range(n):\n",
        "            # 원본 데이터\n",
        "            ax = plt.subplot(2, n, i + 1)\n",
        "            plt.imshow(x_test[i].reshape(28, 28))\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "\n",
        "            # 재구성된 데이터\n",
        "            ax = plt.subplot(2, n, i + 1 + n)\n",
        "            plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "            plt.gray()\n",
        "            ax.get_xaxis().set_visible(False)\n",
        "            ax.get_yaxis().set_visible(False)\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3LcN75ORoIyi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Models"
      ]
    },
    {
      "metadata": {
        "id": "cW4qtlZd27Xg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BaseModel:\n",
        "    def __init__(self):\n",
        "        encode_dim = 32\n",
        "\n",
        "        inputs = Input(shape=(784, ))\n",
        "        encoded = Dense(encode_dim, activation='relu')(inputs)\n",
        "        decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "        autoencoder = Model(inputs=inputs, outputs=decoded)\n",
        "\n",
        "\n",
        "        encoder = Model(inputs=inputs, outputs=encoded)\n",
        "\n",
        "        encoded_inputs = Input(shape=(encode_dim, ))\n",
        "        decoder_layer = autoencoder.layers[-1]\n",
        "        decoder = Model(inputs=encoded_inputs, outputs=decoder_layer(encoded_inputs))\n",
        "\n",
        "\n",
        "        autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.autoencoder = autoencoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "js7vzr8tyFWG",
        "colab_type": "code",
        "outputId": "2b211240-a518-4fa1-bd6c-b20ec2c4d0f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2573
        }
      },
      "cell_type": "code",
      "source": [
        "base_model = AutoEncoderTester(model=BaseModel())\n",
        "base_model.train(x_train=x_train_flat, y_train=x_train_flat, x_test=x_test_flat, y_test=x_test_flat,\n",
        "                epochs=200, batch_size=1024, verbose=1)\n",
        "base_model.test(x_test=x_test_flat)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1144 - val_loss: 0.1126\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1142 - val_loss: 0.1124\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1139 - val_loss: 0.1121\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1137 - val_loss: 0.1119\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1134 - val_loss: 0.1116\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.1132 - val_loss: 0.1114\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.1130 - val_loss: 0.1112\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1127 - val_loss: 0.1109\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1125 - val_loss: 0.1107\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1123 - val_loss: 0.1105\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1121 - val_loss: 0.1103\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1119 - val_loss: 0.1101\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1117 - val_loss: 0.1099\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1115 - val_loss: 0.1097\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1113 - val_loss: 0.1095\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1111 - val_loss: 0.1093\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1109 - val_loss: 0.1091\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1107 - val_loss: 0.1089\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1105 - val_loss: 0.1087\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1103 - val_loss: 0.1085\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 4s 64us/step - loss: 0.1101 - val_loss: 0.1083\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1099 - val_loss: 0.1082\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1098 - val_loss: 0.1080\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1096 - val_loss: 0.1078\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1094 - val_loss: 0.1076\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1093 - val_loss: 0.1075\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1091 - val_loss: 0.1073\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1089 - val_loss: 0.1071\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1088 - val_loss: 0.1070\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1086 - val_loss: 0.1068\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1085 - val_loss: 0.1067\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1083 - val_loss: 0.1065\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1082 - val_loss: 0.1064\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1080 - val_loss: 0.1063\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1079 - val_loss: 0.1061\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1077 - val_loss: 0.1060\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.1076 - val_loss: 0.1058\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1075 - val_loss: 0.1057\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1073 - val_loss: 0.1056\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1072 - val_loss: 0.1054\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1071 - val_loss: 0.1053\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1069 - val_loss: 0.1052\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1068 - val_loss: 0.1051\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1067 - val_loss: 0.1049\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1066 - val_loss: 0.1048\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1065 - val_loss: 0.1047\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1063 - val_loss: 0.1046\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1062 - val_loss: 0.1045\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1061 - val_loss: 0.1044\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1060 - val_loss: 0.1043\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1059 - val_loss: 0.1042\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1058 - val_loss: 0.1040\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1057 - val_loss: 0.1039\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1056 - val_loss: 0.1038\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1055 - val_loss: 0.1037\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1054 - val_loss: 0.1036\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1053 - val_loss: 0.1035\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.1052 - val_loss: 0.1035\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.1051 - val_loss: 0.1034\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.1050 - val_loss: 0.1033\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1049 - val_loss: 0.1032\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1048 - val_loss: 0.1031\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1047 - val_loss: 0.1030\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1047 - val_loss: 0.1029\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1046 - val_loss: 0.1028\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1045 - val_loss: 0.1028\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1044 - val_loss: 0.1027\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1043 - val_loss: 0.1026\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.1042 - val_loss: 0.1025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "-8NGZ-tT0N1n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RegularizedModel:\n",
        "    def __init__(self):\n",
        "        encoding_dim = 32\n",
        "\n",
        "        inputs = Input(shape=(784,))\n",
        "        # L1 activity regularizer를 Dense layer에 추가 \n",
        "        encoded = Dense(encoding_dim, activation='relu',\n",
        "                        activity_regularizer=regularizers.l1(10e-5))(inputs)\n",
        "        decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "        autoencoder = Model(inputs, decoded)\n",
        "        \n",
        "        encoder = Model(inputs=inputs, outputs=encoded)\n",
        "\n",
        "        encoded_inputs = Input(shape=(encode_dim, ))\n",
        "        decoder_layer = autoencoder.layers[-1]\n",
        "        decoder = Model(inputs=encoded_inputs, outputs=decoder_layer(encoded_inputs))\n",
        "\n",
        "\n",
        "        autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.autoencoder = autoencoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YAhRNWF01RbS",
        "colab_type": "code",
        "outputId": "e85eca18-9cb2-452b-8b4f-3fa97e5b24af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7061
        }
      },
      "cell_type": "code",
      "source": [
        "regularized_model = AutoEncoderTester(RegularizedModel())\n",
        "regularized_model.train(x_train=x_train_flat, y_train=x_train_flat, x_test=x_test_flat, y_test=x_test_flat,\n",
        "                epochs=200, batch_size=1024, verbose=1)\n",
        "regularized_model.test(x_test=x_test_flat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.7095 - val_loss: 0.6826\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.6765 - val_loss: 0.6704\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.6648 - val_loss: 0.6591\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.6538 - val_loss: 0.6483\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.6431 - val_loss: 0.6378\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.6328 - val_loss: 0.6277\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.6229 - val_loss: 0.6180\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.6134 - val_loss: 0.6087\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.6042 - val_loss: 0.5996\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.5953 - val_loss: 0.5909\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.5868 - val_loss: 0.5826\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.5785 - val_loss: 0.5745\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.5706 - val_loss: 0.5667\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.5629 - val_loss: 0.5592\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.5556 - val_loss: 0.5519\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.5484 - val_loss: 0.5449\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.5415 - val_loss: 0.5382\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.5349 - val_loss: 0.5317\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.5285 - val_loss: 0.5254\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.5223 - val_loss: 0.5193\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.5163 - val_loss: 0.5134\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.5105 - val_loss: 0.5077\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.5050 - val_loss: 0.5023\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.4996 - val_loss: 0.4970\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.4944 - val_loss: 0.4918\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.4893 - val_loss: 0.4869\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.4844 - val_loss: 0.4821\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.4797 - val_loss: 0.4774\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.4751 - val_loss: 0.4729\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.4707 - val_loss: 0.4686\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.4664 - val_loss: 0.4644\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.4623 - val_loss: 0.4603\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.4583 - val_loss: 0.4563\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.4544 - val_loss: 0.4525\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.4506 - val_loss: 0.4488\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.4469 - val_loss: 0.4452\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4434 - val_loss: 0.4417\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.4399 - val_loss: 0.4383\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.4366 - val_loss: 0.4350\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4333 - val_loss: 0.4318\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4302 - val_loss: 0.4287\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.4271 - val_loss: 0.4257\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4241 - val_loss: 0.4228\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.4213 - val_loss: 0.4199\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4184 - val_loss: 0.4172\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.4157 - val_loss: 0.4145\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.4131 - val_loss: 0.4119\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4105 - val_loss: 0.4093\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.4080 - val_loss: 0.4068\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4055 - val_loss: 0.4044\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4032 - val_loss: 0.4021\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.4008 - val_loss: 0.3998\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3986 - val_loss: 0.3976\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3964 - val_loss: 0.3954\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3943 - val_loss: 0.3933\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3922 - val_loss: 0.3913\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3902 - val_loss: 0.3893\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3882 - val_loss: 0.3873\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3862 - val_loss: 0.3854\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3844 - val_loss: 0.3836\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3825 - val_loss: 0.3818\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3807 - val_loss: 0.3800\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3790 - val_loss: 0.3783\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.3773 - val_loss: 0.3766\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.3756 - val_loss: 0.3750\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.3740 - val_loss: 0.3734\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3724 - val_loss: 0.3718\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3709 - val_loss: 0.3703\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3694 - val_loss: 0.3688\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3679 - val_loss: 0.3673\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3665 - val_loss: 0.3659\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3650 - val_loss: 0.3645\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3637 - val_loss: 0.3631\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3623 - val_loss: 0.3618\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3610 - val_loss: 0.3605\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3597 - val_loss: 0.3592\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3585 - val_loss: 0.3580\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3572 - val_loss: 0.3568\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3560 - val_loss: 0.3556\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3548 - val_loss: 0.3544\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3537 - val_loss: 0.3533\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3525 - val_loss: 0.3521\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3514 - val_loss: 0.3510\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3504 - val_loss: 0.3500\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3493 - val_loss: 0.3489\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3482 - val_loss: 0.3479\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3472 - val_loss: 0.3469\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3462 - val_loss: 0.3459\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3452 - val_loss: 0.3449\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3443 - val_loss: 0.3440\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3433 - val_loss: 0.3430\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3424 - val_loss: 0.3421\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3415 - val_loss: 0.3412\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3406 - val_loss: 0.3403\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3398 - val_loss: 0.3395\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3389 - val_loss: 0.3386\n",
            "Epoch 97/200\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.3381 - val_loss: 0.3378\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.3372 - val_loss: 0.3370\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3364 - val_loss: 0.3362\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3356 - val_loss: 0.3354\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3349 - val_loss: 0.3346\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3341 - val_loss: 0.3339\n",
            "Epoch 103/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3334 - val_loss: 0.3331\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3326 - val_loss: 0.3324\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3319 - val_loss: 0.3317\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3312 - val_loss: 0.3310\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3305 - val_loss: 0.3303\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3298 - val_loss: 0.3296\n",
            "Epoch 109/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3291 - val_loss: 0.3289\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3285 - val_loss: 0.3283\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3278 - val_loss: 0.3276\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3272 - val_loss: 0.3270\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3265 - val_loss: 0.3264\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3259 - val_loss: 0.3258\n",
            "Epoch 115/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3253 - val_loss: 0.3252\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3247 - val_loss: 0.3246\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3241 - val_loss: 0.3240\n",
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3236 - val_loss: 0.3234\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3230 - val_loss: 0.3228\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3224 - val_loss: 0.3223\n",
            "Epoch 121/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3219 - val_loss: 0.3217\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3213 - val_loss: 0.3212\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3208 - val_loss: 0.3207\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3203 - val_loss: 0.3202\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3198 - val_loss: 0.3196\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3192 - val_loss: 0.3191\n",
            "Epoch 127/200\n",
            "60000/60000 [==============================] - 4s 69us/step - loss: 0.3187 - val_loss: 0.3186\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3183 - val_loss: 0.3181\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3178 - val_loss: 0.3177\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3173 - val_loss: 0.3172\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3168 - val_loss: 0.3167\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3164 - val_loss: 0.3163\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3159 - val_loss: 0.3158\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3154 - val_loss: 0.3154\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3150 - val_loss: 0.3149\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3146 - val_loss: 0.3145\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3141 - val_loss: 0.3141\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3137 - val_loss: 0.3136\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3133 - val_loss: 0.3132\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3129 - val_loss: 0.3128\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.3125 - val_loss: 0.3124\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.3121 - val_loss: 0.3120\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3117 - val_loss: 0.3116\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3113 - val_loss: 0.3112\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3109 - val_loss: 0.3108\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3105 - val_loss: 0.3105\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.3102 - val_loss: 0.3101\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3098 - val_loss: 0.3097\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3094 - val_loss: 0.3094\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3091 - val_loss: 0.3090\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3087 - val_loss: 0.3087\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3084 - val_loss: 0.3083\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3080 - val_loss: 0.3080\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3077 - val_loss: 0.3076\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3073 - val_loss: 0.3073\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3070 - val_loss: 0.3070\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3067 - val_loss: 0.3067\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3064 - val_loss: 0.3063\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3061 - val_loss: 0.3060\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3057 - val_loss: 0.3057\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3054 - val_loss: 0.3054\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3051 - val_loss: 0.3051\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3048 - val_loss: 0.3048\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3045 - val_loss: 0.3045\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3042 - val_loss: 0.3042\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3039 - val_loss: 0.3039\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.3037 - val_loss: 0.3036\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3034 - val_loss: 0.3033\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3031 - val_loss: 0.3031\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3028 - val_loss: 0.3028\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3025 - val_loss: 0.3025\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3023 - val_loss: 0.3022\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.3020 - val_loss: 0.3020\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.3017 - val_loss: 0.3017\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3015 - val_loss: 0.3015\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.3012 - val_loss: 0.3012\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3010 - val_loss: 0.3009\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3007 - val_loss: 0.3007\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.3005 - val_loss: 0.3004\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.3002 - val_loss: 0.3002\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 4s 65us/step - loss: 0.3000 - val_loss: 0.3000\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.2997 - val_loss: 0.2997\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.2995 - val_loss: 0.2995\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.2993 - val_loss: 0.2993\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.2990 - val_loss: 0.2990\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.2988 - val_loss: 0.2988\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.2986 - val_loss: 0.2986\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.2984 - val_loss: 0.2983\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.2981 - val_loss: 0.2981\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.2979 - val_loss: 0.2979\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.2977 - val_loss: 0.2977\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.2975 - val_loss: 0.2975\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.2973 - val_loss: 0.2973\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.2971 - val_loss: 0.2971\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.2969 - val_loss: 0.2968\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.2967 - val_loss: 0.2966\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.2965 - val_loss: 0.2964\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.2962 - val_loss: 0.2962\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.2961 - val_loss: 0.2960\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.2959 - val_loss: 0.2958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Mmas2xDL1Uci",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DeepModel:\n",
        "    def __init__(self):\n",
        "        encode_dim = 32\n",
        "\n",
        "        inputs = Input(shape=(784,))\n",
        "        encoded = Dense(128, activation='relu')(inputs)\n",
        "        encoded = Dense(64, activation='relu')(encoded)\n",
        "        encoded = Dense(32, activation='relu')(encoded)\n",
        "\n",
        "        decoded = Dense(64, activation='relu')(encoded)\n",
        "        decoded = Dense(128, activation='relu')(decoded)\n",
        "        decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "        autoencoder = Model(inputs, decoded)\n",
        "        \n",
        "        encoder = Model(inputs=inputs, outputs=encoded)\n",
        "\n",
        "        encoded_inputs = Input(shape=(encode_dim, ))\n",
        "#         decoder_layer = autoencoder.layers[-3:]\n",
        "        decoder_layer = encoded_inputs\n",
        "        for layer in autoencoder.layers[-3:]:\n",
        "            decoder_layer = layer(decoder_layer)\n",
        "        decoder = Model(inputs=encoded_inputs, outputs=decoder_layer)\n",
        "\n",
        "\n",
        "        autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.autoencoder = autoencoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zG70k1EL7eNV",
        "colab_type": "code",
        "outputId": "c9cb16aa-86c6-4d98-ecbc-fd0aeea9572e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7061
        }
      },
      "cell_type": "code",
      "source": [
        "deep_model = AutoEncoderTester(DeepModel())\n",
        "deep_model.train(x_train=x_train_flat, y_train=x_train_flat, x_test=x_test_flat, y_test=x_test_flat,\n",
        "                epochs=200, batch_size=1024, verbose=1)\n",
        "deep_model.test(x_test=x_test_flat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 2s 26us/step - loss: 0.5071 - val_loss: 0.2734\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2699 - val_loss: 0.2668\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2659 - val_loss: 0.2649\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2637 - val_loss: 0.2622\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2610 - val_loss: 0.2597\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2581 - val_loss: 0.2570\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2545 - val_loss: 0.2518\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2501 - val_loss: 0.2472\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2459 - val_loss: 0.2429\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2417 - val_loss: 0.2390\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2379 - val_loss: 0.2351\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2320 - val_loss: 0.2275\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2246 - val_loss: 0.2201\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2185 - val_loss: 0.2152\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2151 - val_loss: 0.2131\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2128 - val_loss: 0.2106\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2102 - val_loss: 0.2074\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2078 - val_loss: 0.2061\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.2044 - val_loss: 0.2018\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.2013 - val_loss: 0.1989\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1981 - val_loss: 0.1957\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1958 - val_loss: 0.1931\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1933 - val_loss: 0.1919\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1917 - val_loss: 0.1897\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1898 - val_loss: 0.1879\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1884 - val_loss: 0.1862\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1866 - val_loss: 0.1851\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1847 - val_loss: 0.1820\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1829 - val_loss: 0.1806\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1814 - val_loss: 0.1789\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1795 - val_loss: 0.1771\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1780 - val_loss: 0.1753\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1763 - val_loss: 0.1743\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1748 - val_loss: 0.1761\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1735 - val_loss: 0.1703\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1718 - val_loss: 0.1697\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1709 - val_loss: 0.1687\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1696 - val_loss: 0.1672\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1684 - val_loss: 0.1662\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1671 - val_loss: 0.1654\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1659 - val_loss: 0.1646\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1655 - val_loss: 0.1623\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1639 - val_loss: 0.1622\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1628 - val_loss: 0.1612\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1620 - val_loss: 0.1601\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1604 - val_loss: 0.1594\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1599 - val_loss: 0.1574\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1586 - val_loss: 0.1566\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1579 - val_loss: 0.1557\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1564 - val_loss: 0.1555\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1561 - val_loss: 0.1535\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1551 - val_loss: 0.1527\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1543 - val_loss: 0.1521\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1529 - val_loss: 0.1510\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1529 - val_loss: 0.1504\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1522 - val_loss: 0.1510\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1515 - val_loss: 0.1498\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1503 - val_loss: 0.1490\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1501 - val_loss: 0.1482\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1495 - val_loss: 0.1469\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1486 - val_loss: 0.1487\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1483 - val_loss: 0.1457\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1476 - val_loss: 0.1453\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1468 - val_loss: 0.1456\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1462 - val_loss: 0.1447\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1461 - val_loss: 0.1432\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1453 - val_loss: 0.1454\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1446 - val_loss: 0.1438\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1446 - val_loss: 0.1432\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1441 - val_loss: 0.1419\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1435 - val_loss: 0.1416\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1426 - val_loss: 0.1415\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1425 - val_loss: 0.1407\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1418 - val_loss: 0.1404\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1411 - val_loss: 0.1413\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1408 - val_loss: 0.1400\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1407 - val_loss: 0.1387\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1396 - val_loss: 0.1385\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1393 - val_loss: 0.1375\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1390 - val_loss: 0.1376\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1385 - val_loss: 0.1358\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1381 - val_loss: 0.1361\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1371 - val_loss: 0.1352\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1374 - val_loss: 0.1352\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1368 - val_loss: 0.1347\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1364 - val_loss: 0.1351\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1359 - val_loss: 0.1338\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1356 - val_loss: 0.1339\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1352 - val_loss: 0.1334\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1349 - val_loss: 0.1345\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1346 - val_loss: 0.1326\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1340 - val_loss: 0.1330\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1336 - val_loss: 0.1321\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1336 - val_loss: 0.1319\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1331 - val_loss: 0.1303\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1328 - val_loss: 0.1306\n",
            "Epoch 97/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1323 - val_loss: 0.1312\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1321 - val_loss: 0.1306\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1315 - val_loss: 0.1294\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1310 - val_loss: 0.1288\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1312 - val_loss: 0.1287\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1307 - val_loss: 0.1297\n",
            "Epoch 103/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1306 - val_loss: 0.1280\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1300 - val_loss: 0.1274\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1296 - val_loss: 0.1288\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1296 - val_loss: 0.1287\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1292 - val_loss: 0.1278\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1286 - val_loss: 0.1269\n",
            "Epoch 109/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1287 - val_loss: 0.1273\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1280 - val_loss: 0.1263\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1284 - val_loss: 0.1272\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1274 - val_loss: 0.1276\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1275 - val_loss: 0.1258\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1270 - val_loss: 0.1247\n",
            "Epoch 115/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1268 - val_loss: 0.1241\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1266 - val_loss: 0.1243\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 1s 18us/step - loss: 0.1261 - val_loss: 0.1233\n",
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1262 - val_loss: 0.1238\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1255 - val_loss: 0.1237\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1255 - val_loss: 0.1234\n",
            "Epoch 121/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1252 - val_loss: 0.1235\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1248 - val_loss: 0.1236\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1247 - val_loss: 0.1239\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1244 - val_loss: 0.1222\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1241 - val_loss: 0.1219\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1241 - val_loss: 0.1232\n",
            "Epoch 127/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1236 - val_loss: 0.1221\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1236 - val_loss: 0.1215\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1233 - val_loss: 0.1215\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1230 - val_loss: 0.1224\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1228 - val_loss: 0.1226\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1229 - val_loss: 0.1208\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1225 - val_loss: 0.1199\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1225 - val_loss: 0.1201\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1221 - val_loss: 0.1212\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1217 - val_loss: 0.1199\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1221 - val_loss: 0.1206\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1215 - val_loss: 0.1201\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1213 - val_loss: 0.1204\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1210 - val_loss: 0.1202\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1214 - val_loss: 0.1191\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1207 - val_loss: 0.1195\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1208 - val_loss: 0.1198\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1209 - val_loss: 0.1190\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1202 - val_loss: 0.1190\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1204 - val_loss: 0.1178\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1200 - val_loss: 0.1189\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1201 - val_loss: 0.1174\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1199 - val_loss: 0.1185\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1195 - val_loss: 0.1179\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1196 - val_loss: 0.1191\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1194 - val_loss: 0.1182\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1193 - val_loss: 0.1177\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1192 - val_loss: 0.1169\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1187 - val_loss: 0.1172\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1189 - val_loss: 0.1174\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1185 - val_loss: 0.1170\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1186 - val_loss: 0.1184\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1185 - val_loss: 0.1166\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1183 - val_loss: 0.1166\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1183 - val_loss: 0.1164\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1179 - val_loss: 0.1158\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1180 - val_loss: 0.1161\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1178 - val_loss: 0.1170\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1176 - val_loss: 0.1150\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1174 - val_loss: 0.1160\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1173 - val_loss: 0.1156\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1173 - val_loss: 0.1162\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1170 - val_loss: 0.1157\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1171 - val_loss: 0.1143\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1165 - val_loss: 0.1151\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1169 - val_loss: 0.1158\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1165 - val_loss: 0.1150\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1164 - val_loss: 0.1151\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1161 - val_loss: 0.1143\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1160 - val_loss: 0.1158\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1159 - val_loss: 0.1139\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1160 - val_loss: 0.1144\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1154 - val_loss: 0.1142\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1156 - val_loss: 0.1136\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1153 - val_loss: 0.1141\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1153 - val_loss: 0.1130\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1152 - val_loss: 0.1137\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1146 - val_loss: 0.1138\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1150 - val_loss: 0.1131\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1147 - val_loss: 0.1131\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1144 - val_loss: 0.1125\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1145 - val_loss: 0.1131\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1142 - val_loss: 0.1134\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1141 - val_loss: 0.1128\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1141 - val_loss: 0.1121\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1136 - val_loss: 0.1120\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1138 - val_loss: 0.1118\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1135 - val_loss: 0.1128\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1133 - val_loss: 0.1114\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1133 - val_loss: 0.1107\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 1s 20us/step - loss: 0.1129 - val_loss: 0.1127\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1131 - val_loss: 0.1121\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1131 - val_loss: 0.1111\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 1s 19us/step - loss: 0.1129 - val_loss: 0.1109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAHKCBzUAAAAAAAA5wYMaAAAAAACAnPh/WlFm5vIgI2oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "D0roSg9z7ia3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvModel:\n",
        "    def __init__(self):\n",
        "\n",
        "        inputs = Input(shape=(28, 28, 1))  # 'channels_firtst'이미지 데이터 형식을 사용하는 경우 이를 적용\n",
        "\n",
        "        x = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
        "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "        encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "        # 이 시점에서 표현(representatoin)은 (4,4,8) 즉, 128 차원\n",
        "\n",
        "        x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(16, (3, 3), activation='relu')(x)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "        autoencoder = Model(inputs, decoded)\n",
        "        \n",
        "        encoder = Model(inputs=inputs, outputs=encoded)\n",
        "\n",
        "        # Decoder for Predict\n",
        "        encoded_inputs = Input(shape=(4, 4, 8))\n",
        "#         decoder_layer = autoencoder.layers[-3:]\n",
        "        decoder_layer = encoded_inputs\n",
        "        for layer in autoencoder.layers[-7:]:\n",
        "            decoder_layer = layer(decoder_layer)\n",
        "        decoder = Model(inputs=encoded_inputs, outputs=decoder_layer)\n",
        "\n",
        "\n",
        "        autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.autoencoder = autoencoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LclqdAUy8WXi",
        "colab_type": "code",
        "outputId": "d50446be-6393-4e06-96f5-c319061b2f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7588
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "  \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "# Reshape for conv2d\n",
        "x_train_3d = np.reshape(x_train_flat, (len(x_train_flat), 28, 28, 1))  # 'channels_firtst'이미지 데이터 형식을 사용하는 경우 이를 적용\n",
        "x_test_3d = np.reshape(x_test_flat, (len(x_test_flat), 28, 28, 1))  # 'channels_firtst'이미지 데이터 형식을 사용하는 경우 이를 적용\n",
        "\n",
        "conv_model = AutoEncoderTester(ConvModel())\n",
        "conv_model.train(x_train=x_train_3d, y_train=x_train_3d, x_test=x_test_3d, y_test=x_test_3d,\n",
        "                epochs=200, batch_size=1024, verbose=1)\n",
        "conv_model.test(x_test=x_test_3d)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://3f75f667.ngrok.io\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.3748 - val_loss: 0.2391\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.2247 - val_loss: 0.2164\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.2061 - val_loss: 0.1971\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1935 - val_loss: 0.1913\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.1851 - val_loss: 0.1814\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1776 - val_loss: 0.1769\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1718 - val_loss: 0.1697\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.1667 - val_loss: 0.1610\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1640 - val_loss: 0.1617\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.1601 - val_loss: 0.1601\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1569 - val_loss: 0.1531\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1544 - val_loss: 0.1506\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1518 - val_loss: 0.1478\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.1497 - val_loss: 0.1476\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1469 - val_loss: 0.1438\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1454 - val_loss: 0.1429\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.1437 - val_loss: 0.1409\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1415 - val_loss: 0.1400\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1405 - val_loss: 0.1398\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.1391 - val_loss: 0.1399\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1378 - val_loss: 0.1365\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1366 - val_loss: 0.1333\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1357 - val_loss: 0.1336\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.1337 - val_loss: 0.1333\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1344 - val_loss: 0.1291\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1327 - val_loss: 0.1326\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1316 - val_loss: 0.1303\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1312 - val_loss: 0.1300\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1307 - val_loss: 0.1289\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1300 - val_loss: 0.1268\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1290 - val_loss: 0.1277\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1279 - val_loss: 0.1250\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1278 - val_loss: 0.1271\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1272 - val_loss: 0.1255\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1265 - val_loss: 0.1217\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1256 - val_loss: 0.1233\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1255 - val_loss: 0.1240\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1246 - val_loss: 0.1226\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1244 - val_loss: 0.1196\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1239 - val_loss: 0.1231\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1229 - val_loss: 0.1208\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1223 - val_loss: 0.1301\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1221 - val_loss: 0.1245\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1219 - val_loss: 0.1225\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1216 - val_loss: 0.1198\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1211 - val_loss: 0.1208\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1208 - val_loss: 0.1209\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1206 - val_loss: 0.1182\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1203 - val_loss: 0.1196\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1202 - val_loss: 0.1165\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1197 - val_loss: 0.1153\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1187 - val_loss: 0.1189\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1193 - val_loss: 0.1202\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1189 - val_loss: 0.1173\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1182 - val_loss: 0.1156\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1179 - val_loss: 0.1176\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1183 - val_loss: 0.1159\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1176 - val_loss: 0.1139\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1173 - val_loss: 0.1144\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1172 - val_loss: 0.1151\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1168 - val_loss: 0.1184\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1167 - val_loss: 0.1151\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1166 - val_loss: 0.1157\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1163 - val_loss: 0.1154\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1159 - val_loss: 0.1182\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1155 - val_loss: 0.1129\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1161 - val_loss: 0.1133\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1152 - val_loss: 0.1143\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1150 - val_loss: 0.1143\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1150 - val_loss: 0.1139\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1146 - val_loss: 0.1124\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1149 - val_loss: 0.1123\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1141 - val_loss: 0.1152\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1144 - val_loss: 0.1150\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1139 - val_loss: 0.1116\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1138 - val_loss: 0.1116\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1134 - val_loss: 0.1107\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1134 - val_loss: 0.1104\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1130 - val_loss: 0.1111\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1125 - val_loss: 0.1131\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1131 - val_loss: 0.1117\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1124 - val_loss: 0.1104\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1123 - val_loss: 0.1110\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1121 - val_loss: 0.1112\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1118 - val_loss: 0.1104\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1123 - val_loss: 0.1117\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1119 - val_loss: 0.1099\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1116 - val_loss: 0.1110\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1117 - val_loss: 0.1119\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1116 - val_loss: 0.1100\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1108 - val_loss: 0.1073\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1112 - val_loss: 0.1125\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1108 - val_loss: 0.1073\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1106 - val_loss: 0.1103\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1109 - val_loss: 0.1094\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1101 - val_loss: 0.1097\n",
            "Epoch 97/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1104 - val_loss: 0.1098\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1105 - val_loss: 0.1076\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1101 - val_loss: 0.1107\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1100 - val_loss: 0.1073\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1097 - val_loss: 0.1093\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1093 - val_loss: 0.1113\n",
            "Epoch 103/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1096 - val_loss: 0.1094\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1094 - val_loss: 0.1077\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1096 - val_loss: 0.1089\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1091 - val_loss: 0.1076\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1095 - val_loss: 0.1077\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1090 - val_loss: 0.1086\n",
            "Epoch 109/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1090 - val_loss: 0.1053\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1087 - val_loss: 0.1073\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1085 - val_loss: 0.1085\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1086 - val_loss: 0.1070\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1086 - val_loss: 0.1072\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1083 - val_loss: 0.1075\n",
            "Epoch 115/200\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1079 - val_loss: 0.1110\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1083 - val_loss: 0.1076\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1082 - val_loss: 0.1055\n",
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1077 - val_loss: 0.1067\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1083 - val_loss: 0.1056\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1076 - val_loss: 0.1059\n",
            "Epoch 121/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1076 - val_loss: 0.1056\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1075 - val_loss: 0.1045\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1079 - val_loss: 0.1064\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1075 - val_loss: 0.1064\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1072 - val_loss: 0.1074\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1073 - val_loss: 0.1039\n",
            "Epoch 127/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1070 - val_loss: 0.1059\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1068 - val_loss: 0.1059\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1067 - val_loss: 0.1068\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1065 - val_loss: 0.1071\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1068 - val_loss: 0.1069\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1067 - val_loss: 0.1046\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1065 - val_loss: 0.1055\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1059 - val_loss: 0.1062\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1064 - val_loss: 0.1061\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1059 - val_loss: 0.1067\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1063 - val_loss: 0.1049\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1058 - val_loss: 0.1049\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 0.1059 - val_loss: 0.1041\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1058 - val_loss: 0.1068\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1057 - val_loss: 0.1041\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1060 - val_loss: 0.1037\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 4s 62us/step - loss: 0.1057 - val_loss: 0.1060\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1057 - val_loss: 0.1046\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1056 - val_loss: 0.1065\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1057 - val_loss: 0.1040\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1056 - val_loss: 0.1022\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1055 - val_loss: 0.1087\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1051 - val_loss: 0.1029\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1055 - val_loss: 0.1038\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1054 - val_loss: 0.1060\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1051 - val_loss: 0.1057\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1050 - val_loss: 0.1066\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1051 - val_loss: 0.1042\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1052 - val_loss: 0.1044\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1050 - val_loss: 0.1015\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1049 - val_loss: 0.1029\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1045 - val_loss: 0.1039\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1048 - val_loss: 0.1020\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1045 - val_loss: 0.1036\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1051 - val_loss: 0.1046\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1046 - val_loss: 0.1055\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1044 - val_loss: 0.1019\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1043 - val_loss: 0.1030\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1046 - val_loss: 0.1033\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1038 - val_loss: 0.1033\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1042 - val_loss: 0.1029\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1039 - val_loss: 0.1026\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1033 - val_loss: 0.1022\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1041 - val_loss: 0.1015\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1037 - val_loss: 0.1034\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1037 - val_loss: 0.1034\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1038 - val_loss: 0.1045\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1039 - val_loss: 0.1020\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1038 - val_loss: 0.1025\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1042 - val_loss: 0.1017\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1036 - val_loss: 0.1019\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1039 - val_loss: 0.1026\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1035 - val_loss: 0.1026\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1035 - val_loss: 0.1019\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1031 - val_loss: 0.1004\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1037 - val_loss: 0.1020\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1034 - val_loss: 0.1007\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1030 - val_loss: 0.1016\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1034 - val_loss: 0.1028\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1033 - val_loss: 0.1021\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1028 - val_loss: 0.1020\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1033 - val_loss: 0.1004\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1030 - val_loss: 0.1022\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1027 - val_loss: 0.1006\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1033 - val_loss: 0.1022\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1030 - val_loss: 0.1023\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1027 - val_loss: 0.1030\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1026 - val_loss: 0.1027\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1032 - val_loss: 0.1015\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1030 - val_loss: 0.1003\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1025 - val_loss: 0.1021\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.1031 - val_loss: 0.1016\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1025 - val_loss: 0.1009\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1027 - val_loss: 0.1024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/bS8igAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0BAtZwJ56Dyv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Same as ConvModel, but number of filter increased\n",
        "class DenoiseConvModel:\n",
        "    def __init__(self):\n",
        "        \n",
        "        num_filters = 64\n",
        "        \n",
        "        inputs = Input(shape=(28, 28, 1))  # 'channels_firtst'이미지 데이터 형식을 사용하는 경우 이를 적용\n",
        "\n",
        "        x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(inputs)\n",
        "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "        x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(x)\n",
        "        encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "        # 이 시점에서 표현(representatoin)은 (4,4,8) 즉, 128 차원\n",
        "\n",
        "        x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(encoded)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        x = Conv2D(num_filters, (3, 3), activation='relu')(x)\n",
        "        x = UpSampling2D((2, 2))(x)\n",
        "        decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "        autoencoder = Model(inputs, decoded)\n",
        "        \n",
        "        encoder = Model(inputs=inputs, outputs=encoded)\n",
        "\n",
        "        # Decoder for Predict\n",
        "        encoded_inputs = Input(shape=(4, 4, num_filters))\n",
        "#         decoder_layer = autoencoder.layers[-3:]\n",
        "        decoder_layer = encoded_inputs\n",
        "        for layer in autoencoder.layers[-7:]:\n",
        "            decoder_layer = layer(decoder_layer)\n",
        "        decoder = Model(inputs=encoded_inputs, outputs=decoder_layer)\n",
        "\n",
        "\n",
        "        autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.autoencoder = autoencoder\n",
        "        \n",
        "        print(autoencoder.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hXkaxrsO3x-r",
        "colab_type": "code",
        "outputId": "88bb90ae-9c16-4d0e-ba11-61241c3546e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8218
        }
      },
      "cell_type": "code",
      "source": [
        "# Reshape for conv2d\n",
        "x_train_3d = np.reshape(x_train_flat, (len(x_train_flat), 28, 28, 1))  # 'channels_firtst'이미지 데이터 형식을 사용하는 경우 이를 적용\n",
        "x_test_3d = np.reshape(x_test_flat, (len(x_test_flat), 28, 28, 1))  # 'channels_firtst'이미지 데이터 형식을 사용하는 경우 이를 적용\n",
        "\n",
        "noise_factor = 0.5\n",
        "x_train_3d_noisy = x_train_3d + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train_3d.shape) \n",
        "x_test_3d_noisy = x_test_3d + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test_3d.shape) \n",
        "\n",
        "x_train_3d_noisy = np.clip(x_train_3d_noisy, 0., 1.)\n",
        "x_test_3d_noisy = np.clip(x_test_3d_noisy, 0., 1.)\n",
        "\n",
        "\n",
        "dconv_model = AutoEncoderTester(DenoiseConvModel())\n",
        "dconv_model.train(x_train=x_train_3d_noisy, y_train=x_train_3d, \n",
        "                 x_test=x_test_3d_noisy, y_test=x_test_3d,\n",
        "                epochs=200, batch_size=1024, verbose=1)\n",
        "dconv_model.test(x_test=x_test_3d_noisy)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 64)          36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 1)         577       \n",
            "=================================================================\n",
            "Total params: 185,857\n",
            "Trainable params: 185,857\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 15s 256us/step - loss: 0.3532 - val_loss: 0.2822\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.2557 - val_loss: 0.2384\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.2213 - val_loss: 0.2011\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.1944 - val_loss: 0.1796\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.1778 - val_loss: 0.1671\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.1678 - val_loss: 0.1577\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.1595 - val_loss: 0.1499\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.1528 - val_loss: 0.1474\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.1484 - val_loss: 0.1424\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.1440 - val_loss: 0.1414\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.1412 - val_loss: 0.1387\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.1380 - val_loss: 0.1459\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.1358 - val_loss: 0.1322\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.1334 - val_loss: 0.1320\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.1317 - val_loss: 0.1294\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.1300 - val_loss: 0.1291\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.1279 - val_loss: 0.1267\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1269 - val_loss: 0.1285\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1257 - val_loss: 0.1227\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1241 - val_loss: 0.1218\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1233 - val_loss: 0.1193\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1222 - val_loss: 0.1200\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1211 - val_loss: 0.1191\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1202 - val_loss: 0.1189\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1196 - val_loss: 0.1186\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1188 - val_loss: 0.1166\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1179 - val_loss: 0.1165\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1173 - val_loss: 0.1220\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1167 - val_loss: 0.1130\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1154 - val_loss: 0.1140\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1155 - val_loss: 0.1118\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1146 - val_loss: 0.1146\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1144 - val_loss: 0.1144\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1138 - val_loss: 0.1126\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1134 - val_loss: 0.1111\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1129 - val_loss: 0.1108\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1124 - val_loss: 0.1112\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1122 - val_loss: 0.1117\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1119 - val_loss: 0.1103\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1115 - val_loss: 0.1093\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1110 - val_loss: 0.1098\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1106 - val_loss: 0.1127\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1107 - val_loss: 0.1087\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1101 - val_loss: 0.1099\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1098 - val_loss: 0.1105\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1098 - val_loss: 0.1093\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1093 - val_loss: 0.1081\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1091 - val_loss: 0.1096\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1088 - val_loss: 0.1084\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1085 - val_loss: 0.1082\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1083 - val_loss: 0.1064\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1081 - val_loss: 0.1078\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1080 - val_loss: 0.1069\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1074 - val_loss: 0.1069\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1075 - val_loss: 0.1061\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1071 - val_loss: 0.1072\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1069 - val_loss: 0.1056\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1067 - val_loss: 0.1069\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1064 - val_loss: 0.1065\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.1062 - val_loss: 0.1052\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1061 - val_loss: 0.1063\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1059 - val_loss: 0.1055\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1059 - val_loss: 0.1047\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.1056 - val_loss: 0.1058\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.1056 - val_loss: 0.1048\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1052 - val_loss: 0.1070\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1051 - val_loss: 0.1044\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1051 - val_loss: 0.1041\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1050 - val_loss: 0.1041\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1047 - val_loss: 0.1042\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1044 - val_loss: 0.1044\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1046 - val_loss: 0.1042\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1042 - val_loss: 0.1029\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1041 - val_loss: 0.1027\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1038 - val_loss: 0.1025\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1037 - val_loss: 0.1029\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1039 - val_loss: 0.1032\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1035 - val_loss: 0.1038\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1034 - val_loss: 0.1027\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.1033 - val_loss: 0.1030\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.1032 - val_loss: 0.1029\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.1032 - val_loss: 0.1028\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.1030 - val_loss: 0.1027\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.1029 - val_loss: 0.1033\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.1028 - val_loss: 0.1023\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.1025 - val_loss: 0.1030\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.1025 - val_loss: 0.1021\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.1025 - val_loss: 0.1022\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1023 - val_loss: 0.1019\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1020 - val_loss: 0.1014\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1021 - val_loss: 0.1024\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1019 - val_loss: 0.1023\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.1020 - val_loss: 0.1022\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.1019 - val_loss: 0.1013\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1017 - val_loss: 0.1019\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.1016 - val_loss: 0.1013\n",
            "Epoch 97/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1016 - val_loss: 0.1011\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.1015 - val_loss: 0.1010\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.1015 - val_loss: 0.1025\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.1012 - val_loss: 0.1005\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.1011 - val_loss: 0.1016\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.1011 - val_loss: 0.1002\n",
            "Epoch 103/200\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.1011 - val_loss: 0.1019\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.1012 - val_loss: 0.0996\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.1008 - val_loss: 0.1006\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.1008 - val_loss: 0.1005\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.1008 - val_loss: 0.1004\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.1008 - val_loss: 0.1004\n",
            "Epoch 109/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.1005 - val_loss: 0.1007\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.1005 - val_loss: 0.0997\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.1005 - val_loss: 0.1000\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.1005 - val_loss: 0.0994\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1002 - val_loss: 0.1003\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.1002 - val_loss: 0.0996\n",
            "Epoch 115/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.1001 - val_loss: 0.0999\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.1001 - val_loss: 0.0994\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0999 - val_loss: 0.1000\n",
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.0999 - val_loss: 0.1003\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0998 - val_loss: 0.0991\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0997 - val_loss: 0.0995\n",
            "Epoch 121/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0998 - val_loss: 0.0990\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0998 - val_loss: 0.0992\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 10s 173us/step - loss: 0.0996 - val_loss: 0.1000\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0996 - val_loss: 0.0996\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0996 - val_loss: 0.0993\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0996 - val_loss: 0.0994\n",
            "Epoch 127/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0994 - val_loss: 0.0994\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.0994 - val_loss: 0.0992\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0993 - val_loss: 0.0994\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0992 - val_loss: 0.1002\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.0989 - val_loss: 0.0986\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.0991 - val_loss: 0.0995\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0990 - val_loss: 0.0998\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0990 - val_loss: 0.1002\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.0990 - val_loss: 0.0983\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.0987 - val_loss: 0.0995\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 10s 175us/step - loss: 0.0989 - val_loss: 0.0985\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0989 - val_loss: 0.0987\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0987 - val_loss: 0.0989\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.0987 - val_loss: 0.0991\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0987 - val_loss: 0.0987\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0986 - val_loss: 0.0992\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0985 - val_loss: 0.0982\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0985 - val_loss: 0.0990\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 11s 175us/step - loss: 0.0985 - val_loss: 0.0989\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0984 - val_loss: 0.0986\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0984 - val_loss: 0.0985\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0982 - val_loss: 0.0995\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0982 - val_loss: 0.0982\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0983 - val_loss: 0.0989\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0983 - val_loss: 0.0981\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0982 - val_loss: 0.0983\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0982 - val_loss: 0.0988\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0980 - val_loss: 0.0985\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0979 - val_loss: 0.0981\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0980 - val_loss: 0.0986\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0979 - val_loss: 0.0979\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0979 - val_loss: 0.0992\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0978 - val_loss: 0.0979\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0978 - val_loss: 0.0977\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0977 - val_loss: 0.0981\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0977 - val_loss: 0.0980\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0976 - val_loss: 0.0971\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0975 - val_loss: 0.0984\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0977 - val_loss: 0.0979\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0975 - val_loss: 0.0986\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0975 - val_loss: 0.0981\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0976 - val_loss: 0.0983\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0974 - val_loss: 0.0975\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0975 - val_loss: 0.0979\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0974 - val_loss: 0.0973\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0974 - val_loss: 0.0970\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0972 - val_loss: 0.0979\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0971 - val_loss: 0.0973\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0971 - val_loss: 0.0972\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 11s 178us/step - loss: 0.0972 - val_loss: 0.0974\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0970 - val_loss: 0.0969\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0971 - val_loss: 0.0977\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0971 - val_loss: 0.0977\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 11s 177us/step - loss: 0.0970 - val_loss: 0.0976\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 10s 174us/step - loss: 0.0969 - val_loss: 0.0966\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0968 - val_loss: 0.0974\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0969 - val_loss: 0.0974\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0968 - val_loss: 0.0975\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0970 - val_loss: 0.0976\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0967 - val_loss: 0.0970\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0968 - val_loss: 0.0969\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0968 - val_loss: 0.0971\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0967 - val_loss: 0.0974\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0967 - val_loss: 0.0977\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0967 - val_loss: 0.0981\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0966 - val_loss: 0.0968\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0965 - val_loss: 0.0968\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.0967 - val_loss: 0.0967\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0964 - val_loss: 0.0969\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 10s 170us/step - loss: 0.0963 - val_loss: 0.0962\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0965 - val_loss: 0.0975\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 10s 171us/step - loss: 0.0966 - val_loss: 0.0973\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0963 - val_loss: 0.0978\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 10s 172us/step - loss: 0.0964 - val_loss: 0.0969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABGoAAADjCAYAAADdR/IFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DU7U2tzl7PMc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Same as ConvModel, but number of filter increased\n",
        "class Seq2SeqModel:\n",
        "    def __init__(self):\n",
        "        \n",
        "        timesteps = 28\n",
        "        input_dim = 28\n",
        "        latent_dim = 128\n",
        "        \n",
        "        inputs = Input(shape=(timesteps, input_dim))\n",
        "        encoded = LSTM(latent_dim)(inputs)\n",
        "\n",
        "        decoded = RepeatVector(timesteps)(encoded)\n",
        "        decoded = LSTM(input_dim, return_sequences=True)(decoded)\n",
        "\n",
        "        autoencoder = Model(inputs, decoded)\n",
        "        \n",
        "        encoder = Model(inputs=inputs, outputs=encoded)\n",
        "\n",
        "        # Decoder for Predict\n",
        "        encoded_inputs = Input(shape=(timesteps, input_dim))\n",
        "#         decoder_layer = autoencoder.layers[-3:]\n",
        "        decoder_layer = encoded_inputs\n",
        "        for layer in autoencoder.layers[-2:]:\n",
        "            decoder_layer = layer(decoder_layer)\n",
        "        decoder = Model(inputs=encoded_inputs, outputs=decoder_layer)\n",
        "\n",
        "\n",
        "        autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.autoencoder = autoencoder\n",
        "        \n",
        "        print(autoencoder.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p17mmOkBrTSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5431bc87-6a11-429f-dd83-58442e7eac66"
      },
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "AFwOaUSg4AQ6",
        "colab_type": "code",
        "outputId": "52a0e7fd-9dc9-48ff-feb7-017c0d0d51dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "cell_type": "code",
      "source": [
        "seq2seq_model = AutoEncoderTester(Seq2SeqModel())\n",
        "seq2seq_model.train(x_train=x_train, y_train=x_train, \n",
        "                 x_test=x_test, y_test=x_test,\n",
        "                epochs=200, batch_size=1024, verbose=1)\n",
        "seq2seq_model.test(x_test=x_test)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-3bd34565aef9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mseq2seq_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoEncoderTester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSeq2SeqModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m seq2seq_model.train(x_train=x_train, y_train=x_train, \n\u001b[1;32m      3\u001b[0m                  \u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 epochs=200, batch_size=1024, verbose=1)\n\u001b[1;32m      5\u001b[0m \u001b[0mseq2seq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-ed53f5dde071>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mdecoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer repeat_vector_4: expected ndim=2, found ndim=3"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Kqq7HSJH4SZY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
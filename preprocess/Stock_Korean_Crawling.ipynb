{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국 주식 데이터를 크롤링합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예전에 <심이삭>이 만들어 두었던 것을 참조합니다.\n",
    "## 링크: https://github.com/gilgarad/stock_predict/blob/master/src/data_crawler/stock_info.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from os.path import join, exists, dirname\n",
    "from os import makedirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링 구현 순서:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 주가시스템에 있는 회사 리스트 가지고 오기\n",
    "## 설명: 등록된 회사 리스트와 종목 코드를 수집합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_df = pd.read_html('http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13', header=0)[0]\n",
    "# 종목코드가 6자리이기 때문에 6자리를 맞춰주기 위해 설정해줌\n",
    "code_df.종목코드 = code_df.종목코드.map('{:06d}'.format)\n",
    "# 우리가 필요한 것은 회사명과 종목코드이기 때문에 필요없는 column들은 제외해준다.\n",
    "code_df = code_df[['회사명', '종목코드']]  # 한글로된 컬럼명을 영어로 바꿔준다.\n",
    "company_info = code_df.rename(columns={'회사명': 'name', '종목코드': 'code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GS글로벌</td>\n",
       "      <td>001250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSD엔진</td>\n",
       "      <td>082740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KG케미칼</td>\n",
       "      <td>001390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LG이노텍</td>\n",
       "      <td>011070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OCI</td>\n",
       "      <td>010060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SK네트웍스</td>\n",
       "      <td>001740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SK이노베이션</td>\n",
       "      <td>096770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>STX</td>\n",
       "      <td>011810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WISCOM</td>\n",
       "      <td>024070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>갤럭시아에스엠</td>\n",
       "      <td>011420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>경동도시가스</td>\n",
       "      <td>267290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>경동인베스트</td>\n",
       "      <td>012320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>고려아연</td>\n",
       "      <td>010130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>고려제강</td>\n",
       "      <td>002240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>극동유화</td>\n",
       "      <td>014530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>까뮤이앤씨</td>\n",
       "      <td>013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>남양유업</td>\n",
       "      <td>003920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>노루페인트</td>\n",
       "      <td>090350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>대림씨엔에스</td>\n",
       "      <td>004440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>대영포장</td>\n",
       "      <td>014160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>대원제약</td>\n",
       "      <td>003220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>대유에이텍</td>\n",
       "      <td>002880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>대한해운</td>\n",
       "      <td>005880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>동남합성</td>\n",
       "      <td>023450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>동아쏘시오홀딩스</td>\n",
       "      <td>000640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>동양</td>\n",
       "      <td>001520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>롯데손해보험</td>\n",
       "      <td>000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>롯데쇼핑</td>\n",
       "      <td>023530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>마니커</td>\n",
       "      <td>027740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>모두투어리츠</td>\n",
       "      <td>204210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>피엔티</td>\n",
       "      <td>137400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>피제이전자</td>\n",
       "      <td>006140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>하이로닉</td>\n",
       "      <td>149980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>하이비젼시스템</td>\n",
       "      <td>126700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>하츠</td>\n",
       "      <td>066130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>한국기업평가</td>\n",
       "      <td>034950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>한국제6호스팩</td>\n",
       "      <td>281410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>한네트</td>\n",
       "      <td>052600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254</th>\n",
       "      <td>한라IMS</td>\n",
       "      <td>092460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>한화수성스팩</td>\n",
       "      <td>265920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>홈센타홀딩스</td>\n",
       "      <td>060560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>휴맥스</td>\n",
       "      <td>115160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>관악산업</td>\n",
       "      <td>076340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>굿센</td>\n",
       "      <td>243870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>나라소프트</td>\n",
       "      <td>288490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>네추럴FNP</td>\n",
       "      <td>086220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>다이노나</td>\n",
       "      <td>086080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>라온테크</td>\n",
       "      <td>232680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>럭스피아</td>\n",
       "      <td>092590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>루켄테크놀러지스</td>\n",
       "      <td>162120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>메디젠휴먼케어</td>\n",
       "      <td>236340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>아이케이세미콘</td>\n",
       "      <td>149010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>알로이스</td>\n",
       "      <td>271400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>엄지하우스</td>\n",
       "      <td>224810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2270</th>\n",
       "      <td>엔케이맥스</td>\n",
       "      <td>262760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>인프라웨어테크놀러지</td>\n",
       "      <td>247300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>지앤이헬스케어</td>\n",
       "      <td>299480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>툴젠</td>\n",
       "      <td>199800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>틸론</td>\n",
       "      <td>217880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>판도라티비</td>\n",
       "      <td>202960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2276 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            name    code\n",
       "0          GS글로벌  001250\n",
       "1          HSD엔진  082740\n",
       "2          KG케미칼  001390\n",
       "3          LG이노텍  011070\n",
       "4            OCI  010060\n",
       "5         SK네트웍스  001740\n",
       "6        SK이노베이션  096770\n",
       "7            STX  011810\n",
       "8         WISCOM  024070\n",
       "9        갤럭시아에스엠  011420\n",
       "10        경동도시가스  267290\n",
       "11        경동인베스트  012320\n",
       "12          고려아연  010130\n",
       "13          고려제강  002240\n",
       "14          극동유화  014530\n",
       "15         까뮤이앤씨  013700\n",
       "16          남양유업  003920\n",
       "17         노루페인트  090350\n",
       "18        대림씨엔에스  004440\n",
       "19          대영포장  014160\n",
       "20          대원제약  003220\n",
       "21         대유에이텍  002880\n",
       "22          대한해운  005880\n",
       "23          동남합성  023450\n",
       "24      동아쏘시오홀딩스  000640\n",
       "25            동양  001520\n",
       "26        롯데손해보험  000400\n",
       "27          롯데쇼핑  023530\n",
       "28           마니커  027740\n",
       "29        모두투어리츠  204210\n",
       "...          ...     ...\n",
       "2246         피엔티  137400\n",
       "2247       피제이전자  006140\n",
       "2248        하이로닉  149980\n",
       "2249     하이비젼시스템  126700\n",
       "2250          하츠  066130\n",
       "2251      한국기업평가  034950\n",
       "2252     한국제6호스팩  281410\n",
       "2253         한네트  052600\n",
       "2254       한라IMS  092460\n",
       "2255      한화수성스팩  265920\n",
       "2256      홈센타홀딩스  060560\n",
       "2257         휴맥스  115160\n",
       "2258        관악산업  076340\n",
       "2259          굿센  243870\n",
       "2260       나라소프트  288490\n",
       "2261      네추럴FNP  086220\n",
       "2262        다이노나  086080\n",
       "2263        라온테크  232680\n",
       "2264        럭스피아  092590\n",
       "2265    루켄테크놀러지스  162120\n",
       "2266     메디젠휴먼케어  236340\n",
       "2267     아이케이세미콘  149010\n",
       "2268        알로이스  271400\n",
       "2269       엄지하우스  224810\n",
       "2270       엔케이맥스  262760\n",
       "2271  인프라웨어테크놀러지  247300\n",
       "2272     지앤이헬스케어  299480\n",
       "2273          툴젠  199800\n",
       "2274          틸론  217880\n",
       "2275       판도라티비  202960\n",
       "\n",
       "[2276 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 수집하기\n",
    "## 내용: 네이버에서 위에서 수집한 종목코드의 주가 데이터를 수집합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(company_name, by_year=list(), recent_n_data=list()):\n",
    "    t = datetime.now()\n",
    "    print('Crawling Company Name:', company_name)\n",
    "    \n",
    "    # 1. 회사 종목코드와 데이터를 수집하기 위한 대상 url을 생성합닏.\n",
    "    code = company_info.query(\"name=='{}'\".format(company_name))['code'].to_string(index=False)\n",
    "    url = 'http://finance.naver.com/item/sise_day.nhn?code={code}'.format(code=code)\n",
    "    print(\"요청 URL = {}\".format(url))\n",
    "\n",
    "    # 2. (option) 지정된 year 또는 타겟 날짜로부터 가장 최근 n일의 데이터를 수집하고자 할 때 지정하기 위한 로직입니다.\n",
    "    yrs = \"\"\n",
    "    min_year = -1\n",
    "    target_date = -1\n",
    "    num_seq = -1\n",
    "\n",
    "    if len(recent_n_data) == 2:\n",
    "        target_date = str(recent_n_data[0])\n",
    "        target_date = target_date[:4] + '.' + target_date[4:6] + '.' + target_date[6:8]  # yyyy.mm.dd\n",
    "        num_seq = recent_n_data[1]\n",
    "\n",
    "    if len(by_year) != 0 and target_date == -1:\n",
    "        yrs = \"|\".join(str(yr) for yr in by_year)\n",
    "        min_year = sorted(by_year)[0]\n",
    "        print('Collecting years... ', by_year)\n",
    "        # print('Mininum Year: %i' % min_year)\n",
    "\n",
    "    # 3. UI에 Display된 페이지 데이터를 수집하기 때문에 max page를 정해놓고 시도합니다.\n",
    "    max_page = 1000\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for page in range(1, max_page):\n",
    "        pg_url = '{url}&page={page}'.format(url=url, page=page)\n",
    "        d = pd.read_html(pg_url, header=0)[0]\n",
    "        d = d.dropna()\n",
    "\n",
    "        # 3-1. 마지막 페이지 수집시, 이전 페이지의 중복된 날짜도 함께 수집되었는지 확인하고 프로세스를 멈춥니다.\n",
    "        if df.shape[0] != 0 and d['날짜'][1] in df['날짜'].tolist():\n",
    "            # Max page reached\n",
    "            print('Break page:', page)\n",
    "            break\n",
    "\n",
    "        # 3-2. 타겟 날짜에 대한 데이터만 수집할 때에만 해당됩니다.\n",
    "        if target_date != -1:\n",
    "            if df.shape[0] == 0:\n",
    "                d = d[d['날짜'].str.contains(target_date)]\n",
    "                if d.shape[0] == 0:\n",
    "                    continue\n",
    "\n",
    "            df = df.append(d)\n",
    "\n",
    "            if df.shape[0] >= num_seq:\n",
    "                df = df.head(num_seq)\n",
    "                break\n",
    "\n",
    "        # 3-3. 타겟 year만 수집할 때에만 해당됩니다. 타겟 year 이전 해의 데이터가 수집되었다면 프로세스를 멈춥니다.\n",
    "        if min_year != -1 and target_date == -1 and min_year > int(d['날짜'][d.shape[0] - 1][:4]):\n",
    "            print('Found minimum year, break page:', page)\n",
    "            break\n",
    "\n",
    "        df = df.append(d, ignore_index=True)\n",
    "\n",
    "    # 4. 수집된 데이터를 가볍게 가공합니다.\n",
    "    df['name'] = pd.Series([company_name] * len(df['날짜']), index=df.index)\n",
    "    df = df.rename(columns={'날짜': 'date', '종가': 'final_price', '전일비': 'compare_to_prior', '시가': 'start_price',\n",
    "                            '고가': 'highest_price', '저가': 'lowest_price', '거래량': 'num_of_traded'})\n",
    "\n",
    "    # 5. 수집된 데이터 중 타겟 year에 해당하는 데이터만 재정리 합니다.\n",
    "    if min_year != -1:\n",
    "        df = df[df['date'].str.contains(yrs)]\n",
    "\n",
    "    t = datetime.now() - t\n",
    "    print('Elapsed time:', t)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "Crawling Company Name: GS글로벌\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=001250\n",
      "Break page: 577\n",
      "Elapsed time: 0:01:14.563903\n",
      "[1]\n",
      "Crawling Company Name: HSD엔진\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=082740\n",
      "Break page: 207\n",
      "Elapsed time: 0:00:24.792800\n",
      "[2]\n",
      "Crawling Company Name: KG케미칼\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=001390\n",
      "Break page: 577\n",
      "Elapsed time: 0:01:13.448658\n",
      "[3]\n",
      "Crawling Company Name: LG이노텍\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=011070\n",
      "Break page: 269\n",
      "Elapsed time: 0:00:29.585697\n",
      "[4]\n",
      "Crawling Company Name: OCI\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=010060\n",
      "Break page: 577\n",
      "Elapsed time: 0:01:33.890093\n",
      "[5]\n",
      "Crawling Company Name: SK네트웍스\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=001740\n",
      "Break page: 577\n",
      "Elapsed time: 0:01:22.758800\n",
      "[6]\n",
      "Crawling Company Name: SK이노베이션\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=096770\n",
      "Break page: 293\n",
      "Elapsed time: 0:00:56.543179\n",
      "[7]\n",
      "Crawling Company Name: STX\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=011810\n",
      "Break page: 575\n",
      "Elapsed time: 0:02:02.545661\n",
      "[8]\n",
      "Crawling Company Name: WISCOM\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=024070\n",
      "Break page: 459\n",
      "Elapsed time: 0:01:03.437385\n",
      "[9]\n",
      "Crawling Company Name: 갤럭시아에스엠\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=011420\n",
      "Break page: 575\n",
      "Elapsed time: 0:01:21.281189\n",
      "[10]\n",
      "Crawling Company Name: 경동도시가스\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=267290\n",
      "Break page: 51\n",
      "Elapsed time: 0:00:05.753530\n",
      "[11]\n",
      "Crawling Company Name: 경동인베스트\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=012320\n",
      "Break page: 554\n",
      "Elapsed time: 0:01:25.619667\n",
      "[12]\n",
      "Crawling Company Name: 고려아연\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=010130\n",
      "Break page: 575\n",
      "Elapsed time: 0:01:13.411018\n",
      "[13]\n",
      "Crawling Company Name: 고려제강\n",
      "요청 URL = http://finance.naver.com/item/sise_day.nhn?code=002240\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.DataFrame()\n",
    "collect_start_time = datetime.now()\n",
    "for idx, company_name in enumerate(company_info['name']):\n",
    "    print('[%i]' %idx)\n",
    "    stock_data = get_stock_data(company_name=company_name)\n",
    "    all_data = pd.concat([all_data, stock_data])\n",
    "print('Crawling data finished. Total elapsed time:', datetime.now() - collect_start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 수집된 모든 데이터를 pandas로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('/data1/stock_data/2019_05_14_stock_data.csv')\n",
    "print('Data saved!!') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras: #1. 주가 데이터의 여러 feature를 더하는함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features:\n",
    "\n",
    "    @staticmethod\n",
    "    def fnMACD(m_Df, m_NumFast=12, m_NumSlow=26, m_NumSignal=9):\n",
    "        m_Df['EMAFast'] = m_Df['final_price'].ewm(span=m_NumFast, min_periods=m_NumFast - 1).mean()\n",
    "        m_Df['EMASlow'] = m_Df['final_price'].ewm(span=m_NumSlow, min_periods=m_NumSlow - 1).mean()\n",
    "        m_Df['MACD'] = m_Df['EMAFast'] - m_Df['EMASlow']\n",
    "        m_Df['MACDSignal'] = m_Df['MACD'].ewm(span=m_NumSignal, min_periods=m_NumSignal - 1).mean()\n",
    "        m_Df['MACDDiff'] = m_Df['MACD'] - m_Df['MACDSignal']\n",
    "        return m_Df\n",
    "\n",
    "    @staticmethod\n",
    "    def fnBolingerBand(m_DF, n=20, k=2):\n",
    "        m_DF['20d_ma'] = pd.rolling_mean(m_DF['final_price'], window=n)\n",
    "        m_DF['Bol_upper'] = pd.rolling_mean(m_DF['final_price'], window=n) + k * pd.rolling_std(m_DF['final_price'], n,\n",
    "                                                                                                min_periods=n)\n",
    "        m_DF['Bol_lower'] = pd.rolling_mean(m_DF['final_price'], window=n) - k * pd.rolling_std(m_DF['final_price'], n,\n",
    "                                                                                                min_periods=n)\n",
    "\n",
    "        return m_DF\n",
    "\n",
    "    @staticmethod\n",
    "    def fnRSI(m_Df, m_N=14):\n",
    "        U = np.where(m_Df['final_price'].diff(1) > 0, m_Df['final_price'].diff(1), 0)\n",
    "        D = np.where(m_Df['final_price'].diff(1) < 0, m_Df['final_price'].diff(1) * (-1), 0)\n",
    "\n",
    "        AU = pd.DataFrame(U).rolling(window=m_N, min_periods=m_N).mean()\n",
    "        AD = pd.DataFrame(D).rolling(window=m_N, min_periods=m_N).mean()\n",
    "        RSI = AU.div(AD + AU) * 100\n",
    "\n",
    "        m_Df['RSI'] = RSI\n",
    "        return m_Df\n",
    "\n",
    "    @staticmethod\n",
    "    def fnStoch(m_Df, n=14):  # price: 종가(시간 오름차순), n: 기간\n",
    "        sz = len(m_Df['final_price'])\n",
    "\n",
    "        tempSto_K = []\n",
    "        for i in range(sz):\n",
    "            if i >= n - 1:\n",
    "                tempUp = m_Df['final_price'][i] - min(m_Df['lowest_price'][i - n + 1:i + 1])\n",
    "                tempDown = max(m_Df['highest_price'][i - n + 1:i + 1]) - min(m_Df['lowest_price'][i - n + 1:i + 1])\n",
    "                tempSto_K.append(tempUp / tempDown)\n",
    "            else:\n",
    "                tempSto_K.append(0)  # n보다 작은 초기값은 0 설정\n",
    "        m_Df['Sto_K'] = pd.Series(tempSto_K, index=m_Df.index)\n",
    "\n",
    "        m_Df['Sto_D'] = pd.Series(pd.rolling_mean(m_Df['Sto_K'], 3))\n",
    "        m_Df['Sto_SlowD'] = pd.Series(pd.rolling_mean(m_Df['Sto_D'], 3))\n",
    "\n",
    "        return m_Df\n",
    "\n",
    "    @staticmethod\n",
    "    def fnMA(m_Df, m_N=list(), m_ColumnName='final_price'):\n",
    "        all_MA = list()\n",
    "        if m_ColumnName in m_Df.columns:\n",
    "            for num in m_N:\n",
    "                MA = pd.Series.rolling(m_Df[m_ColumnName], window=num, center=False).mean()\n",
    "                m_Df['MA' + str(num)] = MA\n",
    "\n",
    "                all_MA.append(MA)\n",
    "\n",
    "            for i in range(len(all_MA)):\n",
    "                if i + 1 == len(all_MA):\n",
    "                    break\n",
    "\n",
    "                for i2 in range(i + 1, len(all_MA)):\n",
    "                    m_Df['SignalMA' + str(m_N[i]) + '_' + str(m_N[i2])] = all_MA[i] - all_MA[i2]\n",
    "\n",
    "        else:\n",
    "            raise (\"You didn't input a Column Name\")\n",
    "        return m_Df\n",
    "\n",
    "    @staticmethod\n",
    "    def change_prior_to(m_Df):\n",
    "\n",
    "        m_Df['compare_to_prior'] = m_Df['final_price'].diff(1)\n",
    "        m_Df['percent'] = (m_Df['final_price'] * 100 / (m_Df['final_price'] - m_Df['compare_to_prior']) - 100).round(2)\n",
    "\n",
    "        return m_Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extras: 일련의 과정을 class화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockCollector:\n",
    "    def __init__(self):\n",
    "        self.company_info = self._retrieve_company_info()\n",
    "        \n",
    "    def _retrieve_company_info(self):\n",
    "        code_df = pd.read_html('http://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13', header=0)[0]\n",
    "        # 종목코드가 6자리이기 때문에 6자리를 맞춰주기 위해 설정해줌\n",
    "        code_df.종목코드 = code_df.종목코드.map('{:06d}'.format)\n",
    "        # 우리가 필요한 것은 회사명과 종목코드이기 때문에 필요없는 column들은 제외해준다.\n",
    "        code_df = code_df[['회사명', '종목코드']]  # 한글로된 컬럼명을 영어로 바꿔준다.\n",
    "        company_info = code_df.rename(columns={'회사명': 'name', '종목코드': 'code'})\n",
    "        return company_info\n",
    "    \n",
    "    def get_stock_data_by_company(self, company_name, by_year=list(), recent_n_data=list()):\n",
    "        t = datetime.now()\n",
    "        print('Crawling Company Name:', company_name)\n",
    "\n",
    "        # 1. 회사 종목코드와 데이터를 수집하기 위한 대상 url을 생성합닏.\n",
    "        code = self.company_info.query(\"name=='{}'\".format(company_name))['code'].to_string(index=False)\n",
    "        url = 'http://finance.naver.com/item/sise_day.nhn?code={code}'.format(code=code)\n",
    "        print(\"요청 URL = {}\".format(url))\n",
    "\n",
    "        # 2. (option) 지정된 year 또는 타겟 날짜로부터 가장 최근 n일의 데이터를 수집하고자 할 때 지정하기 위한 로직입니다.\n",
    "        yrs = \"\"\n",
    "        min_year = -1\n",
    "        target_date = -1\n",
    "        num_seq = -1\n",
    "\n",
    "        if len(recent_n_data) == 2:\n",
    "            target_date = str(recent_n_data[0])\n",
    "            target_date = target_date[:4] + '.' + target_date[4:6] + '.' + target_date[6:8]  # yyyy.mm.dd\n",
    "            num_seq = recent_n_data[1]\n",
    "\n",
    "        if len(by_year) != 0 and target_date == -1:\n",
    "            yrs = \"|\".join(str(yr) for yr in by_year)\n",
    "            min_year = sorted(by_year)[0]\n",
    "            print('Collecting years... ', by_year)\n",
    "            # print('Mininum Year: %i' % min_year)\n",
    "\n",
    "        # 3. UI에 Display된 페이지 데이터를 수집하기 때문에 max page를 정해놓고 시도합니다.\n",
    "        max_page = 1000\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        for page in range(1, max_page):\n",
    "            pg_url = '{url}&page={page}'.format(url=url, page=page)\n",
    "            d = pd.read_html(pg_url, header=0)[0]\n",
    "            d = d.dropna()\n",
    "\n",
    "            # 3-1. 마지막 페이지 수집시, 이전 페이지의 중복된 날짜도 함께 수집되었는지 확인하고 프로세스를 멈춥니다.\n",
    "            if df.shape[0] != 0 and len(d['날짜']) > 1 and d['날짜'][1] in df['날짜'].tolist():\n",
    "                # Max page reached\n",
    "                print('Break page:', page)\n",
    "                break\n",
    "\n",
    "            # 3-2. 타겟 날짜에 대한 데이터만 수집할 때에만 해당됩니다.\n",
    "            if target_date != -1:\n",
    "                if df.shape[0] == 0:\n",
    "                    d = d[d['날짜'].str.contains(target_date)]\n",
    "                    if d.shape[0] == 0:\n",
    "                        continue\n",
    "\n",
    "                df = df.append(d)\n",
    "\n",
    "                if df.shape[0] >= num_seq:\n",
    "                    df = df.head(num_seq)\n",
    "                    break\n",
    "\n",
    "            # 3-3. 타겟 year만 수집할 때에만 해당됩니다. 타겟 year 이전 해의 데이터가 수집되었다면 프로세스를 멈춥니다.\n",
    "            if min_year != -1 and target_date == -1 and min_year > int(d['날짜'][d.shape[0] - 1][:4]):\n",
    "                print('Found minimum year, break page:', page)\n",
    "                break\n",
    "\n",
    "            df = df.append(d, ignore_index=True)\n",
    "\n",
    "        # 4. 수집된 데이터를 가볍게 가공합니다.\n",
    "        df['name'] = pd.Series([company_name] * len(df['날짜']), index=df.index)\n",
    "        df = df.rename(columns={'날짜': 'date', '종가': 'final_price', '전일비': 'compare_to_prior', '시가': 'start_price',\n",
    "                                '고가': 'highest_price', '저가': 'lowest_price', '거래량': 'num_of_traded'})\n",
    "\n",
    "        # 5. 수집된 데이터 중 타겟 year에 해당하는 데이터만 재정리 합니다.\n",
    "        if min_year != -1:\n",
    "            df = df[df['date'].str.contains(yrs)]\n",
    "\n",
    "        t = datetime.now() - t\n",
    "        print('Elapsed time:', t)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def start_data_collection(self, save_path, autosave=True, save_by_company=True):\n",
    "        all_data = pd.DataFrame()\n",
    "        collect_start_time = datetime.now()\n",
    "        today_date = datetime.today().strftime('%Y%m%d')\n",
    "        save_full_path = join(save_path, today_date + '_stock_data.csv')\n",
    "        for idx, company_name in enumerate(company_info['name']):\n",
    "            if idx < 1151 or idx == 1176:\n",
    "                continue\n",
    "            print('[%i]' %idx)\n",
    "            stock_data = self.get_stock_data_by_company(company_name=company_name)\n",
    "            all_data = pd.concat([all_data, stock_data])\n",
    "            \n",
    "            if autosave and idx % 50 == 0:\n",
    "                all_data.to_csv(save_full_path)\n",
    "                \n",
    "        all_data.to_csv(join(save_path, today_date + '_stock_data.csv'))\n",
    "        print('Crawling data finished. Total elapsed time:', datetime.now() - collect_start_time)\n",
    "        if save_by_company:\n",
    "            self.split_data_by_company(input_path=save_full_path, output_path=save_path)\n",
    "        \n",
    "    def split_data_by_company(self, input_path, output_path):\n",
    "\n",
    "        df = pd.read_csv(input_path, index_col=0)\n",
    "\n",
    "        if not exists(output_path):\n",
    "            makedirs(output_path)\n",
    "\n",
    "        for idx, company_name in enumerate(df.name.unique()):\n",
    "            print(idx, company_name)\n",
    "            a = df.loc[df['name'] == company_name]\n",
    "            a = a.loc[:, a.columns != 'name']\n",
    "            np.save(join(output_path, company_name), a)\n",
    "\n",
    "        print('All data saved by company name. Length of company:', len(df.name.unique()))\n",
    "\n",
    "    def add_features(self, input_path=None, output_path=None, df=None):\n",
    "\n",
    "        if df is None:\n",
    "            df = pd.read_csv(input_path)\n",
    "\n",
    "        df_new = pd.DataFrame()\n",
    "        for idx, name in enumerate(df.name.unique()):\n",
    "            print(idx, name)\n",
    "            try:\n",
    "                df_temp = df[df['name'] == name].sort_values(by=['date']).reset_index(drop=True)\n",
    "                df_temp = Features.fnMACD(df_temp)\n",
    "                df_temp = Features.fnBolingerBand(df_temp)\n",
    "                df_temp = Features.fnRSI(df_temp)\n",
    "                df_temp = Features.fnStoch(df_temp)\n",
    "                df_temp = Features.change_prior_to(df_temp)\n",
    "                df_temp = Features.fnMA(df_temp, m_N=[5, 20, 60, 120, 240])\n",
    "            except Exception as e:\n",
    "                print('Error occurred while adding features at index %i %s' % (idx, name))\n",
    "                print(e)\n",
    "                continue\n",
    "            df_new = pd.concat([df_new, df_temp])\n",
    "\n",
    "        df = df_new.reset_index(drop=True)\n",
    "\n",
    "        if output_path is not None:\n",
    "            if not exists(dirname(output_path)):\n",
    "                makedirs(dirname(output_path))\n",
    "            df.to_csv(output_path)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_collector = StockCollector()\n",
    "stock_collector.start_data_collection(save_path='/data1/stock_data', autosave=True, save_by_company=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainwave_eeg",
   "language": "python",
   "name": "brainwave_eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

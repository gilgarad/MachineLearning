{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 주가 데이터를 일반적인 지도학습으로 학습합니다. Regression 모델과 Classification 모델을 시도해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.layers import Input, Dense, LSTM, GRU, Flatten, Lambda\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loader & Step estimator & train/test splitter\n",
    "## 링크: http://121.140.2.142:8888/notebooks/test_notes/preprocess/stockdata_preprocess_basic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(all_stock_data, batch_size, pre_data_length, pro_data_length, process_data):\n",
    "    num_company = len(all_stock_data)\n",
    "    num_features = all_stock_data[0].shape[1]\n",
    "    company_idx = list(range(num_company))\n",
    "    current_idx = np.array([0 for _ in range(num_company)])\n",
    "    \n",
    "    def get_batch(all_stock_data, current_idx, batch_company_idx, pre_data_length, pro_data_length):\n",
    "        batch_company = [all_stock_data[idx] for idx in batch_company_idx]\n",
    "        \n",
    "        # get cur pos of each data in mini batch\n",
    "        cur_pos = current_idx[batch_company_idx]\n",
    "        x_batch = np.empty(shape=(0, pre_data_length, num_features))\n",
    "        y_batch = np.empty(shape=(0, pro_data_length, num_features))\n",
    "        \n",
    "        for company, pos in zip(batch_company, cur_pos):\n",
    "            _x_batch = company[pos: pos+pre_data_length].reshape(1, pre_data_length, num_features)\n",
    "            _y_batch = company[pos+pre_data_length: pos+pre_data_length+pro_data_length].reshape(1, pro_data_length, num_features)\n",
    "            \n",
    "#             print(_new_x_batch)\n",
    "            x_batch = np.concatenate([x_batch, _x_batch], axis=0)\n",
    "            y_batch = np.concatenate([y_batch, _y_batch], axis=0)\n",
    "        \n",
    "        # update for next pos\n",
    "        new_pos = [c + 1 for c in cur_pos]\n",
    "        current_idx[batch_company_idx] = new_pos\n",
    "\n",
    "        # check if next pos possible, and remove from company_idx if not possible\n",
    "        for idx, (company, pos) in enumerate(zip(batch_company, new_pos)):\n",
    "            if company.shape[0] < pos + pre_data_length + pro_data_length:\n",
    "#                 print(company[0, 7], ' finished at pos:', pos)\n",
    "                company_idx.remove(batch_company_idx[idx])\n",
    "                np.delete(current_idx, batch_company_idx[idx])\n",
    "        \n",
    "        return x_batch, y_batch\n",
    "    \n",
    "    count = 0\n",
    "    while True:\n",
    "        while len(company_idx) > 0:\n",
    "#             if count == 0:\n",
    "#                 print('New Epoch begins', len(company_idx))\n",
    "            count += 1\n",
    "            # random pick from all batch\n",
    "            if len(company_idx) >= batch_size:\n",
    "                batch_company_idx = sample(company_idx, batch_size)\n",
    "\n",
    "\n",
    "                x_batch, y_batch = get_batch(all_stock_data=all_stock_data, current_idx=current_idx, \n",
    "                                             pre_data_length=pre_data_length, pro_data_length=pro_data_length,\n",
    "                                             batch_company_idx=batch_company_idx)\n",
    "\n",
    "            else: # if number of company less than batch, then company should go for parallel\n",
    "                batch_company_idx = company_idx[:]\n",
    "                x_batch = list()\n",
    "                y_batch = list()\n",
    "                idx = 0\n",
    "                while len(x_batch) < batch_size and len(company_idx) > 0:\n",
    "                    if idx >= len(company_idx):\n",
    "                        idx = 0\n",
    "                    batch_company_idx = company_idx[idx]\n",
    "                    idx += 1\n",
    "                    idx = idx % len(company_idx)\n",
    "                    _x_batch, _y_batch = get_batch(all_stock_data=all_stock_data, current_idx=current_idx, \n",
    "                                                   pre_data_length=pre_data_length, pro_data_length=pro_data_length,\n",
    "                                                   batch_company_idx=[batch_company_idx])\n",
    "                    x_batch.append(_x_batch)\n",
    "                    y_batch.append(_y_batch)\n",
    "\n",
    "                x_batch = np.concatenate(x_batch, axis=0)\n",
    "                y_batch = np.concatenate(y_batch, axis=0)\n",
    "\n",
    "            # 마지막 처리를 해줍니다.\n",
    "            x_batch, y_batch = process_data(x_batch, y_batch)\n",
    "\n",
    "            yield x_batch, y_batch\n",
    "        \n",
    "        company_idx = list(range(num_company))\n",
    "        current_idx = np.array([0 for _ in range(num_company)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating total estimated steps\n",
    "def get_estimated_steps(all_stock_data, pre_data_length, pro_data_length, batch_size):\n",
    "    \n",
    "    all_length = pre_data_length + pro_data_length\n",
    "\n",
    "    total_steps = 0\n",
    "    for stock_data in all_stock_data:\n",
    "        total_steps += (stock_data.shape[0] - all_length + 1)\n",
    "    #     print(total_steps)\n",
    "\n",
    "    return total_steps, int(np.ceil(total_steps / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_by_year(all_stock_data, year): # year 이전은 train, year 해당 년 및 이후는 test\n",
    "    train_stock_data = list()\n",
    "    test_stock_data = list()\n",
    "    for stock_data in all_stock_data:\n",
    "        indices = np.where(stock_data[:, 0] >= (year * 10000))[0]\n",
    "        test_stock_data.append(stock_data[indices][:, 1:])\n",
    "        \n",
    "        indices = np.where(stock_data[:, 0] < (year * 10000))[0]\n",
    "        train_stock_data.append(stock_data[indices][:, 1:])\n",
    "    \n",
    "    test_stock_data = [stock_data for stock_data in test_stock_data if stock_data.shape[0] > 0]\n",
    "    train_stock_data = [stock_data for stock_data in train_stock_data if stock_data.shape[0] > 0]\n",
    "    \n",
    "    return train_stock_data, test_stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. '날짜': 'date', 2. '종가': 'final_price', 3. '전일비': 'compare_to_prior', 4. '시가': 'start_price',\n",
    "5. '고가': 'highest_price', 6. '저가': 'lowest_price', 7. '거래량': 'num_of_traded', 8. '회사이름': 'company_name'\n",
    "9. df_temp = Features.fnMACD(df_temp)\n",
    "    df_temp = Features.fnBolingerBand(df_temp)\n",
    "    df_temp = Features.fnRSI(df_temp)\n",
    "    df_temp = Features.fnStoch(df_temp)\n",
    "    df_temp = Features.change_prior_to(df_temp)\n",
    "    df_temp = Features.fnMA(df_temp, m_N=[5, 20, 60, 120, 240])\n",
    "\"\"\"\n",
    "\n",
    "def load_data(root_path):\n",
    "    all_stock_data = list()\n",
    "    for filename in listdir(root_path):\n",
    "        if not isfile(join(root_path, filename)) or '.npy' not in filename:\n",
    "            continue\n",
    "        print(filename)\n",
    "        stock_data = np.load(join(root_path, filename))\n",
    "        all_str_dates = stock_data[:, 0]\n",
    "        all_str_dates = [int(s.replace('.', '')) for s in all_str_dates]\n",
    "        stock_data[:, 0] = all_str_dates\n",
    "        stock_data = stock_data[::-1]\n",
    "        stock_data = stock_data[:, :-1] # remove and company name index\n",
    "        all_stock_data.append(stock_data)\n",
    "    \n",
    "    return all_stock_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data and split train & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/data1/stock_data_temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경방.npy\n",
      "경보제약.npy\n",
      "경동도시가스.npy\n",
      "경동인베스트.npy\n"
     ]
    }
   ],
   "source": [
    "all_stock_data = load_data(root_path=root_path)\n",
    "train_stock_data, test_stock_data = split_train_test_by_year(all_stock_data=all_stock_data, year=2017) # this will also remove date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5172, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stock_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5172, 6)\n",
      "(374, 6)\n",
      "(4951, 6)\n"
     ]
    }
   ],
   "source": [
    "for stock_data in train_stock_data:\n",
    "    print(stock_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model train and test class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. t+1일의 가격으로 regression용 데이터와 classification용 데이터를 만들어주는 로직을 만들어 data_loader의 process_data로 넣을 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression example\n",
    "def process_regression_data(x_batch, y_batch):\n",
    "    \n",
    "    y_batch = y_batch[:, :, 0] # final price index = 1\n",
    "    \n",
    "    return x_batch, y_batch\n",
    "\n",
    "def process_classification_data(x_batch, y_batch):\n",
    "    \n",
    "    y_batch = y_batch[:, :, 2] # final price index = 1\n",
    "    y_batch[np.where(y_batch <= 0)[0], 0] = 0\n",
    "    y_batch[np.where(y_batch > 0)[0], 0] = 1\n",
    "    \n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. 주어진 모델에 대해 학습하고 테스트 할 수 있는 클래스를 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPredictionActivator:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        print(self.model.summary())\n",
    "        \n",
    "    def train(self, train_data, validation_data=None, epochs=50, batch_size=64, verbose=1, validation_split=0.1, **kwargs):\n",
    "#         print(len(args))\n",
    "        \n",
    "        pre_data_length = kwargs['pre_data_length']\n",
    "        pro_data_length = kwargs['pro_data_length']\n",
    "        process_data = kwargs['process_data']\n",
    "        step_estimator = kwargs['step_estimator']\n",
    "        generator = kwargs['generator']\n",
    "        train_steps, train_steps_per_epoch = step_estimator(train_data, pre_data_length, pro_data_length, batch_size)\n",
    "        val_steps, val_steps_per_epoch = step_estimator(validation_data, pre_data_length, pro_data_length, batch_size)\n",
    "        \n",
    "        print('Trains steps:', train_steps_per_epoch, 'Test steps:', val_steps_per_epoch)\n",
    "        \n",
    "#         mc = ModelCheckpoint('./save/s2s_{epoch:03d}.h5', save_weights_only=True, period=5)\n",
    "        \n",
    "        self.model.fit_generator(generator=generator(all_stock_data=train_data, \n",
    "                                                       batch_size=batch_size, \n",
    "                                                       pre_data_length=pre_data_length, \n",
    "                                                       pro_data_length=pro_data_length,\n",
    "                                                       process_data=process_data),\n",
    "                                 steps_per_epoch=train_steps_per_epoch,\n",
    "                                 validation_data=generator(all_stock_data=validation_data, \n",
    "                                                       batch_size=batch_size, \n",
    "                                                       pre_data_length=pre_data_length, \n",
    "                                                       pro_data_length=pro_data_length,\n",
    "                                                       process_data=process_data),\n",
    "                                 validation_steps=val_steps_per_epoch,\n",
    "                                 epochs=epochs,\n",
    "                                 verbose=verbose,\n",
    "#                                  callbacks=[mc]\n",
    "                                )\n",
    "        print('')\n",
    "    \n",
    "    def test(self, test_data, tester, **kwargs):\n",
    "        pre_data_length = kwargs['pre_data_length']\n",
    "        pro_data_length = kwargs['pro_data_length']\n",
    "        process_data = kwargs['process_data']\n",
    "        step_estimator = kwargs['step_estimator']\n",
    "        \n",
    "        test_steps_per_epoch = step_estimator(test_data, pre_data_length, pro_data_length, batch_size)\n",
    "        tester(test_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. lstm regression 심플 모델을 생성하고 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_lstm(pre_data_length, num_features, output_dim):\n",
    "    inputs = Input(shape=(pre_data_length, num_features))\n",
    "    lstm_layer = LSTM(64)\n",
    "    lstm_outputs = lstm_layer(inputs)\n",
    "#     flat_lstm_outputs = Flatten()(lstm_outputs)\n",
    "    outputs = Dense(output_dim)(lstm_outputs)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data_length = 20\n",
    "pro_data_length = 1\n",
    "process_data = process_regression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 20, 6)             0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                18176     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 18,241\n",
      "Trainable params: 18,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Trains steps: 164 Test steps: 22\n",
      "Epoch 1/1000\n",
      "164/164 [==============================] - 4s 21ms/step - loss: 7127609037.3189 - acc: 0.0000e+00 - val_loss: 1294052659.7516 - val_acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7127268613.4388 - acc: 0.0000e+00 - val_loss: 1293919356.8678 - val_acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7126917940.3953 - acc: 0.0000e+00 - val_loss: 1293769010.3024 - val_acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7126529783.4193 - acc: 0.0000e+00 - val_loss: 1293610602.4018 - val_acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7126154748.5776 - acc: 0.0000e+00 - val_loss: 1293454515.8919 - val_acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7125781402.7420 - acc: 0.0000e+00 - val_loss: 1293301118.4573 - val_acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7125408390.2487 - acc: 0.0000e+00 - val_loss: 1293148154.4836 - val_acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7125035549.6493 - acc: 0.0000e+00 - val_loss: 1292996046.7261 - val_acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7124662728.8561 - acc: 0.0000e+00 - val_loss: 1292843910.2177 - val_acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7124290019.9686 - acc: 0.0000e+00 - val_loss: 1292691798.8137 - val_acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7123917137.6118 - acc: 0.0000e+00 - val_loss: 1292539630.0482 - val_acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 7123544413.6994 - acc: 0.0000e+00 - val_loss: 1292387549.2184 - val_acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7123171613.6857 - acc: 0.0000e+00 - val_loss: 1292235432.9993 - val_acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7122798905.5788 - acc: 0.0000e+00 - val_loss: 1292083400.0409 - val_acc: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7122426261.2778 - acc: 0.0000e+00 - val_loss: 1291931238.4280 - val_acc: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7122053527.2176 - acc: 0.0000e+00 - val_loss: 1291779249.6947 - val_acc: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7121680903.3070 - acc: 0.0000e+00 - val_loss: 1291627196.3068 - val_acc: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7121308241.4433 - acc: 0.0000e+00 - val_loss: 1291475172.3243 - val_acc: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7120935561.5319 - acc: 0.0000e+00 - val_loss: 1291323188.9204 - val_acc: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7120562962.8898 - acc: 0.0000e+00 - val_loss: 1291171075.1790 - val_acc: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7120190399.4680 - acc: 0.0000e+00 - val_loss: 1291019110.3813 - val_acc: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7119817728.5303 - acc: 0.0000e+00 - val_loss: 1290867125.8086 - val_acc: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7119445229.1118 - acc: 0.0000e+00 - val_loss: 1290715166.3404 - val_acc: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7119072624.3227 - acc: 0.0000e+00 - val_loss: 1290563228.4704 - val_acc: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7118700216.4184 - acc: 0.0000e+00 - val_loss: 1290411289.9459 - val_acc: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7118327668.6057 - acc: 0.0000e+00 - val_loss: 1290259276.1081 - val_acc: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7117955219.1390 - acc: 0.0000e+00 - val_loss: 1290107357.3587 - val_acc: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7117582687.0348 - acc: 0.0000e+00 - val_loss: 1289955460.7217 - val_acc: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7117210249.2747 - acc: 0.0000e+00 - val_loss: 1289803573.7151 - val_acc: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7116837834.1495 - acc: 0.0000e+00 - val_loss: 1289651685.3996 - val_acc: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7116465366.0464 - acc: 0.0000e+00 - val_loss: 1289499834.8108 - val_acc: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7116093085.0716 - acc: 0.0000e+00 - val_loss: 1289347960.2863 - val_acc: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7115720627.5054 - acc: 0.0000e+00 - val_loss: 1289196021.2476 - val_acc: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7115348293.0654 - acc: 0.0000e+00 - val_loss: 1289044172.4821 - val_acc: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7114975923.0139 - acc: 0.0000e+00 - val_loss: 1288892360.7889 - val_acc: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7114603644.6728 - acc: 0.0000e+00 - val_loss: 1288740541.2885 - val_acc: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7114231307.1096 - acc: 0.0000e+00 - val_loss: 1288588773.3061 - val_acc: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7113859050.9151 - acc: 0.0000e+00 - val_loss: 1288436944.8298 - val_acc: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7113486754.5240 - acc: 0.0000e+00 - val_loss: 1288285161.2330 - val_acc: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7113114516.5735 - acc: 0.0000e+00 - val_loss: 1288133435.6523 - val_acc: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7112742409.2621 - acc: 0.0000e+00 - val_loss: 1287981646.7261 - val_acc: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7112370095.4065 - acc: 0.0000e+00 - val_loss: 1287829902.0248 - val_acc: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7111997936.7752 - acc: 0.0000e+00 - val_loss: 1287678157.3236 - val_acc: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7111625662.5296 - acc: 0.0000e+00 - val_loss: 1287526464.6545 - val_acc: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7111253579.9004 - acc: 0.0000e+00 - val_loss: 1287374651.7925 - val_acc: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7110881436.5872 - acc: 0.0000e+00 - val_loss: 1287222957.9547 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7110509351.2261 - acc: 0.0000e+00 - val_loss: 1287071256.3097 - val_acc: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7110137187.6185 - acc: 0.0000e+00 - val_loss: 1286919611.5121 - val_acc: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7109765200.0158 - acc: 0.0000e+00 - val_loss: 1286767924.8269 - val_acc: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7109393130.9474 - acc: 0.0000e+00 - val_loss: 1286616286.0131 - val_acc: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7109021154.2719 - acc: 0.0000e+00 - val_loss: 1286464621.4405 - val_acc: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7108649011.3468 - acc: 0.0000e+00 - val_loss: 1286312997.5866 - val_acc: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7108277093.6983 - acc: 0.0000e+00 - val_loss: 1286161374.9014 - val_acc: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7107905111.4611 - acc: 0.0000e+00 - val_loss: 1286009777.3207 - val_acc: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7107533112.3447 - acc: 0.0000e+00 - val_loss: 1285858152.2980 - val_acc: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7107161079.1789 - acc: 0.0000e+00 - val_loss: 1285706595.4361 - val_acc: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7106789188.6521 - acc: 0.0000e+00 - val_loss: 1285554993.0402 - val_acc: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7106417295.0022 - acc: 0.0000e+00 - val_loss: 1285403452.3068 - val_acc: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7106045425.7434 - acc: 0.0000e+00 - val_loss: 1285251891.2841 - val_acc: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7105673519.2161 - acc: 0.0000e+00 - val_loss: 1285100354.7115 - val_acc: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7105301664.6889 - acc: 0.0000e+00 - val_loss: 1284948797.1950 - val_acc: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7104929808.8939 - acc: 0.0000e+00 - val_loss: 1284797312.1402 - val_acc: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7104557977.9773 - acc: 0.0000e+00 - val_loss: 1284645755.7925 - val_acc: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7104186160.6216 - acc: 0.0000e+00 - val_loss: 1284494290.5128 - val_acc: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7103814452.4409 - acc: 0.0000e+00 - val_loss: 1284342882.4543 - val_acc: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7103442611.4746 - acc: 0.0000e+00 - val_loss: 1284191430.3112 - val_acc: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7103070959.0996 - acc: 0.0000e+00 - val_loss: 1284039945.7706 - val_acc: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7102699181.0629 - acc: 0.0000e+00 - val_loss: 1283888518.7319 - val_acc: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7102327583.5190 - acc: 0.0000e+00 - val_loss: 1283737056.9584 - val_acc: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7101955763.7237 - acc: 0.0000e+00 - val_loss: 1283585623.2812 - val_acc: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7101584111.5438 - acc: 0.0000e+00 - val_loss: 1283434207.5559 - val_acc: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7101212511.7543 - acc: 0.0000e+00 - val_loss: 1283282789.4931 - val_acc: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7100840833.6223 - acc: 0.0000e+00 - val_loss: 1283131441.9284 - val_acc: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7100469232.5651 - acc: 0.0000e+00 - val_loss: 1282980028.0263 - val_acc: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7100097649.3626 - acc: 0.0000e+00 - val_loss: 1282828662.5099 - val_acc: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7099726124.7947 - acc: 0.0000e+00 - val_loss: 1282677392.7363 - val_acc: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7099354524.6161 - acc: 0.0000e+00 - val_loss: 1282526036.8503 - val_acc: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7098982994.6815 - acc: 0.0000e+00 - val_loss: 1282374701.9080 - val_acc: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7098611446.4060 - acc: 0.0000e+00 - val_loss: 1282223384.2630 - val_acc: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7098239953.7411 - acc: 0.0000e+00 - val_loss: 1282072089.3850 - val_acc: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7097868479.2242 - acc: 0.0000e+00 - val_loss: 1281920748.4587 - val_acc: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7097496956.5094 - acc: 0.0000e+00 - val_loss: 1281769476.8619 - val_acc: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7097125625.0207 - acc: 0.0000e+00 - val_loss: 1281618289.0402 - val_acc: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7096754105.4280 - acc: 0.0000e+00 - val_loss: 1281466996.4996 - val_acc: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7096382757.6455 - acc: 0.0000e+00 - val_loss: 1281315758.4690 - val_acc: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7096011370.8373 - acc: 0.0000e+00 - val_loss: 1281164527.5909 - val_acc: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7095639927.5399 - acc: 0.0000e+00 - val_loss: 1281013276.9379 - val_acc: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7095268625.0262 - acc: 0.0000e+00 - val_loss: 1280862055.0358 - val_acc: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7094897270.1209 - acc: 0.0000e+00 - val_loss: 1280710914.4310 - val_acc: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7094525983.9980 - acc: 0.0000e+00 - val_loss: 1280559699.6815 - val_acc: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7094154632.8983 - acc: 0.0000e+00 - val_loss: 1280408516.6749 - val_acc: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7093783394.5808 - acc: 0.0000e+00 - val_loss: 1280257358.7728 - val_acc: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7093412138.1174 - acc: 0.0000e+00 - val_loss: 1280106152.9993 - val_acc: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7093040866.6292 - acc: 0.0000e+00 - val_loss: 1279955108.1373 - val_acc: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7092669689.6801 - acc: 0.0000e+00 - val_loss: 1279803942.4280 - val_acc: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7092298461.8015 - acc: 0.0000e+00 - val_loss: 1279652827.5822 - val_acc: 0.0000e+00\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 7091927217.8263 - acc: 0.0000e+00 - val_loss: 1279501721.7122 - val_acc: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7091556141.4656 - acc: 0.0000e+00 - val_loss: 1279350672.0351 - val_acc: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7091184869.8770 - acc: 0.0000e+00 - val_loss: 1279199587.1088 - val_acc: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7090813841.4209 - acc: 0.0000e+00 - val_loss: 1279048509.3353 - val_acc: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7090442717.1544 - acc: 0.0000e+00 - val_loss: 1278897392.6662 - val_acc: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7090071549.3753 - acc: 0.0000e+00 - val_loss: 1278746450.6998 - val_acc: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7089700520.6249 - acc: 0.0000e+00 - val_loss: 1278595372.9262 - val_acc: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7089329502.8016 - acc: 0.0000e+00 - val_loss: 1278444325.0723 - val_acc: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7088958444.8789 - acc: 0.0000e+00 - val_loss: 1278293304.1461 - val_acc: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7088587482.7643 - acc: 0.0000e+00 - val_loss: 1278142342.4047 - val_acc: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7088216422.2068 - acc: 0.0000e+00 - val_loss: 1277991378.3258 - val_acc: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7087845446.2370 - acc: 0.0000e+00 - val_loss: 1277840386.6647 - val_acc: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7087474522.1725 - acc: 0.0000e+00 - val_loss: 1277689469.8028 - val_acc: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7087103596.2537 - acc: 0.0000e+00 - val_loss: 1277538506.8926 - val_acc: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7086732642.0402 - acc: 0.0000e+00 - val_loss: 1277387581.0548 - val_acc: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7086361805.6855 - acc: 0.0000e+00 - val_loss: 1277236678.4982 - val_acc: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7085990815.9586 - acc: 0.0000e+00 - val_loss: 1277085747.3309 - val_acc: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7085619949.9421 - acc: 0.0000e+00 - val_loss: 1276934836.4529 - val_acc: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7085249200.4185 - acc: 0.0000e+00 - val_loss: 1276783972.7918 - val_acc: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7084878410.6985 - acc: 0.0000e+00 - val_loss: 1276633078.0424 - val_acc: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7084507459.4108 - acc: 0.0000e+00 - val_loss: 1276482180.9554 - val_acc: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7084136748.6197 - acc: 0.0000e+00 - val_loss: 1276331360.3506 - val_acc: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7083765952.2642 - acc: 0.0000e+00 - val_loss: 1276180480.5610 - val_acc: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7083395172.5916 - acc: 0.0000e+00 - val_loss: 1276029758.6910 - val_acc: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7083024507.3625 - acc: 0.0000e+00 - val_loss: 1275878873.5720 - val_acc: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7082653785.0577 - acc: 0.0000e+00 - val_loss: 1275728051.7984 - val_acc: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7082283095.9248 - acc: 0.0000e+00 - val_loss: 1275577341.8963 - val_acc: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7081912407.7676 - acc: 0.0000e+00 - val_loss: 1275426502.8254 - val_acc: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7081541803.5145 - acc: 0.0000e+00 - val_loss: 1275275765.3411 - val_acc: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7081171016.8162 - acc: 0.0000e+00 - val_loss: 1275125000.4149 - val_acc: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 7080800427.1978 - acc: 0.0000e+00 - val_loss: 1274974206.2235 - val_acc: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7080429884.0211 - acc: 0.0000e+00 - val_loss: 1274823529.7473 - val_acc: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7080059319.8665 - acc: 0.0000e+00 - val_loss: 1274672764.8210 - val_acc: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7079688736.1019 - acc: 0.0000e+00 - val_loss: 1274522135.7020 - val_acc: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7079318198.6799 - acc: 0.0000e+00 - val_loss: 1274371389.8963 - val_acc: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7078947663.5013 - acc: 0.0000e+00 - val_loss: 1274220738.0102 - val_acc: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7078577109.2971 - acc: 0.0000e+00 - val_loss: 1274070038.9072 - val_acc: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7078206635.8773 - acc: 0.0000e+00 - val_loss: 1273919334.3346 - val_acc: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7077836125.5770 - acc: 0.0000e+00 - val_loss: 1273768691.4244 - val_acc: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7077465776.4530 - acc: 0.0000e+00 - val_loss: 1273618016.2571 - val_acc: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7077095327.8134 - acc: 0.0000e+00 - val_loss: 1273467459.4595 - val_acc: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7076724922.4924 - acc: 0.0000e+00 - val_loss: 1273316818.3725 - val_acc: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7076354553.4642 - acc: 0.0000e+00 - val_loss: 1273166217.8641 - val_acc: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7075984144.1425 - acc: 0.0000e+00 - val_loss: 1273015598.8897 - val_acc: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7075613697.6482 - acc: 0.0000e+00 - val_loss: 1272865086.9715 - val_acc: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7075243384.6219 - acc: 0.0000e+00 - val_loss: 1272714478.7962 - val_acc: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7074873110.1329 - acc: 0.0000e+00 - val_loss: 1272563985.9985 - val_acc: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7074502891.4519 - acc: 0.0000e+00 - val_loss: 1272413475.2491 - val_acc: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7074132609.0597 - acc: 0.0000e+00 - val_loss: 1272262892.1782 - val_acc: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7073762253.2991 - acc: 0.0000e+00 - val_loss: 1272112423.3163 - val_acc: 0.0000e+00\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 7073392093.2526 - acc: 0.0000e+00 - val_loss: 1271961874.3258 - val_acc: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7073021881.3019 - acc: 0.0000e+00 - val_loss: 1271811391.6728 - val_acc: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7072651733.6454 - acc: 0.0000e+00 - val_loss: 1271660884.5698 - val_acc: 0.0000e+00\n",
      "Epoch 150/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7072281467.7422 - acc: 0.0000e+00 - val_loss: 1271510463.5793 - val_acc: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7071911268.5707 - acc: 0.0000e+00 - val_loss: 1271360027.6289 - val_acc: 0.0000e+00\n",
      "Epoch 152/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7071541087.3521 - acc: 0.0000e+00 - val_loss: 1271209530.6706 - val_acc: 0.0000e+00\n",
      "Epoch 153/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7071171067.4069 - acc: 0.0000e+00 - val_loss: 1271059122.8167 - val_acc: 0.0000e+00\n",
      "Epoch 154/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7070800995.9476 - acc: 0.0000e+00 - val_loss: 1270908650.9627 - val_acc: 0.0000e+00\n",
      "Epoch 155/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7070430833.0701 - acc: 0.0000e+00 - val_loss: 1270758296.9642 - val_acc: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7070060724.7304 - acc: 0.0000e+00 - val_loss: 1270607846.0541 - val_acc: 0.0000e+00\n",
      "Epoch 157/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7069690664.0022 - acc: 0.0000e+00 - val_loss: 1270457511.1760 - val_acc: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7069320744.7433 - acc: 0.0000e+00 - val_loss: 1270307132.0730 - val_acc: 0.0000e+00\n",
      "Epoch 159/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7068950630.1584 - acc: 0.0000e+00 - val_loss: 1270156705.0986 - val_acc: 0.0000e+00\n",
      "Epoch 160/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7068580523.9652 - acc: 0.0000e+00 - val_loss: 1270006415.1001 - val_acc: 0.0000e+00\n",
      "Epoch 161/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7068210615.2422 - acc: 0.0000e+00 - val_loss: 1269856124.4470 - val_acc: 0.0000e+00\n",
      "Epoch 162/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7067840661.3463 - acc: 0.0000e+00 - val_loss: 1269705718.4164 - val_acc: 0.0000e+00\n",
      "Epoch 163/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7067470745.7926 - acc: 0.0000e+00 - val_loss: 1269555403.8276 - val_acc: 0.0000e+00\n",
      "Epoch 164/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7067100760.1878 - acc: 0.0000e+00 - val_loss: 1269405055.2988 - val_acc: 0.0000e+00\n",
      "Epoch 165/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7066730921.0276 - acc: 0.0000e+00 - val_loss: 1269254800.5493 - val_acc: 0.0000e+00\n",
      "Epoch 166/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7066360907.2261 - acc: 0.0000e+00 - val_loss: 1269104571.5588 - val_acc: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7065991081.4316 - acc: 0.0000e+00 - val_loss: 1268954224.7129 - val_acc: 0.0000e+00\n",
      "Epoch 168/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7065621286.9537 - acc: 0.0000e+00 - val_loss: 1268803968.7947 - val_acc: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7065251391.0099 - acc: 0.0000e+00 - val_loss: 1268653750.6034 - val_acc: 0.0000e+00\n",
      "Epoch 170/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7064881600.2394 - acc: 0.0000e+00 - val_loss: 1268503452.7977 - val_acc: 0.0000e+00\n",
      "Epoch 171/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7064511711.9045 - acc: 0.0000e+00 - val_loss: 1268353280.0000 - val_acc: 0.0000e+00\n",
      "Epoch 172/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7064141959.3803 - acc: 0.0000e+00 - val_loss: 1268203109.6801 - val_acc: 0.0000e+00\n",
      "Epoch 173/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7063772182.1707 - acc: 0.0000e+00 - val_loss: 1268052838.8020 - val_acc: 0.0000e+00\n",
      "Epoch 174/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7063402458.3304 - acc: 0.0000e+00 - val_loss: 1267902677.9722 - val_acc: 0.0000e+00\n",
      "Epoch 175/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7063032726.4876 - acc: 0.0000e+00 - val_loss: 1267752535.0942 - val_acc: 0.0000e+00\n",
      "Epoch 176/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7062663082.3557 - acc: 0.0000e+00 - val_loss: 1267602297.1278 - val_acc: 0.0000e+00\n",
      "Epoch 177/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7062293377.8309 - acc: 0.0000e+00 - val_loss: 1267452130.9686 - val_acc: 0.0000e+00\n",
      "Epoch 178/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7061923696.6235 - acc: 0.0000e+00 - val_loss: 1267302065.2272 - val_acc: 0.0000e+00\n",
      "Epoch 179/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7061553996.0983 - acc: 0.0000e+00 - val_loss: 1267151967.2286 - val_acc: 0.0000e+00\n",
      "Epoch 180/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7061184386.3090 - acc: 0.0000e+00 - val_loss: 1267001781.9489 - val_acc: 0.0000e+00\n",
      "Epoch 181/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7060814796.4218 - acc: 0.0000e+00 - val_loss: 1266851686.9423 - val_acc: 0.0000e+00\n",
      "Epoch 182/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7060445241.6577 - acc: 0.0000e+00 - val_loss: 1266701591.9357 - val_acc: 0.0000e+00\n",
      "Epoch 183/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7060075665.6235 - acc: 0.0000e+00 - val_loss: 1266551468.1782 - val_acc: 0.0000e+00\n",
      "Epoch 184/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7059706089.7855 - acc: 0.0000e+00 - val_loss: 1266401415.0592 - val_acc: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7059336453.7498 - acc: 0.0000e+00 - val_loss: 1266251396.0205 - val_acc: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7058966940.9373 - acc: 0.0000e+00 - val_loss: 1266101350.0541 - val_acc: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7058597380.8066 - acc: 0.0000e+00 - val_loss: 1265951324.3769 - val_acc: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7058227961.6547 - acc: 0.0000e+00 - val_loss: 1265801243.1614 - val_acc: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7057858484.0635 - acc: 0.0000e+00 - val_loss: 1265651274.9861 - val_acc: 0.0000e+00\n",
      "Epoch 190/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7057489103.2538 - acc: 0.0000e+00 - val_loss: 1265501249.3090 - val_acc: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7057119676.1998 - acc: 0.0000e+00 - val_loss: 1265351330.1738 - val_acc: 0.0000e+00\n",
      "Epoch 192/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7056750235.8770 - acc: 0.0000e+00 - val_loss: 1265201260.9262 - val_acc: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7056380844.7255 - acc: 0.0000e+00 - val_loss: 1265051323.1848 - val_acc: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7056011497.8683 - acc: 0.0000e+00 - val_loss: 1264901396.2425 - val_acc: 0.0000e+00\n",
      "Epoch 195/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7055642158.8161 - acc: 0.0000e+00 - val_loss: 1264751471.1234 - val_acc: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7055272781.5188 - acc: 0.0000e+00 - val_loss: 1264601556.1490 - val_acc: 0.0000e+00\n",
      "Epoch 197/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 7054903434.3694 - acc: 0.0000e+00 - val_loss: 1264451644.1665 - val_acc: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7054534165.3674 - acc: 0.0000e+00 - val_loss: 1264301672.9993 - val_acc: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7054164865.6320 - acc: 0.0000e+00 - val_loss: 1264151801.0811 - val_acc: 0.0000e+00\n",
      "Epoch 200/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7053795603.2654 - acc: 0.0000e+00 - val_loss: 1264001936.9701 - val_acc: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7053426368.8982 - acc: 0.0000e+00 - val_loss: 1263852045.2768 - val_acc: 0.0000e+00\n",
      "Epoch 202/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7053057163.9954 - acc: 0.0000e+00 - val_loss: 1263702212.9087 - val_acc: 0.0000e+00\n",
      "Epoch 203/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7052687971.3867 - acc: 0.0000e+00 - val_loss: 1263552394.8459 - val_acc: 0.0000e+00\n",
      "Epoch 204/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7052318806.0939 - acc: 0.0000e+00 - val_loss: 1263402448.7831 - val_acc: 0.0000e+00\n",
      "Epoch 205/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7051949639.8266 - acc: 0.0000e+00 - val_loss: 1263252640.8649 - val_acc: 0.0000e+00\n",
      "Epoch 206/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7051580431.3133 - acc: 0.0000e+00 - val_loss: 1263102871.8422 - val_acc: 0.0000e+00\n",
      "Epoch 207/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7051211220.1664 - acc: 0.0000e+00 - val_loss: 1262953066.9160 - val_acc: 0.0000e+00\n",
      "Epoch 208/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7050842071.2644 - acc: 0.0000e+00 - val_loss: 1262803290.0862 - val_acc: 0.0000e+00\n",
      "Epoch 209/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7050473031.1471 - acc: 0.0000e+00 - val_loss: 1262653542.0073 - val_acc: 0.0000e+00\n",
      "Epoch 210/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7050103998.9320 - acc: 0.0000e+00 - val_loss: 1262503798.7436 - val_acc: 0.0000e+00\n",
      "Epoch 211/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7049734877.2499 - acc: 0.0000e+00 - val_loss: 1262354044.6808 - val_acc: 0.0000e+00\n",
      "Epoch 212/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7049365858.5957 - acc: 0.0000e+00 - val_loss: 1262204321.7064 - val_acc: 0.0000e+00\n",
      "Epoch 213/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7048996831.0627 - acc: 0.0000e+00 - val_loss: 1262054595.7400 - val_acc: 0.0000e+00\n",
      "Epoch 214/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7048627878.9473 - acc: 0.0000e+00 - val_loss: 1261904812.4120 - val_acc: 0.0000e+00\n",
      "Epoch 215/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7048258813.8514 - acc: 0.0000e+00 - val_loss: 1261755105.5661 - val_acc: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7047889986.1301 - acc: 0.0000e+00 - val_loss: 1261605435.2783 - val_acc: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7047521025.8182 - acc: 0.0000e+00 - val_loss: 1261455773.3119 - val_acc: 0.0000e+00\n",
      "Epoch 218/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7047152095.5562 - acc: 0.0000e+00 - val_loss: 1261306101.2009 - val_acc: 0.0000e+00\n",
      "Epoch 219/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7046783154.9524 - acc: 0.0000e+00 - val_loss: 1261156445.2184 - val_acc: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 7046414299.1314 - acc: 0.0000e+00 - val_loss: 1261006803.0270 - val_acc: 0.0000e+00\n",
      "Epoch 221/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7046045499.9947 - acc: 0.0000e+00 - val_loss: 1260857187.1088 - val_acc: 0.0000e+00\n",
      "Epoch 222/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7045676622.1242 - acc: 0.0000e+00 - val_loss: 1260707547.2549 - val_acc: 0.0000e+00\n",
      "Epoch 223/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7045307772.1571 - acc: 0.0000e+00 - val_loss: 1260557970.8868 - val_acc: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7044938944.4335 - acc: 0.0000e+00 - val_loss: 1260408372.9204 - val_acc: 0.0000e+00\n",
      "Epoch 225/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7044570116.9051 - acc: 0.0000e+00 - val_loss: 1260258784.5844 - val_acc: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7044201418.3567 - acc: 0.0000e+00 - val_loss: 1260109226.6822 - val_acc: 0.0000e+00\n",
      "Epoch 227/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7043832655.6110 - acc: 0.0000e+00 - val_loss: 1259959632.8766 - val_acc: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7043463954.1346 - acc: 0.0000e+00 - val_loss: 1259810085.7736 - val_acc: 0.0000e+00\n",
      "Epoch 229/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7043095185.5339 - acc: 0.0000e+00 - val_loss: 1259660559.6143 - val_acc: 0.0000e+00\n",
      "Epoch 230/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7042726472.5459 - acc: 0.0000e+00 - val_loss: 1259511012.5113 - val_acc: 0.0000e+00\n",
      "Epoch 231/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7042357791.8513 - acc: 0.0000e+00 - val_loss: 1259361511.4565 - val_acc: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7041989183.6463 - acc: 0.0000e+00 - val_loss: 1259211989.4580 - val_acc: 0.0000e+00\n",
      "Epoch 233/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7041620532.4150 - acc: 0.0000e+00 - val_loss: 1259062532.1140 - val_acc: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7041251824.4012 - acc: 0.0000e+00 - val_loss: 1258913041.2038 - val_acc: 0.0000e+00\n",
      "Epoch 235/1000\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 7040883243.8064 - acc: 0.0000e+00 - val_loss: 1258763567.0767 - val_acc: 0.0000e+00\n",
      "Epoch 236/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7040514685.7484 - acc: 0.0000e+00 - val_loss: 1258614089.9576 - val_acc: 0.0000e+00\n",
      "Epoch 237/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7040146118.6175 - acc: 0.0000e+00 - val_loss: 1258464731.2082 - val_acc: 0.0000e+00\n",
      "Epoch 238/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7039777548.3646 - acc: 0.0000e+00 - val_loss: 1258315282.8400 - val_acc: 0.0000e+00\n",
      "Epoch 239/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7039409049.1373 - acc: 0.0000e+00 - val_loss: 1258165863.7370 - val_acc: 0.0000e+00\n",
      "Epoch 240/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7039040513.8113 - acc: 0.0000e+00 - val_loss: 1258016453.6099 - val_acc: 0.0000e+00\n",
      "Epoch 241/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7038671997.5097 - acc: 0.0000e+00 - val_loss: 1257867035.6757 - val_acc: 0.0000e+00\n",
      "Epoch 242/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7038303575.9437 - acc: 0.0000e+00 - val_loss: 1257717652.4763 - val_acc: 0.0000e+00\n",
      "Epoch 243/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7037935112.9123 - acc: 0.0000e+00 - val_loss: 1257568254.3170 - val_acc: 0.0000e+00\n",
      "Epoch 244/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7037566616.4157 - acc: 0.0000e+00 - val_loss: 1257418892.0614 - val_acc: 0.0000e+00\n",
      "Epoch 245/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7037198202.1665 - acc: 0.0000e+00 - val_loss: 1257269511.1994 - val_acc: 0.0000e+00\n",
      "Epoch 246/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7036829841.5765 - acc: 0.0000e+00 - val_loss: 1257120181.8554 - val_acc: 0.0000e+00\n",
      "Epoch 247/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 7036461471.2311 - acc: 0.0000e+00 - val_loss: 1256970848.8649 - val_acc: 0.0000e+00\n",
      "Epoch 248/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7036093169.7651 - acc: 0.0000e+00 - val_loss: 1256821612.7860 - val_acc: 0.0000e+00\n",
      "Epoch 249/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7035724732.0993 - acc: 0.0000e+00 - val_loss: 1256672286.9481 - val_acc: 0.0000e+00\n",
      "Epoch 250/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7035356375.4119 - acc: 0.0000e+00 - val_loss: 1256522975.5559 - val_acc: 0.0000e+00\n",
      "Epoch 251/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7034988107.1178 - acc: 0.0000e+00 - val_loss: 1256373711.3806 - val_acc: 0.0000e+00\n",
      "Epoch 252/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7034619796.4796 - acc: 0.0000e+00 - val_loss: 1256224422.1008 - val_acc: 0.0000e+00\n",
      "Epoch 253/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7034251542.0385 - acc: 0.0000e+00 - val_loss: 1256075165.0782 - val_acc: 0.0000e+00\n",
      "Epoch 254/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7033883260.9629 - acc: 0.0000e+00 - val_loss: 1255925917.0314 - val_acc: 0.0000e+00\n",
      "Epoch 255/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7033515005.1559 - acc: 0.0000e+00 - val_loss: 1255776738.9686 - val_acc: 0.0000e+00\n",
      "Epoch 256/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7033146786.1301 - acc: 0.0000e+00 - val_loss: 1255627516.6808 - val_acc: 0.0000e+00\n",
      "Epoch 257/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7032778609.6423 - acc: 0.0000e+00 - val_loss: 1255478304.5376 - val_acc: 0.0000e+00\n",
      "Epoch 258/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7032410438.0327 - acc: 0.0000e+00 - val_loss: 1255329068.4587 - val_acc: 0.0000e+00\n",
      "Epoch 259/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7032042311.3998 - acc: 0.0000e+00 - val_loss: 1255179848.5084 - val_acc: 0.0000e+00\n",
      "Epoch 260/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7031674185.5474 - acc: 0.0000e+00 - val_loss: 1255030669.2768 - val_acc: 0.0000e+00\n",
      "Epoch 261/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7031306046.3281 - acc: 0.0000e+00 - val_loss: 1254881589.2944 - val_acc: 0.0000e+00\n",
      "Epoch 262/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7030937913.1578 - acc: 0.0000e+00 - val_loss: 1254732413.0548 - val_acc: 0.0000e+00\n",
      "Epoch 263/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7030569804.3785 - acc: 0.0000e+00 - val_loss: 1254583287.6786 - val_acc: 0.0000e+00\n",
      "Epoch 264/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7030201708.4778 - acc: 0.0000e+00 - val_loss: 1254434154.4953 - val_acc: 0.0000e+00\n",
      "Epoch 265/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7029833703.7992 - acc: 0.0000e+00 - val_loss: 1254285111.5851 - val_acc: 0.0000e+00\n",
      "Epoch 266/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7029465673.2665 - acc: 0.0000e+00 - val_loss: 1254135981.3937 - val_acc: 0.0000e+00\n",
      "Epoch 267/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7029097633.6588 - acc: 0.0000e+00 - val_loss: 1253986862.0015 - val_acc: 0.0000e+00\n",
      "Epoch 268/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7028729693.7628 - acc: 0.0000e+00 - val_loss: 1253837771.2199 - val_acc: 0.0000e+00\n",
      "Epoch 269/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7028361811.2336 - acc: 0.0000e+00 - val_loss: 1253688749.9080 - val_acc: 0.0000e+00\n",
      "Epoch 270/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7027993713.0872 - acc: 0.0000e+00 - val_loss: 1253539687.8773 - val_acc: 0.0000e+00\n",
      "Epoch 271/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7027625802.7527 - acc: 0.0000e+00 - val_loss: 1253390648.6136 - val_acc: 0.0000e+00\n",
      "Epoch 272/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7027257854.2700 - acc: 0.0000e+00 - val_loss: 1253241566.2936 - val_acc: 0.0000e+00\n",
      "Epoch 273/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7026889949.9834 - acc: 0.0000e+00 - val_loss: 1253092638.2469 - val_acc: 0.0000e+00\n",
      "Epoch 274/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7026522129.1149 - acc: 0.0000e+00 - val_loss: 1252943582.2001 - val_acc: 0.0000e+00\n",
      "Epoch 275/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7026154277.3168 - acc: 0.0000e+00 - val_loss: 1252794545.9284 - val_acc: 0.0000e+00\n",
      "Epoch 276/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7025786390.8850 - acc: 0.0000e+00 - val_loss: 1252645532.9379 - val_acc: 0.0000e+00\n",
      "Epoch 277/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7025418689.2389 - acc: 0.0000e+00 - val_loss: 1252496655.7546 - val_acc: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7025050751.5842 - acc: 0.0000e+00 - val_loss: 1252347655.3864 - val_acc: 0.0000e+00\n",
      "Epoch 279/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7024682920.9581 - acc: 0.0000e+00 - val_loss: 1252198692.0906 - val_acc: 0.0000e+00\n",
      "Epoch 280/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7024315194.8218 - acc: 0.0000e+00 - val_loss: 1252049817.2447 - val_acc: 0.0000e+00\n",
      "Epoch 281/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7023947408.7820 - acc: 0.0000e+00 - val_loss: 1251900859.9328 - val_acc: 0.0000e+00\n",
      "Epoch 282/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7023579730.6495 - acc: 0.0000e+00 - val_loss: 1251751902.6209 - val_acc: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7023212080.0279 - acc: 0.0000e+00 - val_loss: 1251603078.6384 - val_acc: 0.0000e+00\n",
      "Epoch 284/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7022844332.0372 - acc: 0.0000e+00 - val_loss: 1251454144.0935 - val_acc: 0.0000e+00\n",
      "Epoch 285/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7022476650.2920 - acc: 0.0000e+00 - val_loss: 1251305265.0869 - val_acc: 0.0000e+00\n",
      "Epoch 286/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7022108910.3015 - acc: 0.0000e+00 - val_loss: 1251156441.1045 - val_acc: 0.0000e+00\n",
      "Epoch 287/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7021741331.6824 - acc: 0.0000e+00 - val_loss: 1251007554.9452 - val_acc: 0.0000e+00\n",
      "Epoch 288/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7021373745.1601 - acc: 0.0000e+00 - val_loss: 1250858659.8101 - val_acc: 0.0000e+00\n",
      "Epoch 289/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7021006128.2946 - acc: 0.0000e+00 - val_loss: 1250709880.7071 - val_acc: 0.0000e+00\n",
      "Epoch 290/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7020638387.5236 - acc: 0.0000e+00 - val_loss: 1250561032.2747 - val_acc: 0.0000e+00\n",
      "Epoch 291/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7020270851.1482 - acc: 0.0000e+00 - val_loss: 1250412228.0672 - val_acc: 0.0000e+00\n",
      "Epoch 292/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7019903337.0186 - acc: 0.0000e+00 - val_loss: 1250263474.0687 - val_acc: 0.0000e+00\n",
      "Epoch 293/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7019535772.3506 - acc: 0.0000e+00 - val_loss: 1250114641.7648 - val_acc: 0.0000e+00\n",
      "Epoch 294/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7019168325.1479 - acc: 0.0000e+00 - val_loss: 1249965833.3966 - val_acc: 0.0000e+00\n",
      "Epoch 295/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7018800773.3574 - acc: 0.0000e+00 - val_loss: 1249817123.1088 - val_acc: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7018433302.7392 - acc: 0.0000e+00 - val_loss: 1249668349.9898 - val_acc: 0.0000e+00\n",
      "Epoch 297/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 7018065817.0973 - acc: 0.0000e+00 - val_loss: 1249519676.7743 - val_acc: 0.0000e+00\n",
      "Epoch 298/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7017698454.2882 - acc: 0.0000e+00 - val_loss: 1249370898.3258 - val_acc: 0.0000e+00\n",
      "Epoch 299/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7017330976.6455 - acc: 0.0000e+00 - val_loss: 1249222129.3674 - val_acc: 0.0000e+00\n",
      "Epoch 300/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7016963574.2253 - acc: 0.0000e+00 - val_loss: 1249073490.2323 - val_acc: 0.0000e+00\n",
      "Epoch 301/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7016596139.5097 - acc: 0.0000e+00 - val_loss: 1248924781.7677 - val_acc: 0.0000e+00\n",
      "Epoch 302/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7016228802.4566 - acc: 0.0000e+00 - val_loss: 1248776140.8093 - val_acc: 0.0000e+00\n",
      "Epoch 303/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7015861507.3572 - acc: 0.0000e+00 - val_loss: 1248627427.5296 - val_acc: 0.0000e+00\n",
      "Epoch 304/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7015494153.7170 - acc: 0.0000e+00 - val_loss: 1248478829.1132 - val_acc: 0.0000e+00\n",
      "Epoch 305/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7015126890.8128 - acc: 0.0000e+00 - val_loss: 1248330175.0183 - val_acc: 0.0000e+00\n",
      "Epoch 306/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7014759523.7087 - acc: 0.0000e+00 - val_loss: 1248181470.7144 - val_acc: 0.0000e+00\n",
      "Epoch 307/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7014392212.0223 - acc: 0.0000e+00 - val_loss: 1248032886.6034 - val_acc: 0.0000e+00\n",
      "Epoch 308/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7014025014.8742 - acc: 0.0000e+00 - val_loss: 1247884233.1629 - val_acc: 0.0000e+00\n",
      "Epoch 309/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7013657766.9937 - acc: 0.0000e+00 - val_loss: 1247735708.8912 - val_acc: 0.0000e+00\n",
      "Epoch 310/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7013290485.6493 - acc: 0.0000e+00 - val_loss: 1247587054.7962 - val_acc: 0.0000e+00\n",
      "Epoch 311/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7012923296.8917 - acc: 0.0000e+00 - val_loss: 1247438538.8459 - val_acc: 0.0000e+00\n",
      "Epoch 312/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7012556118.2819 - acc: 0.0000e+00 - val_loss: 1247289930.2849 - val_acc: 0.0000e+00\n",
      "Epoch 313/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7012188978.4035 - acc: 0.0000e+00 - val_loss: 1247141424.4792 - val_acc: 0.0000e+00\n",
      "Epoch 314/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7011821809.4521 - acc: 0.0000e+00 - val_loss: 1246992821.9021 - val_acc: 0.0000e+00\n",
      "Epoch 315/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7011454637.3774 - acc: 0.0000e+00 - val_loss: 1246844369.4375 - val_acc: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7011087603.6501 - acc: 0.0000e+00 - val_loss: 1246695807.4390 - val_acc: 0.0000e+00\n",
      "Epoch 317/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7010720509.8210 - acc: 0.0000e+00 - val_loss: 1246547336.3682 - val_acc: 0.0000e+00\n",
      "Epoch 318/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7010353416.5783 - acc: 0.0000e+00 - val_loss: 1246398813.9196 - val_acc: 0.0000e+00\n",
      "Epoch 319/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7009986320.9941 - acc: 0.0000e+00 - val_loss: 1246250390.7202 - val_acc: 0.0000e+00\n",
      "Epoch 320/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7009619332.3393 - acc: 0.0000e+00 - val_loss: 1246101860.4646 - val_acc: 0.0000e+00\n",
      "Epoch 321/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7009252353.3439 - acc: 0.0000e+00 - val_loss: 1245953431.2812 - val_acc: 0.0000e+00\n",
      "Epoch 322/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7008885309.2726 - acc: 0.0000e+00 - val_loss: 1245804944.7363 - val_acc: 0.0000e+00\n",
      "Epoch 323/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7008518262.3714 - acc: 0.0000e+00 - val_loss: 1245656553.7940 - val_acc: 0.0000e+00\n",
      "Epoch 324/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7008151343.2794 - acc: 0.0000e+00 - val_loss: 1245508068.4178 - val_acc: 0.0000e+00\n",
      "Epoch 325/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7007784437.7494 - acc: 0.0000e+00 - val_loss: 1245359709.2184 - val_acc: 0.0000e+00\n",
      "Epoch 326/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7007417487.6319 - acc: 0.0000e+00 - val_loss: 1245211388.9145 - val_acc: 0.0000e+00\n",
      "Epoch 327/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7007050623.7602 - acc: 0.0000e+00 - val_loss: 1245062937.6187 - val_acc: 0.0000e+00\n",
      "Epoch 328/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7006683782.3294 - acc: 0.0000e+00 - val_loss: 1244914597.5398 - val_acc: 0.0000e+00\n",
      "Epoch 329/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7006316810.7468 - acc: 0.0000e+00 - val_loss: 1244766183.9708 - val_acc: 0.0000e+00\n",
      "Epoch 330/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7005949972.0478 - acc: 0.0000e+00 - val_loss: 1244617866.0044 - val_acc: 0.0000e+00\n",
      "Epoch 331/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7005583199.8865 - acc: 0.0000e+00 - val_loss: 1244469461.4112 - val_acc: 0.0000e+00\n",
      "Epoch 332/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7005216303.5254 - acc: 0.0000e+00 - val_loss: 1244321157.2359 - val_acc: 0.0000e+00\n",
      "Epoch 333/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7004849484.9225 - acc: 0.0000e+00 - val_loss: 1244172918.8839 - val_acc: 0.0000e+00\n",
      "Epoch 334/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7004482795.5928 - acc: 0.0000e+00 - val_loss: 1244024520.7889 - val_acc: 0.0000e+00\n",
      "Epoch 335/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7004115975.9172 - acc: 0.0000e+00 - val_loss: 1243876270.4690 - val_acc: 0.0000e+00\n",
      "Epoch 336/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7003749238.2926 - acc: 0.0000e+00 - val_loss: 1243727959.7955 - val_acc: 0.0000e+00\n",
      "Epoch 337/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7003382557.3535 - acc: 0.0000e+00 - val_loss: 1243579712.9817 - val_acc: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7003015837.9729 - acc: 0.0000e+00 - val_loss: 1243431475.7984 - val_acc: 0.0000e+00\n",
      "Epoch 339/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7002649161.1304 - acc: 0.0000e+00 - val_loss: 1243283220.1490 - val_acc: 0.0000e+00\n",
      "Epoch 340/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7002282383.9918 - acc: 0.0000e+00 - val_loss: 1243134988.9496 - val_acc: 0.0000e+00\n",
      "Epoch 341/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7001915828.5192 - acc: 0.0000e+00 - val_loss: 1242986796.6457 - val_acc: 0.0000e+00\n",
      "Epoch 342/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7001549187.1890 - acc: 0.0000e+00 - val_loss: 1242838543.3338 - val_acc: 0.0000e+00\n",
      "Epoch 343/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7001182582.2509 - acc: 0.0000e+00 - val_loss: 1242690368.3272 - val_acc: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7000816018.7770 - acc: 0.0000e+00 - val_loss: 1242542199.9591 - val_acc: 0.0000e+00\n",
      "Epoch 345/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7000449404.9599 - acc: 0.0000e+00 - val_loss: 1242393992.1812 - val_acc: 0.0000e+00\n",
      "Epoch 346/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 7000082864.6082 - acc: 0.0000e+00 - val_loss: 1242245845.2710 - val_acc: 0.0000e+00\n",
      "Epoch 347/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6999716341.6240 - acc: 0.0000e+00 - val_loss: 1242097718.7904 - val_acc: 0.0000e+00\n",
      "Epoch 348/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6999349789.2714 - acc: 0.0000e+00 - val_loss: 1241949507.3660 - val_acc: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6998983268.9198 - acc: 0.0000e+00 - val_loss: 1241801425.1103 - val_acc: 0.0000e+00\n",
      "Epoch 350/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6998616893.7440 - acc: 0.0000e+00 - val_loss: 1241653341.0314 - val_acc: 0.0000e+00\n",
      "Epoch 351/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6998250319.2448 - acc: 0.0000e+00 - val_loss: 1241505172.6633 - val_acc: 0.0000e+00\n",
      "Epoch 352/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6997883851.8701 - acc: 0.0000e+00 - val_loss: 1241357090.4076 - val_acc: 0.0000e+00\n",
      "Epoch 353/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6997517502.4512 - acc: 0.0000e+00 - val_loss: 1241209033.9109 - val_acc: 0.0000e+00\n",
      "Epoch 354/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6997151035.6619 - acc: 0.0000e+00 - val_loss: 1241060910.4222 - val_acc: 0.0000e+00\n",
      "Epoch 355/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6996784703.5114 - acc: 0.0000e+00 - val_loss: 1240912868.2308 - val_acc: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6996418258.4773 - acc: 0.0000e+00 - val_loss: 1240764849.9752 - val_acc: 0.0000e+00\n",
      "Epoch 357/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6996051960.7664 - acc: 0.0000e+00 - val_loss: 1240616846.6793 - val_acc: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6995685634.8589 - acc: 0.0000e+00 - val_loss: 1240468754.2790 - val_acc: 0.0000e+00\n",
      "Epoch 359/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6995319326.2208 - acc: 0.0000e+00 - val_loss: 1240320788.0555 - val_acc: 0.0000e+00\n",
      "Epoch 360/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6994953059.7294 - acc: 0.0000e+00 - val_loss: 1240172799.7195 - val_acc: 0.0000e+00\n",
      "Epoch 361/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6994586777.6278 - acc: 0.0000e+00 - val_loss: 1240024828.6808 - val_acc: 0.0000e+00\n",
      "Epoch 362/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6994220444.1102 - acc: 0.0000e+00 - val_loss: 1239876775.1760 - val_acc: 0.0000e+00\n",
      "Epoch 363/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6993854253.9141 - acc: 0.0000e+00 - val_loss: 1239728838.8722 - val_acc: 0.0000e+00\n",
      "Epoch 364/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6993487968.0069 - acc: 0.0000e+00 - val_loss: 1239580899.5763 - val_acc: 0.0000e+00\n",
      "Epoch 365/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6993121752.4430 - acc: 0.0000e+00 - val_loss: 1239433015.9591 - val_acc: 0.0000e+00\n",
      "Epoch 366/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6992755667.5182 - acc: 0.0000e+00 - val_loss: 1239284993.5427 - val_acc: 0.0000e+00\n",
      "Epoch 367/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6992389411.1724 - acc: 0.0000e+00 - val_loss: 1239137113.4317 - val_acc: 0.0000e+00\n",
      "Epoch 368/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6992023285.0744 - acc: 0.0000e+00 - val_loss: 1238989233.9752 - val_acc: 0.0000e+00\n",
      "Epoch 369/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6991657204.5396 - acc: 0.0000e+00 - val_loss: 1238841327.5909 - val_acc: 0.0000e+00\n",
      "Epoch 370/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6991291049.7577 - acc: 0.0000e+00 - val_loss: 1238693467.2549 - val_acc: 0.0000e+00\n",
      "Epoch 371/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6990924912.9276 - acc: 0.0000e+00 - val_loss: 1238545539.9270 - val_acc: 0.0000e+00\n",
      "Epoch 372/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6990558922.0538 - acc: 0.0000e+00 - val_loss: 1238397699.3660 - val_acc: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 6990192865.4205 - acc: 0.0000e+00 - val_loss: 1238249870.1183 - val_acc: 0.0000e+00\n",
      "Epoch 374/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6989826853.4727 - acc: 0.0000e+00 - val_loss: 1238102034.8868 - val_acc: 0.0000e+00\n",
      "Epoch 375/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6989460755.4711 - acc: 0.0000e+00 - val_loss: 1237954275.6231 - val_acc: 0.0000e+00\n",
      "Epoch 376/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6989094800.8901 - acc: 0.0000e+00 - val_loss: 1237806448.1987 - val_acc: 0.0000e+00\n",
      "Epoch 377/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6988728727.1836 - acc: 0.0000e+00 - val_loss: 1237658597.4931 - val_acc: 0.0000e+00\n",
      "Epoch 378/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6988362829.7742 - acc: 0.0000e+00 - val_loss: 1237510809.4785 - val_acc: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6987996933.2434 - acc: 0.0000e+00 - val_loss: 1237363068.1665 - val_acc: 0.0000e+00\n",
      "Epoch 380/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6987631005.9793 - acc: 0.0000e+00 - val_loss: 1237215289.7823 - val_acc: 0.0000e+00\n",
      "Epoch 381/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6987265046.4220 - acc: 0.0000e+00 - val_loss: 1237067533.5106 - val_acc: 0.0000e+00\n",
      "Epoch 382/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6986899132.1334 - acc: 0.0000e+00 - val_loss: 1236919858.0219 - val_acc: 0.0000e+00\n",
      "Epoch 383/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6986533287.1154 - acc: 0.0000e+00 - val_loss: 1236772106.5654 - val_acc: 0.0000e+00\n",
      "Epoch 384/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6986167413.6098 - acc: 0.0000e+00 - val_loss: 1236624419.1088 - val_acc: 0.0000e+00\n",
      "Epoch 385/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6985801652.4972 - acc: 0.0000e+00 - val_loss: 1236476633.5720 - val_acc: 0.0000e+00\n",
      "Epoch 386/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6985435789.1361 - acc: 0.0000e+00 - val_loss: 1236328974.2118 - val_acc: 0.0000e+00\n",
      "Epoch 387/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6985070087.5366 - acc: 0.0000e+00 - val_loss: 1236181275.9562 - val_acc: 0.0000e+00\n",
      "Epoch 388/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6984704261.5432 - acc: 0.0000e+00 - val_loss: 1236033655.4916 - val_acc: 0.0000e+00\n",
      "Epoch 389/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6984338534.1868 - acc: 0.0000e+00 - val_loss: 1235885951.2520 - val_acc: 0.0000e+00\n",
      "Epoch 390/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6983972774.7322 - acc: 0.0000e+00 - val_loss: 1235738366.6910 - val_acc: 0.0000e+00\n",
      "Epoch 391/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6983607076.0596 - acc: 0.0000e+00 - val_loss: 1235590730.6121 - val_acc: 0.0000e+00\n",
      "Epoch 392/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6983241415.3391 - acc: 0.0000e+00 - val_loss: 1235443119.1234 - val_acc: 0.0000e+00\n",
      "Epoch 393/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6982875779.3987 - acc: 0.0000e+00 - val_loss: 1235295519.6026 - val_acc: 0.0000e+00\n",
      "Epoch 394/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6982510056.3351 - acc: 0.0000e+00 - val_loss: 1235147908.1140 - val_acc: 0.0000e+00\n",
      "Epoch 395/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6982144406.6377 - acc: 0.0000e+00 - val_loss: 1235000350.9949 - val_acc: 0.0000e+00\n",
      "Epoch 396/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6981778944.1678 - acc: 0.0000e+00 - val_loss: 1234852796.3535 - val_acc: 0.0000e+00\n",
      "Epoch 397/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6981413296.9100 - acc: 0.0000e+00 - val_loss: 1234705238.0657 - val_acc: 0.0000e+00\n",
      "Epoch 398/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6981047695.3123 - acc: 0.0000e+00 - val_loss: 1234557657.0110 - val_acc: 0.0000e+00\n",
      "Epoch 399/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6980682104.6418 - acc: 0.0000e+00 - val_loss: 1234410186.1446 - val_acc: 0.0000e+00\n",
      "Epoch 400/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6980316655.3415 - acc: 0.0000e+00 - val_loss: 1234262669.7443 - val_acc: 0.0000e+00\n",
      "Epoch 401/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6979951133.4533 - acc: 0.0000e+00 - val_loss: 1234115134.2235 - val_acc: 0.0000e+00\n",
      "Epoch 402/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6979585549.0258 - acc: 0.0000e+00 - val_loss: 1233967638.1125 - val_acc: 0.0000e+00\n",
      "Epoch 403/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6979220122.7507 - acc: 0.0000e+00 - val_loss: 1233820136.6720 - val_acc: 0.0000e+00\n",
      "Epoch 404/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6978854595.5929 - acc: 0.0000e+00 - val_loss: 1233672690.2557 - val_acc: 0.0000e+00\n",
      "Epoch 405/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6978489310.3947 - acc: 0.0000e+00 - val_loss: 1233525218.7348 - val_acc: 0.0000e+00\n",
      "Epoch 406/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6978123740.0164 - acc: 0.0000e+00 - val_loss: 1233377751.3747 - val_acc: 0.0000e+00\n",
      "Epoch 407/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6977758424.8654 - acc: 0.0000e+00 - val_loss: 1233230294.8137 - val_acc: 0.0000e+00\n",
      "Epoch 408/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6977393057.3229 - acc: 0.0000e+00 - val_loss: 1233082912.3974 - val_acc: 0.0000e+00\n",
      "Epoch 409/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6977027744.2201 - acc: 0.0000e+00 - val_loss: 1232935574.2060 - val_acc: 0.0000e+00\n",
      "Epoch 410/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6976662270.8198 - acc: 0.0000e+00 - val_loss: 1232788160.7012 - val_acc: 0.0000e+00\n",
      "Epoch 411/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6976296913.4228 - acc: 0.0000e+00 - val_loss: 1232640743.0358 - val_acc: 0.0000e+00\n",
      "Epoch 412/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6975931734.5686 - acc: 0.0000e+00 - val_loss: 1232493388.7159 - val_acc: 0.0000e+00\n",
      "Epoch 413/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6975566451.2224 - acc: 0.0000e+00 - val_loss: 1232346015.2754 - val_acc: 0.0000e+00\n",
      "Epoch 414/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6975201158.9014 - acc: 0.0000e+00 - val_loss: 1232198641.8349 - val_acc: 0.0000e+00\n",
      "Epoch 415/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6974835922.2880 - acc: 0.0000e+00 - val_loss: 1232051326.4105 - val_acc: 0.0000e+00\n",
      "Epoch 416/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6974470662.4543 - acc: 0.0000e+00 - val_loss: 1231903946.9861 - val_acc: 0.0000e+00\n",
      "Epoch 417/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6974105523.4052 - acc: 0.0000e+00 - val_loss: 1231756746.4251 - val_acc: 0.0000e+00\n",
      "Epoch 418/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6973740295.2804 - acc: 0.0000e+00 - val_loss: 1231609419.0329 - val_acc: 0.0000e+00\n",
      "Epoch 419/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6973375109.1072 - acc: 0.0000e+00 - val_loss: 1231462098.7933 - val_acc: 0.0000e+00\n",
      "Epoch 420/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6973009974.1558 - acc: 0.0000e+00 - val_loss: 1231314830.0716 - val_acc: 0.0000e+00\n",
      "Epoch 421/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6972644802.6172 - acc: 0.0000e+00 - val_loss: 1231167511.6552 - val_acc: 0.0000e+00\n",
      "Epoch 422/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6972279674.2010 - acc: 0.0000e+00 - val_loss: 1231020247.0942 - val_acc: 0.0000e+00\n",
      "Epoch 423/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6971914585.3000 - acc: 0.0000e+00 - val_loss: 1230872978.8868 - val_acc: 0.0000e+00\n",
      "Epoch 424/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6971549384.8813 - acc: 0.0000e+00 - val_loss: 1230725721.4785 - val_acc: 0.0000e+00\n",
      "Epoch 425/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6971184313.7358 - acc: 0.0000e+00 - val_loss: 1230578453.9255 - val_acc: 0.0000e+00\n",
      "Epoch 426/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6970819169.9044 - acc: 0.0000e+00 - val_loss: 1230431312.5493 - val_acc: 0.0000e+00\n",
      "Epoch 427/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6970454142.4667 - acc: 0.0000e+00 - val_loss: 1230284098.1972 - val_acc: 0.0000e+00\n",
      "Epoch 428/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6970088955.4149 - acc: 0.0000e+00 - val_loss: 1230136878.5157 - val_acc: 0.0000e+00\n",
      "Epoch 429/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6969723982.6132 - acc: 0.0000e+00 - val_loss: 1229989652.8503 - val_acc: 0.0000e+00\n",
      "Epoch 430/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6969358898.0028 - acc: 0.0000e+00 - val_loss: 1229842463.6026 - val_acc: 0.0000e+00\n",
      "Epoch 431/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6968993867.8333 - acc: 0.0000e+00 - val_loss: 1229695279.1702 - val_acc: 0.0000e+00\n",
      "Epoch 432/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6968628936.0075 - acc: 0.0000e+00 - val_loss: 1229548119.8422 - val_acc: 0.0000e+00\n",
      "Epoch 433/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6968263882.9098 - acc: 0.0000e+00 - val_loss: 1229400981.4580 - val_acc: 0.0000e+00\n",
      "Epoch 434/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6967899007.2811 - acc: 0.0000e+00 - val_loss: 1229253809.6479 - val_acc: 0.0000e+00\n",
      "Epoch 435/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6967534063.2593 - acc: 0.0000e+00 - val_loss: 1229106700.0146 - val_acc: 0.0000e+00\n",
      "Epoch 436/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6967169252.9997 - acc: 0.0000e+00 - val_loss: 1228959644.0964 - val_acc: 0.0000e+00\n",
      "Epoch 437/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6966804185.6566 - acc: 0.0000e+00 - val_loss: 1228812531.4711 - val_acc: 0.0000e+00\n",
      "Epoch 438/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6966439377.2491 - acc: 0.0000e+00 - val_loss: 1228665411.0387 - val_acc: 0.0000e+00\n",
      "Epoch 439/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6966074438.5927 - acc: 0.0000e+00 - val_loss: 1228518333.6625 - val_acc: 0.0000e+00\n",
      "Epoch 440/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6965709633.8927 - acc: 0.0000e+00 - val_loss: 1228371261.7560 - val_acc: 0.0000e+00\n",
      "Epoch 441/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6965344810.4593 - acc: 0.0000e+00 - val_loss: 1228224181.3879 - val_acc: 0.0000e+00\n",
      "Epoch 442/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6964980002.7342 - acc: 0.0000e+00 - val_loss: 1228077153.7064 - val_acc: 0.0000e+00\n",
      "Epoch 443/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6964615263.7914 - acc: 0.0000e+00 - val_loss: 1227930050.5712 - val_acc: 0.0000e+00\n",
      "Epoch 444/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6964250419.0890 - acc: 0.0000e+00 - val_loss: 1227783159.8656 - val_acc: 0.0000e+00\n",
      "Epoch 445/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6963885658.1937 - acc: 0.0000e+00 - val_loss: 1227636089.6421 - val_acc: 0.0000e+00\n",
      "Epoch 446/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6963520920.0314 - acc: 0.0000e+00 - val_loss: 1227489096.0409 - val_acc: 0.0000e+00\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6963156225.1866 - acc: 0.0000e+00 - val_loss: 1227342087.4799 - val_acc: 0.0000e+00\n",
      "Epoch 448/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6962791546.2454 - acc: 0.0000e+00 - val_loss: 1227195080.0877 - val_acc: 0.0000e+00\n",
      "Epoch 449/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6962426813.4475 - acc: 0.0000e+00 - val_loss: 1227048241.4142 - val_acc: 0.0000e+00\n",
      "Epoch 450/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6962062172.7515 - acc: 0.0000e+00 - val_loss: 1226901226.8692 - val_acc: 0.0000e+00\n",
      "Epoch 451/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6961697639.8635 - acc: 0.0000e+00 - val_loss: 1226754279.3163 - val_acc: 0.0000e+00\n",
      "Epoch 452/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6961332818.3791 - acc: 0.0000e+00 - val_loss: 1226607355.0446 - val_acc: 0.0000e+00\n",
      "Epoch 453/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6960968343.4443 - acc: 0.0000e+00 - val_loss: 1226460391.3630 - val_acc: 0.0000e+00\n",
      "Epoch 454/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6960603740.3089 - acc: 0.0000e+00 - val_loss: 1226313581.9547 - val_acc: 0.0000e+00\n",
      "Epoch 455/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6960239200.8824 - acc: 0.0000e+00 - val_loss: 1226166641.5544 - val_acc: 0.0000e+00\n",
      "Epoch 456/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6959874597.0635 - acc: 0.0000e+00 - val_loss: 1226019741.8729 - val_acc: 0.0000e+00\n",
      "Epoch 457/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6959510072.3698 - acc: 0.0000e+00 - val_loss: 1225872972.5289 - val_acc: 0.0000e+00\n",
      "Epoch 458/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6959145619.1902 - acc: 0.0000e+00 - val_loss: 1225726060.8795 - val_acc: 0.0000e+00\n",
      "Epoch 459/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6958781124.9354 - acc: 0.0000e+00 - val_loss: 1225579221.5515 - val_acc: 0.0000e+00\n",
      "Epoch 460/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6958416666.9746 - acc: 0.0000e+00 - val_loss: 1225432363.7575 - val_acc: 0.0000e+00\n",
      "Epoch 461/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6958052278.0893 - acc: 0.0000e+00 - val_loss: 1225285624.3331 - val_acc: 0.0000e+00\n",
      "Epoch 462/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6957687798.7614 - acc: 0.0000e+00 - val_loss: 1225138774.8605 - val_acc: 0.0000e+00\n",
      "Epoch 463/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6957323398.3635 - acc: 0.0000e+00 - val_loss: 1224991982.2352 - val_acc: 0.0000e+00\n",
      "Epoch 464/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6956959111.3343 - acc: 0.0000e+00 - val_loss: 1224845241.6421 - val_acc: 0.0000e+00\n",
      "Epoch 465/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6956594603.3224 - acc: 0.0000e+00 - val_loss: 1224698444.2016 - val_acc: 0.0000e+00\n",
      "Epoch 466/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6956230241.1687 - acc: 0.0000e+00 - val_loss: 1224551666.5362 - val_acc: 0.0000e+00\n",
      "Epoch 467/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6955865987.3113 - acc: 0.0000e+00 - val_loss: 1224404869.0957 - val_acc: 0.0000e+00\n",
      "Epoch 468/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6955501599.7908 - acc: 0.0000e+00 - val_loss: 1224258220.5990 - val_acc: 0.0000e+00\n",
      "Epoch 469/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6955137309.1512 - acc: 0.0000e+00 - val_loss: 1224111462.0541 - val_acc: 0.0000e+00\n",
      "Epoch 470/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6954773103.6846 - acc: 0.0000e+00 - val_loss: 1223964807.5734 - val_acc: 0.0000e+00\n",
      "Epoch 471/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6954408768.1654 - acc: 0.0000e+00 - val_loss: 1223818099.8919 - val_acc: 0.0000e+00\n",
      "Epoch 472/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6954044570.9913 - acc: 0.0000e+00 - val_loss: 1223671386.2264 - val_acc: 0.0000e+00\n",
      "Epoch 473/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6953680363.6715 - acc: 0.0000e+00 - val_loss: 1223524723.2841 - val_acc: 0.0000e+00\n",
      "Epoch 474/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6953316156.7399 - acc: 0.0000e+00 - val_loss: 1223378047.3455 - val_acc: 0.0000e+00\n",
      "Epoch 475/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6952951950.2971 - acc: 0.0000e+00 - val_loss: 1223231360.6077 - val_acc: 0.0000e+00\n",
      "Epoch 476/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6952587849.0287 - acc: 0.0000e+00 - val_loss: 1223084769.4726 - val_acc: 0.0000e+00\n",
      "Epoch 477/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6952223676.8311 - acc: 0.0000e+00 - val_loss: 1222938097.6947 - val_acc: 0.0000e+00\n",
      "Epoch 478/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6951859568.1461 - acc: 0.0000e+00 - val_loss: 1222791561.0694 - val_acc: 0.0000e+00\n",
      "Epoch 479/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6951495484.3417 - acc: 0.0000e+00 - val_loss: 1222644902.4280 - val_acc: 0.0000e+00\n",
      "Epoch 480/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6951131356.4372 - acc: 0.0000e+00 - val_loss: 1222498288.0117 - val_acc: 0.0000e+00\n",
      "Epoch 481/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6950767308.9250 - acc: 0.0000e+00 - val_loss: 1222351764.5230 - val_acc: 0.0000e+00\n",
      "Epoch 482/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6950403213.7040 - acc: 0.0000e+00 - val_loss: 1222205168.7129 - val_acc: 0.0000e+00\n",
      "Epoch 483/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6950039240.1456 - acc: 0.0000e+00 - val_loss: 1222058655.3689 - val_acc: 0.0000e+00\n",
      "Epoch 484/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6949675262.0988 - acc: 0.0000e+00 - val_loss: 1221912070.8722 - val_acc: 0.0000e+00\n",
      "Epoch 485/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6949311228.1481 - acc: 0.0000e+00 - val_loss: 1221765600.0701 - val_acc: 0.0000e+00\n",
      "Epoch 486/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6948947325.3228 - acc: 0.0000e+00 - val_loss: 1221619059.2841 - val_acc: 0.0000e+00\n",
      "Epoch 487/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6948583345.8130 - acc: 0.0000e+00 - val_loss: 1221472575.8598 - val_acc: 0.0000e+00\n",
      "Epoch 488/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6948219482.2080 - acc: 0.0000e+00 - val_loss: 1221326055.3630 - val_acc: 0.0000e+00\n",
      "Epoch 489/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6947855523.2831 - acc: 0.0000e+00 - val_loss: 1221179623.9708 - val_acc: 0.0000e+00\n",
      "Epoch 490/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6947491691.4846 - acc: 0.0000e+00 - val_loss: 1221033107.1205 - val_acc: 0.0000e+00\n",
      "Epoch 491/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6947127804.3655 - acc: 0.0000e+00 - val_loss: 1220886689.5194 - val_acc: 0.0000e+00\n",
      "Epoch 492/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6946764031.1051 - acc: 0.0000e+00 - val_loss: 1220740218.0628 - val_acc: 0.0000e+00\n",
      "Epoch 493/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6946400104.0838 - acc: 0.0000e+00 - val_loss: 1220593839.3572 - val_acc: 0.0000e+00\n",
      "Epoch 494/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6946036269.7470 - acc: 0.0000e+00 - val_loss: 1220447370.8926 - val_acc: 0.0000e+00\n",
      "Epoch 495/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6945672526.9255 - acc: 0.0000e+00 - val_loss: 1220300984.3798 - val_acc: 0.0000e+00\n",
      "Epoch 496/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6945308860.0101 - acc: 0.0000e+00 - val_loss: 1220154552.4733 - val_acc: 0.0000e+00\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6944945076.1141 - acc: 0.0000e+00 - val_loss: 1220008210.1855 - val_acc: 0.0000e+00\n",
      "Epoch 498/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6944581335.6330 - acc: 0.0000e+00 - val_loss: 1219861893.6567 - val_acc: 0.0000e+00\n",
      "Epoch 499/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6944217585.2004 - acc: 0.0000e+00 - val_loss: 1219715492.8386 - val_acc: 0.0000e+00\n",
      "Epoch 500/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6943854014.0916 - acc: 0.0000e+00 - val_loss: 1219569149.3820 - val_acc: 0.0000e+00\n",
      "Epoch 501/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6943490271.3666 - acc: 0.0000e+00 - val_loss: 1219422770.6764 - val_acc: 0.0000e+00\n",
      "Epoch 502/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6943126632.4511 - acc: 0.0000e+00 - val_loss: 1219276506.8342 - val_acc: 0.0000e+00\n",
      "Epoch 503/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6942762954.8985 - acc: 0.0000e+00 - val_loss: 1219130238.1768 - val_acc: 0.0000e+00\n",
      "Epoch 504/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6942399323.0065 - acc: 0.0000e+00 - val_loss: 1218983889.9050 - val_acc: 0.0000e+00\n",
      "Epoch 505/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6942035698.6259 - acc: 0.0000e+00 - val_loss: 1218837600.3039 - val_acc: 0.0000e+00\n",
      "Epoch 506/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6941672224.5919 - acc: 0.0000e+00 - val_loss: 1218691275.4536 - val_acc: 0.0000e+00\n",
      "Epoch 507/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6941308700.7031 - acc: 0.0000e+00 - val_loss: 1218545049.1980 - val_acc: 0.0000e+00\n",
      "Epoch 508/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6940945087.3478 - acc: 0.0000e+00 - val_loss: 1218398852.3477 - val_acc: 0.0000e+00\n",
      "Epoch 509/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6940581601.5091 - acc: 0.0000e+00 - val_loss: 1218252581.3528 - val_acc: 0.0000e+00\n",
      "Epoch 510/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6940218135.5713 - acc: 0.0000e+00 - val_loss: 1218106373.0489 - val_acc: 0.0000e+00\n",
      "Epoch 511/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6939854670.8060 - acc: 0.0000e+00 - val_loss: 1217960156.4237 - val_acc: 0.0000e+00\n",
      "Epoch 512/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6939491300.9690 - acc: 0.0000e+00 - val_loss: 1217813899.7341 - val_acc: 0.0000e+00\n",
      "Epoch 513/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6939127837.5690 - acc: 0.0000e+00 - val_loss: 1217667778.1972 - val_acc: 0.0000e+00\n",
      "Epoch 514/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6938764413.1941 - acc: 0.0000e+00 - val_loss: 1217521626.2264 - val_acc: 0.0000e+00\n",
      "Epoch 515/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6938400946.5740 - acc: 0.0000e+00 - val_loss: 1217375477.7619 - val_acc: 0.0000e+00\n",
      "Epoch 516/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6938037552.5405 - acc: 0.0000e+00 - val_loss: 1217229256.3214 - val_acc: 0.0000e+00\n",
      "Epoch 517/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6937674274.4140 - acc: 0.0000e+00 - val_loss: 1217083158.7202 - val_acc: 0.0000e+00\n",
      "Epoch 518/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6937310958.4321 - acc: 0.0000e+00 - val_loss: 1216937046.1592 - val_acc: 0.0000e+00\n",
      "Epoch 519/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6936947654.3529 - acc: 0.0000e+00 - val_loss: 1216790951.5500 - val_acc: 0.0000e+00\n",
      "Epoch 520/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6936584351.3470 - acc: 0.0000e+00 - val_loss: 1216644786.9569 - val_acc: 0.0000e+00\n",
      "Epoch 521/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6936221111.2695 - acc: 0.0000e+00 - val_loss: 1216498713.9459 - val_acc: 0.0000e+00\n",
      "Epoch 522/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6935857754.4070 - acc: 0.0000e+00 - val_loss: 1216352689.3207 - val_acc: 0.0000e+00\n",
      "Epoch 523/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6935494587.6973 - acc: 0.0000e+00 - val_loss: 1216206606.6793 - val_acc: 0.0000e+00\n",
      "Epoch 524/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6935131284.3011 - acc: 0.0000e+00 - val_loss: 1216060494.1183 - val_acc: 0.0000e+00\n",
      "Epoch 525/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6934768084.0299 - acc: 0.0000e+00 - val_loss: 1215914486.2761 - val_acc: 0.0000e+00\n",
      "Epoch 526/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6934404949.2232 - acc: 0.0000e+00 - val_loss: 1215768435.8919 - val_acc: 0.0000e+00\n",
      "Epoch 527/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6934041733.6338 - acc: 0.0000e+00 - val_loss: 1215622453.1541 - val_acc: 0.0000e+00\n",
      "Epoch 528/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6933678667.6088 - acc: 0.0000e+00 - val_loss: 1215476358.5449 - val_acc: 0.0000e+00\n",
      "Epoch 529/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6933315500.0205 - acc: 0.0000e+00 - val_loss: 1215330390.7670 - val_acc: 0.0000e+00\n",
      "Epoch 530/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6932952464.8270 - acc: 0.0000e+00 - val_loss: 1215184417.0051 - val_acc: 0.0000e+00\n",
      "Epoch 531/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6932589223.6741 - acc: 0.0000e+00 - val_loss: 1215038469.5164 - val_acc: 0.0000e+00\n",
      "Epoch 532/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6932226230.7249 - acc: 0.0000e+00 - val_loss: 1214892535.8188 - val_acc: 0.0000e+00\n",
      "Epoch 533/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6931863148.2116 - acc: 0.0000e+00 - val_loss: 1214746609.2739 - val_acc: 0.0000e+00\n",
      "Epoch 534/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6931500145.1161 - acc: 0.0000e+00 - val_loss: 1214600580.4879 - val_acc: 0.0000e+00\n",
      "Epoch 535/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6931137122.3122 - acc: 0.0000e+00 - val_loss: 1214454676.7100 - val_acc: 0.0000e+00\n",
      "Epoch 536/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6930774162.8259 - acc: 0.0000e+00 - val_loss: 1214308780.0847 - val_acc: 0.0000e+00\n",
      "Epoch 537/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6930411195.1457 - acc: 0.0000e+00 - val_loss: 1214162909.2184 - val_acc: 0.0000e+00\n",
      "Epoch 538/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6930048266.5873 - acc: 0.0000e+00 - val_loss: 1214017013.7619 - val_acc: 0.0000e+00\n",
      "Epoch 539/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6929685345.5413 - acc: 0.0000e+00 - val_loss: 1213871151.2169 - val_acc: 0.0000e+00\n",
      "Epoch 540/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6929322375.9093 - acc: 0.0000e+00 - val_loss: 1213725286.3346 - val_acc: 0.0000e+00\n",
      "Epoch 541/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6928959539.8418 - acc: 0.0000e+00 - val_loss: 1213579362.7816 - val_acc: 0.0000e+00\n",
      "Epoch 542/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6928596607.7700 - acc: 0.0000e+00 - val_loss: 1213433524.8269 - val_acc: 0.0000e+00\n",
      "Epoch 543/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6928233784.6785 - acc: 0.0000e+00 - val_loss: 1213287718.4748 - val_acc: 0.0000e+00\n",
      "Epoch 544/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6927870896.3166 - acc: 0.0000e+00 - val_loss: 1213141905.6245 - val_acc: 0.0000e+00\n",
      "Epoch 545/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6927508095.6638 - acc: 0.0000e+00 - val_loss: 1212996099.9270 - val_acc: 0.0000e+00\n",
      "Epoch 546/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6927145170.7147 - acc: 0.0000e+00 - val_loss: 1212850319.3338 - val_acc: 0.0000e+00\n",
      "Epoch 547/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6926782466.0653 - acc: 0.0000e+00 - val_loss: 1212704558.5157 - val_acc: 0.0000e+00\n",
      "Epoch 548/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6926419613.3126 - acc: 0.0000e+00 - val_loss: 1212558779.7458 - val_acc: 0.0000e+00\n",
      "Epoch 549/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6926056800.4638 - acc: 0.0000e+00 - val_loss: 1212413026.0804 - val_acc: 0.0000e+00\n",
      "Epoch 550/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6925694049.0811 - acc: 0.0000e+00 - val_loss: 1212267305.3265 - val_acc: 0.0000e+00\n",
      "Epoch 551/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6925331406.6771 - acc: 0.0000e+00 - val_loss: 1212121466.7173 - val_acc: 0.0000e+00\n",
      "Epoch 552/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6924968673.5372 - acc: 0.0000e+00 - val_loss: 1211975748.9554 - val_acc: 0.0000e+00\n",
      "Epoch 553/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6924605978.7412 - acc: 0.0000e+00 - val_loss: 1211830038.3462 - val_acc: 0.0000e+00\n",
      "Epoch 554/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6924243224.7237 - acc: 0.0000e+00 - val_loss: 1211684332.5522 - val_acc: 0.0000e+00\n",
      "Epoch 555/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6923880561.1472 - acc: 0.0000e+00 - val_loss: 1211538641.7180 - val_acc: 0.0000e+00\n",
      "Epoch 556/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6923518021.2817 - acc: 0.0000e+00 - val_loss: 1211392977.1570 - val_acc: 0.0000e+00\n",
      "Epoch 557/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6923155388.7306 - acc: 0.0000e+00 - val_loss: 1211247287.4916 - val_acc: 0.0000e+00\n",
      "Epoch 558/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6922792842.5240 - acc: 0.0000e+00 - val_loss: 1211101662.4806 - val_acc: 0.0000e+00\n",
      "Epoch 559/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6922430204.8004 - acc: 0.0000e+00 - val_loss: 1210956005.0723 - val_acc: 0.0000e+00\n",
      "Epoch 560/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6922067623.9584 - acc: 0.0000e+00 - val_loss: 1210810342.3346 - val_acc: 0.0000e+00\n",
      "Epoch 561/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6921705150.5342 - acc: 0.0000e+00 - val_loss: 1210664734.6209 - val_acc: 0.0000e+00\n",
      "Epoch 562/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6921342625.3022 - acc: 0.0000e+00 - val_loss: 1210519129.8992 - val_acc: 0.0000e+00\n",
      "Epoch 563/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6920980144.3645 - acc: 0.0000e+00 - val_loss: 1210373517.3703 - val_acc: 0.0000e+00\n",
      "Epoch 564/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6920617640.2064 - acc: 0.0000e+00 - val_loss: 1210227950.3755 - val_acc: 0.0000e+00\n",
      "Epoch 565/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6920255240.4422 - acc: 0.0000e+00 - val_loss: 1210082403.6698 - val_acc: 0.0000e+00\n",
      "Epoch 566/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6919892725.5520 - acc: 0.0000e+00 - val_loss: 1209936839.6669 - val_acc: 0.0000e+00\n",
      "Epoch 567/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6919530319.8353 - acc: 0.0000e+00 - val_loss: 1209791279.1702 - val_acc: 0.0000e+00\n",
      "Epoch 568/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6919167937.0467 - acc: 0.0000e+00 - val_loss: 1209645765.3762 - val_acc: 0.0000e+00\n",
      "Epoch 569/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6918805589.7709 - acc: 0.0000e+00 - val_loss: 1209500223.4858 - val_acc: 0.0000e+00\n",
      "Epoch 570/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6918443216.5425 - acc: 0.0000e+00 - val_loss: 1209354703.7078 - val_acc: 0.0000e+00\n",
      "Epoch 571/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6918080900.9752 - acc: 0.0000e+00 - val_loss: 1209209209.0343 - val_acc: 0.0000e+00\n",
      "Epoch 572/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6917718593.2114 - acc: 0.0000e+00 - val_loss: 1209063817.2564 - val_acc: 0.0000e+00\n",
      "Epoch 573/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6917356199.1053 - acc: 0.0000e+00 - val_loss: 1208918311.7838 - val_acc: 0.0000e+00\n",
      "Epoch 574/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6916993984.0276 - acc: 0.0000e+00 - val_loss: 1208772853.0139 - val_acc: 0.0000e+00\n",
      "Epoch 575/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6916631805.2449 - acc: 0.0000e+00 - val_loss: 1208627412.1958 - val_acc: 0.0000e+00\n",
      "Epoch 576/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6916269492.8955 - acc: 0.0000e+00 - val_loss: 1208481950.4339 - val_acc: 0.0000e+00\n",
      "Epoch 577/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6915907462.7022 - acc: 0.0000e+00 - val_loss: 1208336518.5917 - val_acc: 0.0000e+00\n",
      "Epoch 578/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6915545230.3556 - acc: 0.0000e+00 - val_loss: 1208191087.9182 - val_acc: 0.0000e+00\n",
      "Epoch 579/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6915183016.4481 - acc: 0.0000e+00 - val_loss: 1208045680.0117 - val_acc: 0.0000e+00\n",
      "Epoch 580/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6914820892.8851 - acc: 0.0000e+00 - val_loss: 1207900393.4668 - val_acc: 0.0000e+00\n",
      "Epoch 581/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6914458751.5660 - acc: 0.0000e+00 - val_loss: 1207754991.5442 - val_acc: 0.0000e+00\n",
      "Epoch 582/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6914096597.2692 - acc: 0.0000e+00 - val_loss: 1207609644.6457 - val_acc: 0.0000e+00\n",
      "Epoch 583/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6913734483.3646 - acc: 0.0000e+00 - val_loss: 1207464276.8035 - val_acc: 0.0000e+00\n",
      "Epoch 584/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6913372473.6581 - acc: 0.0000e+00 - val_loss: 1207318923.9211 - val_acc: 0.0000e+00\n",
      "Epoch 585/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6913010394.9736 - acc: 0.0000e+00 - val_loss: 1207173688.2396 - val_acc: 0.0000e+00\n",
      "Epoch 586/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6912648370.9252 - acc: 0.0000e+00 - val_loss: 1207028319.7429 - val_acc: 0.0000e+00\n",
      "Epoch 587/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6912286409.3179 - acc: 0.0000e+00 - val_loss: 1206883006.9248 - val_acc: 0.0000e+00\n",
      "Epoch 588/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6911924429.4656 - acc: 0.0000e+00 - val_loss: 1206737692.9379 - val_acc: 0.0000e+00\n",
      "Epoch 589/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6911562399.9535 - acc: 0.0000e+00 - val_loss: 1206592508.1198 - val_acc: 0.0000e+00\n",
      "Epoch 590/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6911200485.3712 - acc: 0.0000e+00 - val_loss: 1206447200.6311 - val_acc: 0.0000e+00\n",
      "Epoch 591/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6910838583.8630 - acc: 0.0000e+00 - val_loss: 1206301980.5639 - val_acc: 0.0000e+00\n",
      "Epoch 592/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6910476617.6691 - acc: 0.0000e+00 - val_loss: 1206156695.8422 - val_acc: 0.0000e+00\n",
      "Epoch 593/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6910114656.5480 - acc: 0.0000e+00 - val_loss: 1206011545.1045 - val_acc: 0.0000e+00\n",
      "Epoch 594/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6909752777.0882 - acc: 0.0000e+00 - val_loss: 1205866292.1256 - val_acc: 0.0000e+00\n",
      "Epoch 595/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6909390999.8753 - acc: 0.0000e+00 - val_loss: 1205721065.4200 - val_acc: 0.0000e+00\n",
      "Epoch 596/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6909029198.2719 - acc: 0.0000e+00 - val_loss: 1205575823.7546 - val_acc: 0.0000e+00\n",
      "Epoch 597/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6908667284.2732 - acc: 0.0000e+00 - val_loss: 1205430734.0248 - val_acc: 0.0000e+00\n",
      "Epoch 598/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6908305528.4269 - acc: 0.0000e+00 - val_loss: 1205285549.2067 - val_acc: 0.0000e+00\n",
      "Epoch 599/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6907943672.7723 - acc: 0.0000e+00 - val_loss: 1205140361.3966 - val_acc: 0.0000e+00\n",
      "Epoch 600/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6907581909.7062 - acc: 0.0000e+00 - val_loss: 1204995267.5062 - val_acc: 0.0000e+00\n",
      "Epoch 601/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6907220191.4216 - acc: 0.0000e+00 - val_loss: 1204850116.7684 - val_acc: 0.0000e+00\n",
      "Epoch 602/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6906858490.5024 - acc: 0.0000e+00 - val_loss: 1204704961.8700 - val_acc: 0.0000e+00\n",
      "Epoch 603/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6906496742.8503 - acc: 0.0000e+00 - val_loss: 1204559893.0840 - val_acc: 0.0000e+00\n",
      "Epoch 604/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6906135081.6403 - acc: 0.0000e+00 - val_loss: 1204414803.3543 - val_acc: 0.0000e+00\n",
      "Epoch 605/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6905773426.3812 - acc: 0.0000e+00 - val_loss: 1204269687.3514 - val_acc: 0.0000e+00\n",
      "Epoch 606/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6905411725.0722 - acc: 0.0000e+00 - val_loss: 1204124675.4127 - val_acc: 0.0000e+00\n",
      "Epoch 607/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6905050070.7881 - acc: 0.0000e+00 - val_loss: 1203979568.8999 - val_acc: 0.0000e+00\n",
      "Epoch 608/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6904688537.9717 - acc: 0.0000e+00 - val_loss: 1203834469.0256 - val_acc: 0.0000e+00\n",
      "Epoch 609/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6904326877.5416 - acc: 0.0000e+00 - val_loss: 1203689485.1833 - val_acc: 0.0000e+00\n",
      "Epoch 610/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6903965247.5505 - acc: 0.0000e+00 - val_loss: 1203544444.4938 - val_acc: 0.0000e+00\n",
      "Epoch 611/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6903603640.8778 - acc: 0.0000e+00 - val_loss: 1203399484.5873 - val_acc: 0.0000e+00\n",
      "Epoch 612/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6903242132.1586 - acc: 0.0000e+00 - val_loss: 1203254444.5522 - val_acc: 0.0000e+00\n",
      "Epoch 613/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6902880666.7591 - acc: 0.0000e+00 - val_loss: 1203109406.8546 - val_acc: 0.0000e+00\n",
      "Epoch 614/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6902519198.3334 - acc: 0.0000e+00 - val_loss: 1202964472.0526 - val_acc: 0.0000e+00\n",
      "Epoch 615/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6902157638.4905 - acc: 0.0000e+00 - val_loss: 1202819482.2264 - val_acc: 0.0000e+00\n",
      "Epoch 616/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6901796168.3098 - acc: 0.0000e+00 - val_loss: 1202674581.5047 - val_acc: 0.0000e+00\n",
      "Epoch 617/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6901434786.8128 - acc: 0.0000e+00 - val_loss: 1202529605.4697 - val_acc: 0.0000e+00\n",
      "Epoch 618/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6901073331.4608 - acc: 0.0000e+00 - val_loss: 1202384602.5069 - val_acc: 0.0000e+00\n",
      "Epoch 619/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6900711895.6216 - acc: 0.0000e+00 - val_loss: 1202239740.6808 - val_acc: 0.0000e+00\n",
      "Epoch 620/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6900350545.0530 - acc: 0.0000e+00 - val_loss: 1202094811.8627 - val_acc: 0.0000e+00\n",
      "Epoch 621/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6899989047.6502 - acc: 0.0000e+00 - val_loss: 1201949954.1972 - val_acc: 0.0000e+00\n",
      "Epoch 622/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6899627851.1352 - acc: 0.0000e+00 - val_loss: 1201805027.2023 - val_acc: 0.0000e+00\n",
      "Epoch 623/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6899266453.5401 - acc: 0.0000e+00 - val_loss: 1201660206.6092 - val_acc: 0.0000e+00\n",
      "Epoch 624/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6898905036.0419 - acc: 0.0000e+00 - val_loss: 1201515327.4858 - val_acc: 0.0000e+00\n",
      "Epoch 625/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6898543820.4037 - acc: 0.0000e+00 - val_loss: 1201370517.6917 - val_acc: 0.0000e+00\n",
      "Epoch 626/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6898182566.4228 - acc: 0.0000e+00 - val_loss: 1201225624.7772 - val_acc: 0.0000e+00\n",
      "Epoch 627/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6897821304.4416 - acc: 0.0000e+00 - val_loss: 1201080734.8546 - val_acc: 0.0000e+00\n",
      "Epoch 628/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6897460034.3620 - acc: 0.0000e+00 - val_loss: 1200935971.1088 - val_acc: 0.0000e+00\n",
      "Epoch 629/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6897098781.2585 - acc: 0.0000e+00 - val_loss: 1200791124.2425 - val_acc: 0.0000e+00\n",
      "Epoch 630/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6896737664.0617 - acc: 0.0000e+00 - val_loss: 1200646405.3762 - val_acc: 0.0000e+00\n",
      "Epoch 631/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6896376431.3486 - acc: 0.0000e+00 - val_loss: 1200501570.4777 - val_acc: 0.0000e+00\n",
      "Epoch 632/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6896015304.3953 - acc: 0.0000e+00 - val_loss: 1200356831.8364 - val_acc: 0.0000e+00\n",
      "Epoch 633/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6895654077.5356 - acc: 0.0000e+00 - val_loss: 1200212156.6808 - val_acc: 0.0000e+00\n",
      "Epoch 634/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6895292918.0929 - acc: 0.0000e+00 - val_loss: 1200067346.8868 - val_acc: 0.0000e+00\n",
      "Epoch 635/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6894931952.2177 - acc: 0.0000e+00 - val_loss: 1199922660.9321 - val_acc: 0.0000e+00\n",
      "Epoch 636/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6894570754.1389 - acc: 0.0000e+00 - val_loss: 1199777915.1381 - val_acc: 0.0000e+00\n",
      "Epoch 637/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6894209702.4066 - acc: 0.0000e+00 - val_loss: 1199633266.2557 - val_acc: 0.0000e+00\n",
      "Epoch 638/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6893848687.1633 - acc: 0.0000e+00 - val_loss: 1199488500.1724 - val_acc: 0.0000e+00\n",
      "Epoch 639/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6893487719.5304 - acc: 0.0000e+00 - val_loss: 1199343827.3543 - val_acc: 0.0000e+00\n",
      "Epoch 640/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6893126575.5011 - acc: 0.0000e+00 - val_loss: 1199199129.4317 - val_acc: 0.0000e+00\n",
      "Epoch 641/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6892765626.4065 - acc: 0.0000e+00 - val_loss: 1199054498.5011 - val_acc: 0.0000e+00\n",
      "Epoch 642/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6892404700.8232 - acc: 0.0000e+00 - val_loss: 1198909893.8437 - val_acc: 0.0000e+00\n",
      "Epoch 643/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6892043648.9928 - acc: 0.0000e+00 - val_loss: 1198765219.8568 - val_acc: 0.0000e+00\n",
      "Epoch 644/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6891682742.2394 - acc: 0.0000e+00 - val_loss: 1198620633.1512 - val_acc: 0.0000e+00\n",
      "Epoch 645/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6891321842.9009 - acc: 0.0000e+00 - val_loss: 1198475963.9795 - val_acc: 0.0000e+00\n",
      "Epoch 646/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6890960909.1222 - acc: 0.0000e+00 - val_loss: 1198331364.1373 - val_acc: 0.0000e+00\n",
      "Epoch 647/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6890599947.8304 - acc: 0.0000e+00 - val_loss: 1198186855.2228 - val_acc: 0.0000e+00\n",
      "Epoch 648/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6890239181.9588 - acc: 0.0000e+00 - val_loss: 1198042211.1556 - val_acc: 0.0000e+00\n",
      "Epoch 649/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6889878265.4489 - acc: 0.0000e+00 - val_loss: 1197897677.6508 - val_acc: 0.0000e+00\n",
      "Epoch 650/1000\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 6889517424.7455 - acc: 0.0000e+00 - val_loss: 1197753063.5033 - val_acc: 0.0000e+00\n",
      "Epoch 651/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6889156657.6050 - acc: 0.0000e+00 - val_loss: 1197608551.5968 - val_acc: 0.0000e+00\n",
      "Epoch 652/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6888795925.6858 - acc: 0.0000e+00 - val_loss: 1197464037.8671 - val_acc: 0.0000e+00\n",
      "Epoch 653/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6888435065.6641 - acc: 0.0000e+00 - val_loss: 1197319490.7115 - val_acc: 0.0000e+00\n",
      "Epoch 654/1000\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 6888074309.7435 - acc: 0.0000e+00 - val_loss: 1197175014.7085 - val_acc: 0.0000e+00\n",
      "Epoch 655/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6887713604.0685 - acc: 0.0000e+00 - val_loss: 1197030541.0431 - val_acc: 0.0000e+00\n",
      "Epoch 656/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6887352832.1474 - acc: 0.0000e+00 - val_loss: 1196886002.2089 - val_acc: 0.0000e+00\n",
      "Epoch 657/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6886992078.7624 - acc: 0.0000e+00 - val_loss: 1196741565.1015 - val_acc: 0.0000e+00\n",
      "Epoch 658/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6886631430.0644 - acc: 0.0000e+00 - val_loss: 1196597113.5486 - val_acc: 0.0000e+00\n",
      "Epoch 659/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6886270749.7551 - acc: 0.0000e+00 - val_loss: 1196452604.1198 - val_acc: 0.0000e+00\n",
      "Epoch 660/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6885910063.2992 - acc: 0.0000e+00 - val_loss: 1196308212.4061 - val_acc: 0.0000e+00\n",
      "Epoch 661/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6885549503.2861 - acc: 0.0000e+00 - val_loss: 1196163779.4595 - val_acc: 0.0000e+00\n",
      "Epoch 662/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6885188962.0060 - acc: 0.0000e+00 - val_loss: 1196019334.5449 - val_acc: 0.0000e+00\n",
      "Epoch 663/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6884828291.4520 - acc: 0.0000e+00 - val_loss: 1195874947.6465 - val_acc: 0.0000e+00\n",
      "Epoch 664/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6884467772.6105 - acc: 0.0000e+00 - val_loss: 1195730593.0051 - val_acc: 0.0000e+00\n",
      "Epoch 665/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6884107156.3028 - acc: 0.0000e+00 - val_loss: 1195586153.5603 - val_acc: 0.0000e+00\n",
      "Epoch 666/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6883746671.4131 - acc: 0.0000e+00 - val_loss: 1195441788.7743 - val_acc: 0.0000e+00\n",
      "Epoch 667/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6883386100.0820 - acc: 0.0000e+00 - val_loss: 1195297449.0928 - val_acc: 0.0000e+00\n",
      "Epoch 668/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6883025548.2633 - acc: 0.0000e+00 - val_loss: 1195153145.9693 - val_acc: 0.0000e+00\n",
      "Epoch 669/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6882665190.7915 - acc: 0.0000e+00 - val_loss: 1195008739.9503 - val_acc: 0.0000e+00\n",
      "Epoch 670/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6882304579.0688 - acc: 0.0000e+00 - val_loss: 1194864478.0599 - val_acc: 0.0000e+00\n",
      "Epoch 671/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6881944273.1110 - acc: 0.0000e+00 - val_loss: 1194720179.0972 - val_acc: 0.0000e+00\n",
      "Epoch 672/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6881583785.8798 - acc: 0.0000e+00 - val_loss: 1194575899.2549 - val_acc: 0.0000e+00\n",
      "Epoch 673/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6881223365.6742 - acc: 0.0000e+00 - val_loss: 1194431529.1395 - val_acc: 0.0000e+00\n",
      "Epoch 674/1000\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 6880863081.8624 - acc: 0.0000e+00 - val_loss: 1194287298.3375 - val_acc: 0.0000e+00\n",
      "Epoch 675/1000\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 6880502653.4619 - acc: 0.0000e+00 - val_loss: 1194143050.2381 - val_acc: 0.0000e+00\n",
      "Epoch 676/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6880142300.8673 - acc: 0.0000e+00 - val_loss: 1193998849.3557 - val_acc: 0.0000e+00\n",
      "Epoch 677/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6879781998.9097 - acc: 0.0000e+00 - val_loss: 1193854608.4091 - val_acc: 0.0000e+00\n",
      "Epoch 678/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6879421648.2658 - acc: 0.0000e+00 - val_loss: 1193710342.3579 - val_acc: 0.0000e+00\n",
      "Epoch 679/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6879061402.5046 - acc: 0.0000e+00 - val_loss: 1193566131.3309 - val_acc: 0.0000e+00\n",
      "Epoch 680/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6878701135.0836 - acc: 0.0000e+00 - val_loss: 1193421957.3762 - val_acc: 0.0000e+00\n",
      "Epoch 681/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6878340793.4157 - acc: 0.0000e+00 - val_loss: 1193277793.5661 - val_acc: 0.0000e+00\n",
      "Epoch 682/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6877980616.1436 - acc: 0.0000e+00 - val_loss: 1193133595.6757 - val_acc: 0.0000e+00\n",
      "Epoch 683/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6877620363.9415 - acc: 0.0000e+00 - val_loss: 1192989375.6728 - val_acc: 0.0000e+00\n",
      "Epoch 684/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6877260161.3997 - acc: 0.0000e+00 - val_loss: 1192845216.6779 - val_acc: 0.0000e+00\n",
      "Epoch 685/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6876899942.1750 - acc: 0.0000e+00 - val_loss: 1192701129.4901 - val_acc: 0.0000e+00\n",
      "Epoch 686/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6876539813.5864 - acc: 0.0000e+00 - val_loss: 1192556974.6560 - val_acc: 0.0000e+00\n",
      "Epoch 687/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6876179689.4863 - acc: 0.0000e+00 - val_loss: 1192412883.8218 - val_acc: 0.0000e+00\n",
      "Epoch 688/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6875819511.9198 - acc: 0.0000e+00 - val_loss: 1192268796.6340 - val_acc: 0.0000e+00\n",
      "Epoch 689/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6875459486.5537 - acc: 0.0000e+00 - val_loss: 1192124681.8641 - val_acc: 0.0000e+00\n",
      "Epoch 690/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6875099308.8892 - acc: 0.0000e+00 - val_loss: 1191980564.7568 - val_acc: 0.0000e+00\n",
      "Epoch 691/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6874739336.5986 - acc: 0.0000e+00 - val_loss: 1191836502.6735 - val_acc: 0.0000e+00\n",
      "Epoch 692/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6874379226.9358 - acc: 0.0000e+00 - val_loss: 1191692447.7429 - val_acc: 0.0000e+00\n",
      "Epoch 693/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6874019208.3992 - acc: 0.0000e+00 - val_loss: 1191548408.9408 - val_acc: 0.0000e+00\n",
      "Epoch 694/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6873659237.4729 - acc: 0.0000e+00 - val_loss: 1191404357.6567 - val_acc: 0.0000e+00\n",
      "Epoch 695/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6873299244.8874 - acc: 0.0000e+00 - val_loss: 1191260384.6779 - val_acc: 0.0000e+00\n",
      "Epoch 696/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6872939300.5961 - acc: 0.0000e+00 - val_loss: 1191116356.6749 - val_acc: 0.0000e+00\n",
      "Epoch 697/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6872579332.8889 - acc: 0.0000e+00 - val_loss: 1190972392.6720 - val_acc: 0.0000e+00\n",
      "Epoch 698/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6872219387.7190 - acc: 0.0000e+00 - val_loss: 1190828395.7575 - val_acc: 0.0000e+00\n",
      "Epoch 699/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6871859426.8418 - acc: 0.0000e+00 - val_loss: 1190684442.5537 - val_acc: 0.0000e+00\n",
      "Epoch 700/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6871499590.3575 - acc: 0.0000e+00 - val_loss: 1190540473.7356 - val_acc: 0.0000e+00\n",
      "Epoch 701/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6871139675.4320 - acc: 0.0000e+00 - val_loss: 1190396537.8291 - val_acc: 0.0000e+00\n",
      "Epoch 702/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6870779904.5115 - acc: 0.0000e+00 - val_loss: 1190252490.7056 - val_acc: 0.0000e+00\n",
      "Epoch 703/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6870419956.9989 - acc: 0.0000e+00 - val_loss: 1190108583.5500 - val_acc: 0.0000e+00\n",
      "Epoch 704/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6870060215.4447 - acc: 0.0000e+00 - val_loss: 1189964671.5793 - val_acc: 0.0000e+00\n",
      "Epoch 705/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6869700396.0341 - acc: 0.0000e+00 - val_loss: 1189820788.3594 - val_acc: 0.0000e+00\n",
      "Epoch 706/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6869340573.3064 - acc: 0.0000e+00 - val_loss: 1189676889.5252 - val_acc: 0.0000e+00\n",
      "Epoch 707/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6868980821.8971 - acc: 0.0000e+00 - val_loss: 1189533013.4580 - val_acc: 0.0000e+00\n",
      "Epoch 708/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6868621100.1478 - acc: 0.0000e+00 - val_loss: 1189389136.7363 - val_acc: 0.0000e+00\n",
      "Epoch 709/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6868261270.4919 - acc: 0.0000e+00 - val_loss: 1189245291.7575 - val_acc: 0.0000e+00\n",
      "Epoch 710/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6867901696.1618 - acc: 0.0000e+00 - val_loss: 1189101415.6903 - val_acc: 0.0000e+00\n",
      "Epoch 711/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6867541909.7263 - acc: 0.0000e+00 - val_loss: 1188957609.6070 - val_acc: 0.0000e+00\n",
      "Epoch 712/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6867182311.3954 - acc: 0.0000e+00 - val_loss: 1188813760.4675 - val_acc: 0.0000e+00\n",
      "Epoch 713/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6866822583.8893 - acc: 0.0000e+00 - val_loss: 1188669973.5047 - val_acc: 0.0000e+00\n",
      "Epoch 714/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6866462985.4587 - acc: 0.0000e+00 - val_loss: 1188526153.6304 - val_acc: 0.0000e+00\n",
      "Epoch 715/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6866103350.4430 - acc: 0.0000e+00 - val_loss: 1188382383.4507 - val_acc: 0.0000e+00\n",
      "Epoch 716/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6865743811.3320 - acc: 0.0000e+00 - val_loss: 1188238607.2871 - val_acc: 0.0000e+00\n",
      "Epoch 717/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6865384123.2408 - acc: 0.0000e+00 - val_loss: 1188094927.3806 - val_acc: 0.0000e+00\n",
      "Epoch 718/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6865024633.3028 - acc: 0.0000e+00 - val_loss: 1187951069.2652 - val_acc: 0.0000e+00\n",
      "Epoch 719/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6864665063.4584 - acc: 0.0000e+00 - val_loss: 1187807429.4229 - val_acc: 0.0000e+00\n",
      "Epoch 720/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6864305528.6397 - acc: 0.0000e+00 - val_loss: 1187663683.1790 - val_acc: 0.0000e+00\n",
      "Epoch 721/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6863945974.8935 - acc: 0.0000e+00 - val_loss: 1187519964.3769 - val_acc: 0.0000e+00\n",
      "Epoch 722/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6863586534.3219 - acc: 0.0000e+00 - val_loss: 1187376251.0446 - val_acc: 0.0000e+00\n",
      "Epoch 723/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6863226972.6724 - acc: 0.0000e+00 - val_loss: 1187232568.1461 - val_acc: 0.0000e+00\n",
      "Epoch 724/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6862867616.1031 - acc: 0.0000e+00 - val_loss: 1187088857.1512 - val_acc: 0.0000e+00\n",
      "Epoch 725/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6862508115.8216 - acc: 0.0000e+00 - val_loss: 1186945177.8992 - val_acc: 0.0000e+00\n",
      "Epoch 726/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6862148667.3467 - acc: 0.0000e+00 - val_loss: 1186801527.9123 - val_acc: 0.0000e+00\n",
      "Epoch 727/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6861789327.7526 - acc: 0.0000e+00 - val_loss: 1186657848.0058 - val_acc: 0.0000e+00\n",
      "Epoch 728/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6861429915.7662 - acc: 0.0000e+00 - val_loss: 1186514245.8904 - val_acc: 0.0000e+00\n",
      "Epoch 729/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6861070520.8525 - acc: 0.0000e+00 - val_loss: 1186370561.8232 - val_acc: 0.0000e+00\n",
      "Epoch 730/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6860711185.3560 - acc: 0.0000e+00 - val_loss: 1186226965.6917 - val_acc: 0.0000e+00\n",
      "Epoch 731/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6860351895.6172 - acc: 0.0000e+00 - val_loss: 1186083327.6728 - val_acc: 0.0000e+00\n",
      "Epoch 732/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6859992499.9230 - acc: 0.0000e+00 - val_loss: 1185939832.6136 - val_acc: 0.0000e+00\n",
      "Epoch 733/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6859633177.6947 - acc: 0.0000e+00 - val_loss: 1185796221.5223 - val_acc: 0.0000e+00\n",
      "Epoch 734/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6859273878.8813 - acc: 0.0000e+00 - val_loss: 1185652662.4631 - val_acc: 0.0000e+00\n",
      "Epoch 735/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6858914750.5133 - acc: 0.0000e+00 - val_loss: 1185509060.3477 - val_acc: 0.0000e+00\n",
      "Epoch 736/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6858555489.0665 - acc: 0.0000e+00 - val_loss: 1185365510.2644 - val_acc: 0.0000e+00\n",
      "Epoch 737/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6858196158.3490 - acc: 0.0000e+00 - val_loss: 1185221985.2856 - val_acc: 0.0000e+00\n",
      "Epoch 738/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6857837089.0064 - acc: 0.0000e+00 - val_loss: 1185078431.0416 - val_acc: 0.0000e+00\n",
      "Epoch 739/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6857477814.8762 - acc: 0.0000e+00 - val_loss: 1184935053.1833 - val_acc: 0.0000e+00\n",
      "Epoch 740/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6857118718.6052 - acc: 0.0000e+00 - val_loss: 1184791515.0679 - val_acc: 0.0000e+00\n",
      "Epoch 741/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6856759622.7240 - acc: 0.0000e+00 - val_loss: 1184648021.8320 - val_acc: 0.0000e+00\n",
      "Epoch 742/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6856400459.8171 - acc: 0.0000e+00 - val_loss: 1184504536.9175 - val_acc: 0.0000e+00\n",
      "Epoch 743/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6856041414.8634 - acc: 0.0000e+00 - val_loss: 1184361059.8101 - val_acc: 0.0000e+00\n",
      "Epoch 744/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6855682214.5888 - acc: 0.0000e+00 - val_loss: 1184217693.4054 - val_acc: 0.0000e+00\n",
      "Epoch 745/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6855323142.7084 - acc: 0.0000e+00 - val_loss: 1184074226.4427 - val_acc: 0.0000e+00\n",
      "Epoch 746/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6854964043.0210 - acc: 0.0000e+00 - val_loss: 1183930786.4076 - val_acc: 0.0000e+00\n",
      "Epoch 747/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6854605072.6075 - acc: 0.0000e+00 - val_loss: 1183787383.4449 - val_acc: 0.0000e+00\n",
      "Epoch 748/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6854246100.2416 - acc: 0.0000e+00 - val_loss: 1183643948.2250 - val_acc: 0.0000e+00\n",
      "Epoch 749/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6853886994.5052 - acc: 0.0000e+00 - val_loss: 1183500630.2060 - val_acc: 0.0000e+00\n",
      "Epoch 750/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6853528106.8246 - acc: 0.0000e+00 - val_loss: 1183357211.1147 - val_acc: 0.0000e+00\n",
      "Epoch 751/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6853169179.2412 - acc: 0.0000e+00 - val_loss: 1183213823.7663 - val_acc: 0.0000e+00\n",
      "Epoch 752/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6852810189.1175 - acc: 0.0000e+00 - val_loss: 1183070469.8437 - val_acc: 0.0000e+00\n",
      "Epoch 753/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6852451300.3631 - acc: 0.0000e+00 - val_loss: 1182927166.7845 - val_acc: 0.0000e+00\n",
      "Epoch 754/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6852092287.0196 - acc: 0.0000e+00 - val_loss: 1182783839.7896 - val_acc: 0.0000e+00\n",
      "Epoch 755/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6851733446.6571 - acc: 0.0000e+00 - val_loss: 1182640506.2966 - val_acc: 0.0000e+00\n",
      "Epoch 756/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6851374694.9800 - acc: 0.0000e+00 - val_loss: 1182497161.3499 - val_acc: 0.0000e+00\n",
      "Epoch 757/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6851015707.6856 - acc: 0.0000e+00 - val_loss: 1182353942.0657 - val_acc: 0.0000e+00\n",
      "Epoch 758/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6850656923.1294 - acc: 0.0000e+00 - val_loss: 1182210600.1110 - val_acc: 0.0000e+00\n",
      "Epoch 759/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6850298135.7438 - acc: 0.0000e+00 - val_loss: 1182067317.9956 - val_acc: 0.0000e+00\n",
      "Epoch 760/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6849939358.8945 - acc: 0.0000e+00 - val_loss: 1181924044.8561 - val_acc: 0.0000e+00\n",
      "Epoch 761/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6849580623.8999 - acc: 0.0000e+00 - val_loss: 1181780839.8773 - val_acc: 0.0000e+00\n",
      "Epoch 762/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6849221895.5406 - acc: 0.0000e+00 - val_loss: 1181637599.6494 - val_acc: 0.0000e+00\n",
      "Epoch 763/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6848863065.7129 - acc: 0.0000e+00 - val_loss: 1181494337.3090 - val_acc: 0.0000e+00\n",
      "Epoch 764/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6848504351.4994 - acc: 0.0000e+00 - val_loss: 1181351173.5632 - val_acc: 0.0000e+00\n",
      "Epoch 765/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6848145725.5822 - acc: 0.0000e+00 - val_loss: 1181207944.1344 - val_acc: 0.0000e+00\n",
      "Epoch 766/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6847786983.3661 - acc: 0.0000e+00 - val_loss: 1181064754.7699 - val_acc: 0.0000e+00\n",
      "Epoch 767/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6847428359.3020 - acc: 0.0000e+00 - val_loss: 1180921585.0402 - val_acc: 0.0000e+00\n",
      "Epoch 768/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6847069759.7250 - acc: 0.0000e+00 - val_loss: 1180778405.8203 - val_acc: 0.0000e+00\n",
      "Epoch 769/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6846711124.6356 - acc: 0.0000e+00 - val_loss: 1180635245.7210 - val_acc: 0.0000e+00\n",
      "Epoch 770/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6846352491.3019 - acc: 0.0000e+00 - val_loss: 1180492137.6538 - val_acc: 0.0000e+00\n",
      "Epoch 771/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6845993880.8952 - acc: 0.0000e+00 - val_loss: 1180348980.5464 - val_acc: 0.0000e+00\n",
      "Epoch 772/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6845635294.0996 - acc: 0.0000e+00 - val_loss: 1180205834.2381 - val_acc: 0.0000e+00\n",
      "Epoch 773/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6845276761.9395 - acc: 0.0000e+00 - val_loss: 1180062752.4441 - val_acc: 0.0000e+00\n",
      "Epoch 774/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6844918229.8764 - acc: 0.0000e+00 - val_loss: 1179919646.8546 - val_acc: 0.0000e+00\n",
      "Epoch 775/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6844559778.5966 - acc: 0.0000e+00 - val_loss: 1179776630.8839 - val_acc: 0.0000e+00\n",
      "Epoch 776/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6844201232.0934 - acc: 0.0000e+00 - val_loss: 1179633521.6479 - val_acc: 0.0000e+00\n",
      "Epoch 777/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6843842858.4742 - acc: 0.0000e+00 - val_loss: 1179490493.7093 - val_acc: 0.0000e+00\n",
      "Epoch 778/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6843484379.6812 - acc: 0.0000e+00 - val_loss: 1179347409.5778 - val_acc: 0.0000e+00\n",
      "Epoch 779/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6843125938.0592 - acc: 0.0000e+00 - val_loss: 1179204357.1892 - val_acc: 0.0000e+00\n",
      "Epoch 780/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6842767524.5362 - acc: 0.0000e+00 - val_loss: 1179061365.1541 - val_acc: 0.0000e+00\n",
      "Epoch 781/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6842409138.0380 - acc: 0.0000e+00 - val_loss: 1178918310.9423 - val_acc: 0.0000e+00\n",
      "Epoch 782/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6842050706.8547 - acc: 0.0000e+00 - val_loss: 1178775378.7465 - val_acc: 0.0000e+00\n",
      "Epoch 783/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6841692342.1133 - acc: 0.0000e+00 - val_loss: 1178632349.6392 - val_acc: 0.0000e+00\n",
      "Epoch 784/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6841334047.5202 - acc: 0.0000e+00 - val_loss: 1178489321.1863 - val_acc: 0.0000e+00\n",
      "Epoch 785/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6840975642.0939 - acc: 0.0000e+00 - val_loss: 1178346399.1351 - val_acc: 0.0000e+00\n",
      "Epoch 786/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6840617314.0356 - acc: 0.0000e+00 - val_loss: 1178203395.7867 - val_acc: 0.0000e+00\n",
      "Epoch 787/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6840259089.6887 - acc: 0.0000e+00 - val_loss: 1178060471.9123 - val_acc: 0.0000e+00\n",
      "Epoch 788/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6839900854.5111 - acc: 0.0000e+00 - val_loss: 1177917517.6041 - val_acc: 0.0000e+00\n",
      "Epoch 789/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6839542571.1367 - acc: 0.0000e+00 - val_loss: 1177774661.3762 - val_acc: 0.0000e+00\n",
      "Epoch 790/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6839184379.1801 - acc: 0.0000e+00 - val_loss: 1177631721.3733 - val_acc: 0.0000e+00\n",
      "Epoch 791/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6838826107.7080 - acc: 0.0000e+00 - val_loss: 1177488835.2257 - val_acc: 0.0000e+00\n",
      "Epoch 792/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6838467955.2644 - acc: 0.0000e+00 - val_loss: 1177345916.8210 - val_acc: 0.0000e+00\n",
      "Epoch 793/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6838109689.2559 - acc: 0.0000e+00 - val_loss: 1177203088.6896 - val_acc: 0.0000e+00\n",
      "Epoch 794/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6837751480.3220 - acc: 0.0000e+00 - val_loss: 1177060192.3974 - val_acc: 0.0000e+00\n",
      "Epoch 795/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6837393400.7584 - acc: 0.0000e+00 - val_loss: 1176917341.4989 - val_acc: 0.0000e+00\n",
      "Epoch 796/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6837035375.8308 - acc: 0.0000e+00 - val_loss: 1176774469.1424 - val_acc: 0.0000e+00\n",
      "Epoch 797/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6836677134.0177 - acc: 0.0000e+00 - val_loss: 1176631691.8744 - val_acc: 0.0000e+00\n",
      "Epoch 798/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6836319018.5499 - acc: 0.0000e+00 - val_loss: 1176488839.8072 - val_acc: 0.0000e+00\n",
      "Epoch 799/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6835961022.3062 - acc: 0.0000e+00 - val_loss: 1176346047.5793 - val_acc: 0.0000e+00\n",
      "Epoch 800/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6835602934.5460 - acc: 0.0000e+00 - val_loss: 1176203201.4960 - val_acc: 0.0000e+00\n",
      "Epoch 801/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6835244879.9578 - acc: 0.0000e+00 - val_loss: 1176060463.1234 - val_acc: 0.0000e+00\n",
      "Epoch 802/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6834886828.3940 - acc: 0.0000e+00 - val_loss: 1175917654.1125 - val_acc: 0.0000e+00\n",
      "Epoch 803/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6834528871.3690 - acc: 0.0000e+00 - val_loss: 1175774901.9489 - val_acc: 0.0000e+00\n",
      "Epoch 804/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6834170934.9317 - acc: 0.0000e+00 - val_loss: 1175632136.6486 - val_acc: 0.0000e+00\n",
      "Epoch 805/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6833812937.6126 - acc: 0.0000e+00 - val_loss: 1175489432.3565 - val_acc: 0.0000e+00\n",
      "Epoch 806/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6833454985.3682 - acc: 0.0000e+00 - val_loss: 1175346640.1286 - val_acc: 0.0000e+00\n",
      "Epoch 807/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6833097004.7326 - acc: 0.0000e+00 - val_loss: 1175203978.8926 - val_acc: 0.0000e+00\n",
      "Epoch 808/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6832739112.9781 - acc: 0.0000e+00 - val_loss: 1175061308.6808 - val_acc: 0.0000e+00\n",
      "Epoch 809/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6832381305.0313 - acc: 0.0000e+00 - val_loss: 1174918547.5413 - val_acc: 0.0000e+00\n",
      "Epoch 810/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6832023285.5646 - acc: 0.0000e+00 - val_loss: 1174775917.3937 - val_acc: 0.0000e+00\n",
      "Epoch 811/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6831665530.8869 - acc: 0.0000e+00 - val_loss: 1174633202.9569 - val_acc: 0.0000e+00\n",
      "Epoch 812/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6831307640.7899 - acc: 0.0000e+00 - val_loss: 1174490576.9701 - val_acc: 0.0000e+00\n",
      "Epoch 813/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6830949934.8948 - acc: 0.0000e+00 - val_loss: 1174347865.5252 - val_acc: 0.0000e+00\n",
      "Epoch 814/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6830592151.5327 - acc: 0.0000e+00 - val_loss: 1174205274.2732 - val_acc: 0.0000e+00\n",
      "Epoch 815/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6830234284.1676 - acc: 0.0000e+00 - val_loss: 1174062684.1899 - val_acc: 0.0000e+00\n",
      "Epoch 816/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6829876516.0260 - acc: 0.0000e+00 - val_loss: 1173920048.0584 - val_acc: 0.0000e+00\n",
      "Epoch 817/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6829518750.3218 - acc: 0.0000e+00 - val_loss: 1173777477.7502 - val_acc: 0.0000e+00\n",
      "Epoch 818/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6829161098.4763 - acc: 0.0000e+00 - val_loss: 1173634910.4339 - val_acc: 0.0000e+00\n",
      "Epoch 819/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6828803414.1414 - acc: 0.0000e+00 - val_loss: 1173492277.2944 - val_acc: 0.0000e+00\n",
      "Epoch 820/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6828445653.6087 - acc: 0.0000e+00 - val_loss: 1173349727.9299 - val_acc: 0.0000e+00\n",
      "Epoch 821/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6828087972.4923 - acc: 0.0000e+00 - val_loss: 1173207238.9189 - val_acc: 0.0000e+00\n",
      "Epoch 822/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6827730329.7197 - acc: 0.0000e+00 - val_loss: 1173064655.4741 - val_acc: 0.0000e+00\n",
      "Epoch 823/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6827372790.2661 - acc: 0.0000e+00 - val_loss: 1172922128.2221 - val_acc: 0.0000e+00\n",
      "Epoch 824/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6827015222.9097 - acc: 0.0000e+00 - val_loss: 1172779645.1950 - val_acc: 0.0000e+00\n",
      "Epoch 825/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6826657609.8937 - acc: 0.0000e+00 - val_loss: 1172637101.8145 - val_acc: 0.0000e+00\n",
      "Epoch 826/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6826300015.1206 - acc: 0.0000e+00 - val_loss: 1172494617.6187 - val_acc: 0.0000e+00\n",
      "Epoch 827/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6825942423.9585 - acc: 0.0000e+00 - val_loss: 1172352178.3024 - val_acc: 0.0000e+00\n",
      "Epoch 828/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6825584913.7731 - acc: 0.0000e+00 - val_loss: 1172209673.1629 - val_acc: 0.0000e+00\n",
      "Epoch 829/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6825227390.3206 - acc: 0.0000e+00 - val_loss: 1172067252.9671 - val_acc: 0.0000e+00\n",
      "Epoch 830/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6824870000.6271 - acc: 0.0000e+00 - val_loss: 1171924797.5223 - val_acc: 0.0000e+00\n",
      "Epoch 831/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6824512413.2689 - acc: 0.0000e+00 - val_loss: 1171782372.5113 - val_acc: 0.0000e+00\n",
      "Epoch 832/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6824155016.3552 - acc: 0.0000e+00 - val_loss: 1171639915.8977 - val_acc: 0.0000e+00\n",
      "Epoch 833/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6823797585.9774 - acc: 0.0000e+00 - val_loss: 1171497528.6136 - val_acc: 0.0000e+00\n",
      "Epoch 834/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6823440127.7938 - acc: 0.0000e+00 - val_loss: 1171355161.6187 - val_acc: 0.0000e+00\n",
      "Epoch 835/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6823082710.2939 - acc: 0.0000e+00 - val_loss: 1171212820.3828 - val_acc: 0.0000e+00\n",
      "Epoch 836/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6822725305.7702 - acc: 0.0000e+00 - val_loss: 1171070366.1066 - val_acc: 0.0000e+00\n",
      "Epoch 837/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6822367931.1011 - acc: 0.0000e+00 - val_loss: 1170928040.4850 - val_acc: 0.0000e+00\n",
      "Epoch 838/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6822010696.1435 - acc: 0.0000e+00 - val_loss: 1170785671.6669 - val_acc: 0.0000e+00\n",
      "Epoch 839/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6821653342.2545 - acc: 0.0000e+00 - val_loss: 1170643372.3185 - val_acc: 0.0000e+00\n",
      "Epoch 840/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6821296104.8568 - acc: 0.0000e+00 - val_loss: 1170501087.9299 - val_acc: 0.0000e+00\n",
      "Epoch 841/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6820938846.7759 - acc: 0.0000e+00 - val_loss: 1170358705.4609 - val_acc: 0.0000e+00\n",
      "Epoch 842/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6820581586.9384 - acc: 0.0000e+00 - val_loss: 1170216423.4098 - val_acc: 0.0000e+00\n",
      "Epoch 843/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6820224401.3473 - acc: 0.0000e+00 - val_loss: 1170074176.0935 - val_acc: 0.0000e+00\n",
      "Epoch 844/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6819867233.0246 - acc: 0.0000e+00 - val_loss: 1169931931.7692 - val_acc: 0.0000e+00\n",
      "Epoch 845/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6819510101.5811 - acc: 0.0000e+00 - val_loss: 1169789699.4127 - val_acc: 0.0000e+00\n",
      "Epoch 846/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6819152829.9377 - acc: 0.0000e+00 - val_loss: 1169647465.2330 - val_acc: 0.0000e+00\n",
      "Epoch 847/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6818795763.2770 - acc: 0.0000e+00 - val_loss: 1169505235.8685 - val_acc: 0.0000e+00\n",
      "Epoch 848/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6818438654.6625 - acc: 0.0000e+00 - val_loss: 1169363059.7049 - val_acc: 0.0000e+00\n",
      "Epoch 849/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6818081517.0714 - acc: 0.0000e+00 - val_loss: 1169220859.0913 - val_acc: 0.0000e+00\n",
      "Epoch 850/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6817724511.6811 - acc: 0.0000e+00 - val_loss: 1169078691.9036 - val_acc: 0.0000e+00\n",
      "Epoch 851/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6817367477.2144 - acc: 0.0000e+00 - val_loss: 1168936511.5793 - val_acc: 0.0000e+00\n",
      "Epoch 852/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6817010456.8950 - acc: 0.0000e+00 - val_loss: 1168794363.5121 - val_acc: 0.0000e+00\n",
      "Epoch 853/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6816653416.3810 - acc: 0.0000e+00 - val_loss: 1168652226.8985 - val_acc: 0.0000e+00\n",
      "Epoch 854/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6816296454.2094 - acc: 0.0000e+00 - val_loss: 1168510079.4858 - val_acc: 0.0000e+00\n",
      "Epoch 855/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6815939458.2806 - acc: 0.0000e+00 - val_loss: 1168367965.4989 - val_acc: 0.0000e+00\n",
      "Epoch 856/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6815582469.2789 - acc: 0.0000e+00 - val_loss: 1168225850.9978 - val_acc: 0.0000e+00\n",
      "Epoch 857/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6815225620.3795 - acc: 0.0000e+00 - val_loss: 1168083759.7779 - val_acc: 0.0000e+00\n",
      "Epoch 858/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6814868642.5001 - acc: 0.0000e+00 - val_loss: 1167941661.4054 - val_acc: 0.0000e+00\n",
      "Epoch 859/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6814511719.0605 - acc: 0.0000e+00 - val_loss: 1167799591.1293 - val_acc: 0.0000e+00\n",
      "Epoch 860/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6814154886.2587 - acc: 0.0000e+00 - val_loss: 1167657511.8773 - val_acc: 0.0000e+00\n",
      "Epoch 861/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6813798062.5304 - acc: 0.0000e+00 - val_loss: 1167515462.5449 - val_acc: 0.0000e+00\n",
      "Epoch 862/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6813441129.2368 - acc: 0.0000e+00 - val_loss: 1167373398.2527 - val_acc: 0.0000e+00\n",
      "Epoch 863/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6813084351.9480 - acc: 0.0000e+00 - val_loss: 1167231372.8561 - val_acc: 0.0000e+00\n",
      "Epoch 864/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6812727555.4390 - acc: 0.0000e+00 - val_loss: 1167089337.3148 - val_acc: 0.0000e+00\n",
      "Epoch 865/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6812370770.7347 - acc: 0.0000e+00 - val_loss: 1166947323.2316 - val_acc: 0.0000e+00\n",
      "Epoch 866/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6812014048.4722 - acc: 0.0000e+00 - val_loss: 1166805337.8992 - val_acc: 0.0000e+00\n",
      "Epoch 867/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6811657381.5281 - acc: 0.0000e+00 - val_loss: 1166663348.4061 - val_acc: 0.0000e+00\n",
      "Epoch 868/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6811300583.9453 - acc: 0.0000e+00 - val_loss: 1166521357.0898 - val_acc: 0.0000e+00\n",
      "Epoch 869/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6810943880.4141 - acc: 0.0000e+00 - val_loss: 1166379407.6611 - val_acc: 0.0000e+00\n",
      "Epoch 870/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6810587178.7371 - acc: 0.0000e+00 - val_loss: 1166237435.4653 - val_acc: 0.0000e+00\n",
      "Epoch 871/1000\n",
      "164/164 [==============================] - 3s 15ms/step - loss: 6810230605.0628 - acc: 0.0000e+00 - val_loss: 1166095602.0687 - val_acc: 0.0000e+00\n",
      "Epoch 872/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6809873843.6759 - acc: 0.0000e+00 - val_loss: 1165953653.8086 - val_acc: 0.0000e+00\n",
      "Epoch 873/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6809517276.7346 - acc: 0.0000e+00 - val_loss: 1165811726.4923 - val_acc: 0.0000e+00\n",
      "Epoch 874/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6809160628.2285 - acc: 0.0000e+00 - val_loss: 1165669823.1118 - val_acc: 0.0000e+00\n",
      "Epoch 875/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6808804044.8959 - acc: 0.0000e+00 - val_loss: 1165527909.5866 - val_acc: 0.0000e+00\n",
      "Epoch 876/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6808447424.3908 - acc: 0.0000e+00 - val_loss: 1165386045.1015 - val_acc: 0.0000e+00\n",
      "Epoch 877/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6808090829.0572 - acc: 0.0000e+00 - val_loss: 1165244156.6808 - val_acc: 0.0000e+00\n",
      "Epoch 878/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6807734294.9935 - acc: 0.0000e+00 - val_loss: 1165102379.4770 - val_acc: 0.0000e+00\n",
      "Epoch 879/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6807377797.2243 - acc: 0.0000e+00 - val_loss: 1164960519.1527 - val_acc: 0.0000e+00\n",
      "Epoch 880/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6807021260.2331 - acc: 0.0000e+00 - val_loss: 1164818670.7962 - val_acc: 0.0000e+00\n",
      "Epoch 881/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6806664808.8064 - acc: 0.0000e+00 - val_loss: 1164676823.6085 - val_acc: 0.0000e+00\n",
      "Epoch 882/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6806308281.5711 - acc: 0.0000e+00 - val_loss: 1164535023.1234 - val_acc: 0.0000e+00\n",
      "Epoch 883/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6805951853.3641 - acc: 0.0000e+00 - val_loss: 1164393204.0321 - val_acc: 0.0000e+00\n",
      "Epoch 884/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6805595406.2291 - acc: 0.0000e+00 - val_loss: 1164251390.4105 - val_acc: 0.0000e+00\n",
      "Epoch 885/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6805238987.0951 - acc: 0.0000e+00 - val_loss: 1164109597.7327 - val_acc: 0.0000e+00\n",
      "Epoch 886/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6804882594.0107 - acc: 0.0000e+00 - val_loss: 1163967898.8342 - val_acc: 0.0000e+00\n",
      "Epoch 887/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6804526162.3879 - acc: 0.0000e+00 - val_loss: 1163826132.4295 - val_acc: 0.0000e+00\n",
      "Epoch 888/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6804169806.1829 - acc: 0.0000e+00 - val_loss: 1163684346.9043 - val_acc: 0.0000e+00\n",
      "Epoch 889/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6803813499.6364 - acc: 0.0000e+00 - val_loss: 1163542644.4996 - val_acc: 0.0000e+00\n",
      "Epoch 890/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6803457111.8205 - acc: 0.0000e+00 - val_loss: 1163400891.2316 - val_acc: 0.0000e+00\n",
      "Epoch 891/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6803100786.5428 - acc: 0.0000e+00 - val_loss: 1163259165.5457 - val_acc: 0.0000e+00\n",
      "Epoch 892/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6802744484.1911 - acc: 0.0000e+00 - val_loss: 1163117543.2695 - val_acc: 0.0000e+00\n",
      "Epoch 893/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6802388245.9397 - acc: 0.0000e+00 - val_loss: 1162975843.8568 - val_acc: 0.0000e+00\n",
      "Epoch 894/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6802031949.5399 - acc: 0.0000e+00 - val_loss: 1162834147.4361 - val_acc: 0.0000e+00\n",
      "Epoch 895/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6801675738.9967 - acc: 0.0000e+00 - val_loss: 1162692455.1760 - val_acc: 0.0000e+00\n",
      "Epoch 896/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6801319526.5998 - acc: 0.0000e+00 - val_loss: 1162550788.6749 - val_acc: 0.0000e+00\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6800963298.5921 - acc: 0.0000e+00 - val_loss: 1162409111.3747 - val_acc: 0.0000e+00\n",
      "Epoch 898/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6800607093.9017 - acc: 0.0000e+00 - val_loss: 1162267559.0825 - val_acc: 0.0000e+00\n",
      "Epoch 899/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6800250824.4286 - acc: 0.0000e+00 - val_loss: 1162125910.5332 - val_acc: 0.0000e+00\n",
      "Epoch 900/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6799894638.2754 - acc: 0.0000e+00 - val_loss: 1161984306.2089 - val_acc: 0.0000e+00\n",
      "Epoch 901/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6799538491.2450 - acc: 0.0000e+00 - val_loss: 1161842804.7801 - val_acc: 0.0000e+00\n",
      "Epoch 902/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6799182435.6323 - acc: 0.0000e+00 - val_loss: 1161701179.5121 - val_acc: 0.0000e+00\n",
      "Epoch 903/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6798826314.0667 - acc: 0.0000e+00 - val_loss: 1161559569.8583 - val_acc: 0.0000e+00\n",
      "Epoch 904/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6798470346.0657 - acc: 0.0000e+00 - val_loss: 1161417996.6224 - val_acc: 0.0000e+00\n",
      "Epoch 905/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6798114230.8412 - acc: 0.0000e+00 - val_loss: 1161276415.0650 - val_acc: 0.0000e+00\n",
      "Epoch 906/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6797758247.2299 - acc: 0.0000e+00 - val_loss: 1161134962.6764 - val_acc: 0.0000e+00\n",
      "Epoch 907/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6797402115.6146 - acc: 0.0000e+00 - val_loss: 1160993430.1592 - val_acc: 0.0000e+00\n",
      "Epoch 908/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6797046198.3465 - acc: 0.0000e+00 - val_loss: 1160851883.8510 - val_acc: 0.0000e+00\n",
      "Epoch 909/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6796690091.6090 - acc: 0.0000e+00 - val_loss: 1160710447.5909 - val_acc: 0.0000e+00\n",
      "Epoch 910/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6796334220.8791 - acc: 0.0000e+00 - val_loss: 1160568913.2505 - val_acc: 0.0000e+00\n",
      "Epoch 911/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6795978338.6360 - acc: 0.0000e+00 - val_loss: 1160427416.6370 - val_acc: 0.0000e+00\n",
      "Epoch 912/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6795622416.2946 - acc: 0.0000e+00 - val_loss: 1160286001.3207 - val_acc: 0.0000e+00\n",
      "Epoch 913/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6795266440.5854 - acc: 0.0000e+00 - val_loss: 1160144523.8276 - val_acc: 0.0000e+00\n",
      "Epoch 914/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6794910497.1695 - acc: 0.0000e+00 - val_loss: 1160003071.4390 - val_acc: 0.0000e+00\n",
      "Epoch 915/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6794554672.7821 - acc: 0.0000e+00 - val_loss: 1159861706.9861 - val_acc: 0.0000e+00\n",
      "Epoch 916/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6794198796.5869 - acc: 0.0000e+00 - val_loss: 1159720271.3806 - val_acc: 0.0000e+00\n",
      "Epoch 917/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6793843061.5684 - acc: 0.0000e+00 - val_loss: 1159578821.9839 - val_acc: 0.0000e+00\n",
      "Epoch 918/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6793487189.6666 - acc: 0.0000e+00 - val_loss: 1159437483.8042 - val_acc: 0.0000e+00\n",
      "Epoch 919/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6793131437.3781 - acc: 0.0000e+00 - val_loss: 1159296090.0862 - val_acc: 0.0000e+00\n",
      "Epoch 920/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6792775598.0617 - acc: 0.0000e+00 - val_loss: 1159154781.8262 - val_acc: 0.0000e+00\n",
      "Epoch 921/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6792419879.6280 - acc: 0.0000e+00 - val_loss: 1159013384.4617 - val_acc: 0.0000e+00\n",
      "Epoch 922/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6792064244.8064 - acc: 0.0000e+00 - val_loss: 1158871982.9365 - val_acc: 0.0000e+00\n",
      "Epoch 923/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6791708525.4935 - acc: 0.0000e+00 - val_loss: 1158730697.4434 - val_acc: 0.0000e+00\n",
      "Epoch 924/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6791352736.2282 - acc: 0.0000e+00 - val_loss: 1158589383.8539 - val_acc: 0.0000e+00\n",
      "Epoch 925/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6790996966.2783 - acc: 0.0000e+00 - val_loss: 1158448100.6983 - val_acc: 0.0000e+00\n",
      "Epoch 926/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6790641370.3849 - acc: 0.0000e+00 - val_loss: 1158306775.1410 - val_acc: 0.0000e+00\n",
      "Epoch 927/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6790285766.9779 - acc: 0.0000e+00 - val_loss: 1158165440.6077 - val_acc: 0.0000e+00\n",
      "Epoch 928/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6789930151.4729 - acc: 0.0000e+00 - val_loss: 1158024210.1388 - val_acc: 0.0000e+00\n",
      "Epoch 929/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6789574516.0654 - acc: 0.0000e+00 - val_loss: 1157882915.6698 - val_acc: 0.0000e+00\n",
      "Epoch 930/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6789218939.6826 - acc: 0.0000e+00 - val_loss: 1157741709.1366 - val_acc: 0.0000e+00\n",
      "Epoch 931/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6788863363.3009 - acc: 0.0000e+00 - val_loss: 1157600449.9167 - val_acc: 0.0000e+00\n",
      "Epoch 932/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6788507781.5527 - acc: 0.0000e+00 - val_loss: 1157459145.3031 - val_acc: 0.0000e+00\n",
      "Epoch 933/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6788152270.9288 - acc: 0.0000e+00 - val_loss: 1157317981.8262 - val_acc: 0.0000e+00\n",
      "Epoch 934/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6787796641.8607 - acc: 0.0000e+00 - val_loss: 1157176751.3572 - val_acc: 0.0000e+00\n",
      "Epoch 935/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6787441097.9669 - acc: 0.0000e+00 - val_loss: 1157035590.8722 - val_acc: 0.0000e+00\n",
      "Epoch 936/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6787085792.3245 - acc: 0.0000e+00 - val_loss: 1156894360.4032 - val_acc: 0.0000e+00\n",
      "Epoch 937/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6786730181.9888 - acc: 0.0000e+00 - val_loss: 1156753233.9985 - val_acc: 0.0000e+00\n",
      "Epoch 938/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6786374751.1715 - acc: 0.0000e+00 - val_loss: 1156612039.4332 - val_acc: 0.0000e+00\n",
      "Epoch 939/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6786019300.9388 - acc: 0.0000e+00 - val_loss: 1156470835.8919 - val_acc: 0.0000e+00\n",
      "Epoch 940/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6785663866.3159 - acc: 0.0000e+00 - val_loss: 1156329744.7363 - val_acc: 0.0000e+00\n",
      "Epoch 941/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6785308438.2298 - acc: 0.0000e+00 - val_loss: 1156188574.1066 - val_acc: 0.0000e+00\n",
      "Epoch 942/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6784953051.9001 - acc: 0.0000e+00 - val_loss: 1156047467.4770 - val_acc: 0.0000e+00\n",
      "Epoch 943/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6784597578.8369 - acc: 0.0000e+00 - val_loss: 1155906344.0643 - val_acc: 0.0000e+00\n",
      "Epoch 944/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6784242253.4854 - acc: 0.0000e+00 - val_loss: 1155765294.7962 - val_acc: 0.0000e+00\n",
      "Epoch 945/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6783886999.4530 - acc: 0.0000e+00 - val_loss: 1155624158.2469 - val_acc: 0.0000e+00\n",
      "Epoch 946/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6783531658.6858 - acc: 0.0000e+00 - val_loss: 1155483125.7619 - val_acc: 0.0000e+00\n",
      "Epoch 947/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6783176321.4310 - acc: 0.0000e+00 - val_loss: 1155342037.0840 - val_acc: 0.0000e+00\n",
      "Epoch 948/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6782820975.8827 - acc: 0.0000e+00 - val_loss: 1155201014.7436 - val_acc: 0.0000e+00\n",
      "Epoch 949/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6782465862.3417 - acc: 0.0000e+00 - val_loss: 1155059942.1943 - val_acc: 0.0000e+00\n",
      "Epoch 950/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6782110540.6967 - acc: 0.0000e+00 - val_loss: 1154918933.6450 - val_acc: 0.0000e+00\n",
      "Epoch 951/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6781755343.4455 - acc: 0.0000e+00 - val_loss: 1154777896.9993 - val_acc: 0.0000e+00\n",
      "Epoch 952/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6781400085.8991 - acc: 0.0000e+00 - val_loss: 1154636941.6508 - val_acc: 0.0000e+00\n",
      "Epoch 953/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6781044955.8704 - acc: 0.0000e+00 - val_loss: 1154495888.2221 - val_acc: 0.0000e+00\n",
      "Epoch 954/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6780689766.7160 - acc: 0.0000e+00 - val_loss: 1154354933.5281 - val_acc: 0.0000e+00\n",
      "Epoch 955/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6780334600.2952 - acc: 0.0000e+00 - val_loss: 1154213948.9145 - val_acc: 0.0000e+00\n",
      "Epoch 956/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6779979454.3613 - acc: 0.0000e+00 - val_loss: 1154073006.7027 - val_acc: 0.0000e+00\n",
      "Epoch 957/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6779624357.5027 - acc: 0.0000e+00 - val_loss: 1153932016.1052 - val_acc: 0.0000e+00\n",
      "Epoch 958/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6779269203.6672 - acc: 0.0000e+00 - val_loss: 1153791102.6443 - val_acc: 0.0000e+00\n",
      "Epoch 959/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6778914091.2959 - acc: 0.0000e+00 - val_loss: 1153650164.0789 - val_acc: 0.0000e+00\n",
      "Epoch 960/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6778558933.1664 - acc: 0.0000e+00 - val_loss: 1153509257.7706 - val_acc: 0.0000e+00\n",
      "Epoch 961/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6778203997.8739 - acc: 0.0000e+00 - val_loss: 1153368300.0847 - val_acc: 0.0000e+00\n",
      "Epoch 962/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6777848928.4303 - acc: 0.0000e+00 - val_loss: 1153227462.5917 - val_acc: 0.0000e+00\n",
      "Epoch 963/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6777493908.0611 - acc: 0.0000e+00 - val_loss: 1153086613.1308 - val_acc: 0.0000e+00\n",
      "Epoch 964/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6777138988.6710 - acc: 0.0000e+00 - val_loss: 1152945679.3806 - val_acc: 0.0000e+00\n",
      "Epoch 965/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6776783993.3753 - acc: 0.0000e+00 - val_loss: 1152804858.0161 - val_acc: 0.0000e+00\n",
      "Epoch 966/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6776428933.3939 - acc: 0.0000e+00 - val_loss: 1152663964.3302 - val_acc: 0.0000e+00\n",
      "Epoch 967/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6776073943.1720 - acc: 0.0000e+00 - val_loss: 1152523174.7085 - val_acc: 0.0000e+00\n",
      "Epoch 968/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6775719136.9560 - acc: 0.0000e+00 - val_loss: 1152382286.3521 - val_acc: 0.0000e+00\n",
      "Epoch 969/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6775364154.1479 - acc: 0.0000e+00 - val_loss: 1152241500.8912 - val_acc: 0.0000e+00\n",
      "Epoch 970/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6775009244.4155 - acc: 0.0000e+00 - val_loss: 1152100751.3338 - val_acc: 0.0000e+00\n",
      "Epoch 971/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6774654421.9051 - acc: 0.0000e+00 - val_loss: 1151959898.8809 - val_acc: 0.0000e+00\n",
      "Epoch 972/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6774299512.9527 - acc: 0.0000e+00 - val_loss: 1151819152.3156 - val_acc: 0.0000e+00\n",
      "Epoch 973/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6773944654.7338 - acc: 0.0000e+00 - val_loss: 1151678353.7180 - val_acc: 0.0000e+00\n",
      "Epoch 974/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6773589840.4182 - acc: 0.0000e+00 - val_loss: 1151537622.1125 - val_acc: 0.0000e+00\n",
      "Epoch 975/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6773235030.2004 - acc: 0.0000e+00 - val_loss: 1151396909.6275 - val_acc: 0.0000e+00\n",
      "Epoch 976/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6772880239.8851 - acc: 0.0000e+00 - val_loss: 1151256122.9978 - val_acc: 0.0000e+00\n",
      "Epoch 977/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6772525557.4765 - acc: 0.0000e+00 - val_loss: 1151115413.5047 - val_acc: 0.0000e+00\n",
      "Epoch 978/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6772170777.0146 - acc: 0.0000e+00 - val_loss: 1150974660.9554 - val_acc: 0.0000e+00\n",
      "Epoch 979/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6771815957.1374 - acc: 0.0000e+00 - val_loss: 1150834005.3178 - val_acc: 0.0000e+00\n",
      "Epoch 980/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6771461255.4105 - acc: 0.0000e+00 - val_loss: 1150693352.0175 - val_acc: 0.0000e+00\n",
      "Epoch 981/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6771106735.0546 - acc: 0.0000e+00 - val_loss: 1150552613.2593 - val_acc: 0.0000e+00\n",
      "Epoch 982/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6770752005.2281 - acc: 0.0000e+00 - val_loss: 1150411988.7100 - val_acc: 0.0000e+00\n",
      "Epoch 983/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6770397388.2840 - acc: 0.0000e+00 - val_loss: 1150271380.2893 - val_acc: 0.0000e+00\n",
      "Epoch 984/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6770042772.4121 - acc: 0.0000e+00 - val_loss: 1150130763.5471 - val_acc: 0.0000e+00\n",
      "Epoch 985/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6769688106.4902 - acc: 0.0000e+00 - val_loss: 1149990088.1344 - val_acc: 0.0000e+00\n",
      "Epoch 986/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6769333516.0826 - acc: 0.0000e+00 - val_loss: 1149849496.4967 - val_acc: 0.0000e+00\n",
      "Epoch 987/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6768979006.6528 - acc: 0.0000e+00 - val_loss: 1149708906.0278 - val_acc: 0.0000e+00\n",
      "Epoch 988/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6768624432.8305 - acc: 0.0000e+00 - val_loss: 1149568368.2454 - val_acc: 0.0000e+00\n",
      "Epoch 989/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6768269924.5715 - acc: 0.0000e+00 - val_loss: 1149427732.8970 - val_acc: 0.0000e+00\n",
      "Epoch 990/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6767915371.2377 - acc: 0.0000e+00 - val_loss: 1149287166.3638 - val_acc: 0.0000e+00\n",
      "Epoch 991/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6767560897.2232 - acc: 0.0000e+00 - val_loss: 1149146645.8787 - val_acc: 0.0000e+00\n",
      "Epoch 992/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6767206487.6006 - acc: 0.0000e+00 - val_loss: 1149006135.0241 - val_acc: 0.0000e+00\n",
      "Epoch 993/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6766851987.1456 - acc: 0.0000e+00 - val_loss: 1148865566.6676 - val_acc: 0.0000e+00\n",
      "Epoch 994/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6766497649.0388 - acc: 0.0000e+00 - val_loss: 1148725077.9255 - val_acc: 0.0000e+00\n",
      "Epoch 995/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6766143239.5126 - acc: 0.0000e+00 - val_loss: 1148584549.6333 - val_acc: 0.0000e+00\n",
      "Epoch 996/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6765788719.9350 - acc: 0.0000e+00 - val_loss: 1148444106.9394 - val_acc: 0.0000e+00\n",
      "Epoch 997/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 6765434387.7780 - acc: 0.0000e+00 - val_loss: 1148303562.0044 - val_acc: 0.0000e+00\n",
      "Epoch 998/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6765080006.3509 - acc: 0.0000e+00 - val_loss: 1148163114.4953 - val_acc: 0.0000e+00\n",
      "Epoch 999/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6764725690.7792 - acc: 0.0000e+00 - val_loss: 1148022666.9861 - val_acc: 0.0000e+00\n",
      "Epoch 1000/1000\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 6764371344.5729 - acc: 0.0000e+00 - val_loss: 1147882215.3163 - val_acc: 0.0000e+00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sp_activator = StockPredictionActivator(get_simple_lstm(pre_data_length=pre_data_length, num_features=6, output_dim=1))\n",
    "sp_activator.train(train_data=train_stock_data, validation_data=test_stock_data, \n",
    "                   epochs=1000, batch_size=64, verbose=1, validation_split=0.1,\n",
    "                  pre_data_length=pre_data_length, pro_data_length=pro_data_length, process_data=process_data,\n",
    "                  step_estimator=get_estimated_steps, generator=data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahahaha\n"
     ]
    }
   ],
   "source": [
    "print('ahahaha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data, tester, batch_size=64, **kwargs):\n",
    "    pre_data_length = kwargs['pre_data_length']\n",
    "    pro_data_length = kwargs['pro_data_length']\n",
    "    process_data = kwargs['process_data']\n",
    "    step_estimator = kwargs['step_estimator']\n",
    "    generator = kwargs['generator']\n",
    "    test_steps, test_steps_per_epoch = step_estimator(test_data, pre_data_length, pro_data_length, batch_size)\n",
    "    print('Total Samples:', test_steps)\n",
    "\n",
    "    \"\"\"\n",
    "    모든 회사를 한꺼번에 넣으면 각 미니배치마다 랜덤 회사를 가지고 오기 때문에, predict 된 내역과 실제 y를 비교 불가능하게 된다.\n",
    "    따라서 한 회사씩 predict하여 그 순서가 회사 -> 시간순으로 예측되도록 한다.\n",
    "    \"\"\"\n",
    "    all_predicted = list()\n",
    "    for td in test_data:\n",
    "        test_steps, test_steps_per_epoch = step_estimator([td], pre_data_length, pro_data_length, batch_size)\n",
    "        predicted = model.predict_generator(generator=generator(all_stock_data=[td], \n",
    "                                                                batch_size=batch_size, \n",
    "                                                                pre_data_length=pre_data_length, \n",
    "                                                                pro_data_length=pro_data_length,\n",
    "                                                                process_data=process_data),\n",
    "                                            steps=test_steps_per_epoch)\n",
    "        all_predicted.extend(predicted)\n",
    "    \n",
    "    tester(test_data, predicted, pre_data_length=pre_data_length, pro_data_length=pro_data_length)\n",
    "    return all_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples: 1369\n",
      "14300.0 [2853.1057]\n",
      "14100.0 [2853.1057]\n",
      "14000.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14100.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "14400.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14400.0 [2853.1057]\n",
      "14550.0 [2853.1057]\n",
      "14500.0 [2853.1057]\n",
      "14100.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "14150.0 [2853.1057]\n",
      "14150.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "14400.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "14000.0 [2853.1057]\n",
      "13900.0 [2853.1057]\n",
      "13700.0 [2853.1057]\n",
      "13550.0 [2853.1057]\n",
      "13600.0 [2853.1057]\n",
      "13650.0 [2853.1057]\n",
      "13550.0 [2853.1057]\n",
      "13500.0 [2853.1057]\n",
      "13650.0 [2853.1057]\n",
      "13650.0 [2853.1057]\n",
      "13450.0 [2853.1057]\n",
      "13250.0 [2853.1057]\n",
      "13250.0 [2853.1057]\n",
      "13350.0 [2853.1057]\n",
      "13400.0 [2853.1057]\n",
      "14100.0 [2853.1057]\n",
      "14550.0 [2853.1057]\n",
      "15050.0 [2853.1057]\n",
      "14600.0 [2853.1057]\n",
      "14500.0 [2853.1057]\n",
      "14850.0 [1295.3517]\n",
      "14750.0 [1292.149]\n",
      "14950.0 [1291.6582]\n",
      "14800.0 [1291.5906]\n",
      "14850.0 [1291.5814]\n",
      "14750.0 [1291.5802]\n",
      "14500.0 [1291.5796]\n",
      "14500.0 [1291.5591]\n",
      "14400.0 [1290.4581]\n",
      "14350.0 [1260.3943]\n",
      "14250.0 [1230.3306]\n",
      "14600.0 [1229.2295]\n",
      "14750.0 [1229.2086]\n",
      "14850.0 [1229.205]\n",
      "15050.0 [1229.1813]\n",
      "14800.0 [1229.0055]\n",
      "14600.0 [1227.7103]\n",
      "14600.0 [1218.3093]\n",
      "14850.0 [1156.9736]\n",
      "14800.0 [811.0271]\n",
      "14700.0 [811.0271]\n",
      "14450.0 [811.0271]\n",
      "14400.0 [811.0271]\n",
      "14600.0 [811.0271]\n",
      "14850.0 [811.0271]\n",
      "15150.0 [811.0271]\n",
      "14800.0 [811.0271]\n",
      "14950.0 [1049.5142]\n",
      "14700.0 [1512.5997]\n",
      "14700.0 [1921.4594]\n",
      "14600.0 [1932.6584]\n",
      "14500.0 [2672.7017]\n",
      "14900.0 [2867.9866]\n",
      "14900.0 [2934.2412]\n",
      "14900.0 [2944.3118]\n",
      "14900.0 [2945.6978]\n",
      "15300.0 [2945.8855]\n",
      "15800.0 [1836.6962]\n",
      "16250.0 [2754.4512]\n",
      "16350.0 [2903.9692]\n",
      "15850.0 [2939.674]\n",
      "16000.0 [2945.0874]\n",
      "15700.0 [2946.015]\n",
      "15900.0 [2947.4673]\n",
      "15950.0 [2956.2246]\n",
      "16200.0 [2986.9639]\n",
      "15700.0 [3003.6165]\n",
      "15850.0 [2989.5193]\n",
      "15950.0 [2979.9412]\n",
      "15800.0 [2979.552]\n",
      "15800.0 [2976.7263]\n",
      "15900.0 [2958.2932]\n",
      "16150.0 [2958.2932]\n",
      "15950.0 [3053.972]\n",
      "15800.0 [2976.7263]\n",
      "15800.0 [2976.7263]\n",
      "15600.0 [2976.7263]\n",
      "15550.0 [2922.4568]\n",
      "15750.0 [2922.4568]\n",
      "15600.0 [2922.4568]\n",
      "15600.0 [2922.4568]\n",
      "15700.0 [2922.4568]\n",
      "15700.0 [2922.4568]\n",
      "16000.0 [2922.4568]\n",
      "15850.0 [2922.4568]\n",
      "16450.0 [2922.4568]\n",
      "16700.0 [2922.4568]\n",
      "16500.0 [2922.4568]\n",
      "16300.0 [2922.4568]\n",
      "16150.0 [2922.4568]\n",
      "16300.0 [2922.4568]\n",
      "16250.0 [2922.4568]\n",
      "16450.0 [2922.4568]\n",
      "16700.0 [2853.1057]\n",
      "16350.0 [2853.1057]\n",
      "16050.0 [2853.1057]\n",
      "16350.0 [2853.1057]\n",
      "16350.0 [2853.1057]\n",
      "16650.0 [2853.1057]\n",
      "16400.0 [2853.1057]\n",
      "16000.0 [2853.1057]\n",
      "16300.0 [2853.1057]\n",
      "16350.0 [2853.1057]\n",
      "16150.0 [2853.1057]\n",
      "15950.0 [2853.1057]\n",
      "16100.0 [2853.1057]\n",
      "15950.0 [2853.1057]\n",
      "15650.0 [2853.1057]\n",
      "15350.0 [2853.1057]\n",
      "15300.0 [2853.1057]\n",
      "14850.0 [2853.1057]\n",
      "14750.0 [2853.1057]\n",
      "14800.0 [2853.1057]\n",
      "14850.0 [2853.1057]\n",
      "14650.0 [2853.1057]\n",
      "14600.0 [2853.1057]\n",
      "14850.0 [2853.1057]\n",
      "14500.0 [2853.1057]\n",
      "14550.0 [2853.1057]\n",
      "14600.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14600.0 [2853.1057]\n",
      "14900.0 [2853.1057]\n",
      "14650.0 [2853.1057]\n",
      "14700.0 [2853.1057]\n",
      "14300.0 [2853.1057]\n",
      "14500.0 [2853.1057]\n",
      "14600.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14650.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14550.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "13800.0 [2853.1057]\n",
      "13700.0 [2853.1057]\n",
      "13550.0 [2853.1057]\n",
      "13700.0 [2853.1057]\n",
      "13450.0 [2853.1057]\n",
      "13500.0 [2853.1057]\n",
      "14000.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "14250.0 [2853.1057]\n",
      "14100.0 [2853.1057]\n",
      "13900.0 [2853.1057]\n",
      "14300.0 [2853.1057]\n",
      "14000.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "13950.0 [2853.1057]\n",
      "13950.0 [2853.1057]\n",
      "14100.0 [2853.1057]\n",
      "14500.0 [2853.1057]\n",
      "14250.0 [2853.1057]\n",
      "13900.0 [2853.1057]\n",
      "13850.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "14400.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14550.0 [2853.1057]\n",
      "14550.0 [2853.1057]\n",
      "14650.0 [2853.1057]\n",
      "15000.0 [2853.1057]\n",
      "15000.0 [2853.1057]\n",
      "15000.0 [2853.1057]\n",
      "14700.0 [2853.1057]\n",
      "14800.0 [2853.1057]\n",
      "14800.0 [2853.1057]\n",
      "14500.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14500.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "14000.0 [2853.1057]\n",
      "13750.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "13850.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "14350.0 [2853.1057]\n",
      "14150.0 [2853.1057]\n",
      "14000.0 [2853.1057]\n",
      "13650.0 [2853.1057]\n",
      "13650.0 [2853.1057]\n",
      "13950.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "13950.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "13750.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "13950.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "13600.0 [2853.1057]\n",
      "13700.0 [2853.1057]\n",
      "14000.0 [2853.1057]\n",
      "13800.0 [2853.1057]\n",
      "13850.0 [2853.1057]\n",
      "14500.0 [2853.1057]\n",
      "14400.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "13950.0 [2853.1057]\n",
      "13900.0 [2853.1057]\n",
      "13850.0 [2853.1057]\n",
      "13750.0 [2853.1057]\n",
      "13750.0 [2853.1057]\n",
      "13550.0 [2853.1057]\n",
      "13450.0 [2853.1057]\n",
      "13600.0 [2853.1057]\n",
      "13600.0 [2853.1057]\n",
      "13750.0 [2853.1057]\n",
      "13900.0 [2853.1057]\n",
      "14100.0 [2853.1057]\n",
      "14150.0 [2853.1057]\n",
      "13800.0 [2853.1057]\n",
      "13750.0 [2853.1057]\n",
      "13700.0 [2853.1057]\n",
      "13650.0 [2853.1057]\n",
      "13850.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "14650.0 [2853.1057]\n",
      "14900.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14650.0 [2853.1057]\n",
      "14500.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14000.0 [2853.1057]\n",
      "13900.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "15600.0 [2853.1057]\n",
      "15900.0 [2853.1057]\n",
      "15750.0 [2853.1057]\n",
      "15400.0 [2853.1057]\n",
      "15550.0 [2853.1057]\n",
      "14650.0 [2853.1057]\n",
      "14550.0 [2853.1057]\n",
      "14400.0 [2853.1057]\n",
      "14550.0 [2853.1057]\n",
      "14600.0 [2853.1057]\n",
      "14400.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "13700.0 [2853.1057]\n",
      "13450.0 [2853.1057]\n",
      "13550.0 [2853.1057]\n",
      "13100.0 [2853.1057]\n",
      "13300.0 [2853.1057]\n",
      "13300.0 [2853.1057]\n",
      "13600.0 [2853.1057]\n",
      "13500.0 [2853.1057]\n",
      "13600.0 [2853.1057]\n",
      "13850.0 [2853.1057]\n",
      "13800.0 [2853.1057]\n",
      "13650.0 [2853.1057]\n",
      "14250.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "13950.0 [2853.1057]\n",
      "13450.0 [2853.1057]\n",
      "13600.0 [2853.1057]\n",
      "13700.0 [2853.1057]\n",
      "13850.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "14050.0 [2853.1057]\n",
      "14000.0 [2853.1057]\n",
      "14350.0 [2853.1057]\n",
      "14250.0 [2853.1057]\n",
      "14300.0 [2853.1057]\n",
      "14200.0 [2853.1057]\n",
      "14300.0 [2853.1057]\n",
      "14600.0 [2853.1057]\n",
      "14950.0 [2853.1057]\n",
      "14700.0 [2853.1057]\n",
      "14450.0 [2853.1057]\n",
      "14250.0 [2853.1057]\n",
      "14150.0 [2853.1057]\n",
      "14250.0 [2853.1057]\n",
      "14550.0 [2853.1057]\n",
      "14750.0 [2853.1057]\n",
      "15150.0 [2853.1057]\n",
      "15150.0 [2158.3867]\n",
      "15250.0 [2802.7864]\n",
      "14850.0 [2921.772]\n",
      "14700.0 [2952.794]\n",
      "14900.0 [2957.5374]\n",
      "15050.0 [2958.1907]\n",
      "14800.0 [2958.2793]\n",
      "14750.0 [3053.8044]\n",
      "14000.0 [2976.726]\n",
      "13900.0 [2976.7263]\n",
      "14000.0 [2976.7263]\n",
      "14100.0 [3103.763]\n",
      "14650.0 [2979.552]\n",
      "14200.0 [2099.5085]\n",
      "14150.0 [3041.684]\n",
      "14300.0 [3041.6912]\n",
      "14450.0 [2199.082]\n",
      "14250.0 [1562.2795]\n",
      "13800.0 [2854.814]\n",
      "13850.0 [2687.2893]\n",
      "13150.0 [2729.425]\n",
      "13200.0 [2099.364]\n",
      "13200.0 [1628.6671]\n",
      "13250.0 [1797.2557]\n",
      "13050.0 [2763.6697]\n",
      "13200.0 [2977.3616]\n",
      "13550.0 [3056.7617]\n",
      "13600.0 [2989.5854]\n",
      "13800.0 [2990.9712]\n",
      "13800.0 [2991.159]\n",
      "13800.0 [2991.1843]\n",
      "13650.0 [2991.188]\n",
      "13850.0 [2991.1887]\n",
      "14500.0 [2990.9875]\n",
      "14550.0 [2990.9875]\n",
      "14250.0 [2990.9875]\n",
      "14200.0 [2989.5276]\n",
      "14100.0 [2990.9875]\n",
      "13550.0 [2990.9875]\n",
      "13800.0 [2990.9875]\n",
      "13900.0 [2990.9866]\n",
      "14250.0 [2989.5193]\n",
      "14200.0 [2979.9412]\n",
      "13850.0 [2943.7156]\n",
      "13800.0 [2943.7156]\n",
      "13550.0 [2940.89]\n",
      "13800.0 [2922.4568]\n",
      "13800.0 [2853.1057]\n",
      "13800.0 [2853.1057]\n",
      "13850.0 [2853.1057]\n",
      "13700.0 [2853.1057]\n",
      "14350.0 [2853.1057]\n",
      "13950.0 [2853.1057]\n",
      "13850.0 [2853.1057]\n",
      "13700.0 [2853.1057]\n",
      "13750.0 [2853.1057]\n",
      "13750.0 [2853.1057]\n",
      "13400.0 [2853.1057]\n",
      "13250.0 [2853.1057]\n",
      "13200.0 [2853.1057]\n",
      "13050.0 [2853.1057]\n",
      "12650.0 [2853.1057]\n",
      "12650.0 [2853.1057]\n",
      "12900.0 [2853.1057]\n"
     ]
    }
   ],
   "source": [
    "def regression_tester(test_data, predicted, **kwargs):\n",
    "    pre_data_length = kwargs['pre_data_length']\n",
    "    pro_data_length = kwargs['pro_data_length']\n",
    "    \n",
    "    y_data = list()\n",
    "    for td in test_data:\n",
    "        y_data.extend(td[pre_data_length:, 0])\n",
    "    \n",
    "    for y, y_hat in zip(y_data, predicted):\n",
    "        print(y, y_hat)\n",
    "    \n",
    "all_predicted = test(model=sp_activator.model, test_data=test_stock_data, tester=regression_tester, batch_size=64,\n",
    "                     pre_data_length=pre_data_length, pro_data_length=pro_data_length, process_data=process_data,\n",
    "                     step_estimator=get_estimated_steps, generator=data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50.0]\n",
      " [350.0]\n",
      " [600.0]\n",
      " [200.0]\n",
      " [200.0]\n",
      " [400.0]\n",
      " [800.0]\n",
      " [1500.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [0.0]\n",
      " [500.0]\n",
      " [450.0]\n",
      " [0.0]\n",
      " [800.0]\n",
      " [500.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [200.0]\n",
      " [900.0]\n",
      " [350.0]\n",
      " [0.0]\n",
      " [900.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [900.0]\n",
      " [700.0]\n",
      " [150.0]\n",
      " [0.0]\n",
      " [1400.0]\n",
      " [500.0]\n",
      " [200.0]\n",
      " [50.0]\n",
      " [1500.0]\n",
      " [800.0]\n",
      " [50.0]\n",
      " [50.0]\n",
      " [0.0]\n",
      " [1000.0]\n",
      " [50.0]\n",
      " [600.0]\n",
      " [300.0]\n",
      " [500.0]\n",
      " [150.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [600.0]\n",
      " [50.0]\n",
      " [150.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [400.0]\n",
      " [0.0]\n",
      " [200.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [300.0]\n",
      " [1100.0]\n",
      " [50.0]\n",
      " [0.0]\n",
      " [700.0]\n",
      " [100.0]]\n",
      "[[0.0]\n",
      " [150.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [250.0]\n",
      " [200.0]\n",
      " [200.0]\n",
      " [200.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [200.0]\n",
      " [250.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [150.0]\n",
      " [400.0]\n",
      " [0.0]\n",
      " [800.0]\n",
      " [50.0]\n",
      " [150.0]\n",
      " [100.0]\n",
      " [500.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [0.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [900.0]\n",
      " [150.0]\n",
      " [150.0]\n",
      " [600.0]\n",
      " [800.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [200.0]\n",
      " [50.0]\n",
      " [50.0]\n",
      " [200.0]\n",
      " [1000.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [200.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [300.0]\n",
      " [300.0]\n",
      " [150.0]\n",
      " [200.0]\n",
      " [200.0]\n",
      " [300.0]\n",
      " [0.0]\n",
      " [300.0]\n",
      " [200.0]\n",
      " [0.0]\n",
      " [200.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [100.0]]\n",
      "[[200.0]\n",
      " [200.0]\n",
      " [400.0]\n",
      " [800.0]\n",
      " [0.0]\n",
      " [50.0]\n",
      " [500.0]\n",
      " [600.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [1100.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [1300.0]\n",
      " [700.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [500.0]\n",
      " [450.0]\n",
      " [250.0]\n",
      " [200.0]\n",
      " [500.0]\n",
      " [500.0]\n",
      " [50.0]\n",
      " [0.0]\n",
      " [1300.0]\n",
      " [450.0]\n",
      " [100.0]\n",
      " [2000.0]\n",
      " [2100.0]\n",
      " [100.0]\n",
      " [0.0]\n",
      " [900.0]\n",
      " [0.0]\n",
      " [350.0]\n",
      " [100.0]\n",
      " [600.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [400.0]\n",
      " [500.0]\n",
      " [0.0]\n",
      " [200.0]\n",
      " [50.0]\n",
      " [1000.0]\n",
      " [0.0]\n",
      " [150.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [0.0]\n",
      " [50.0]\n",
      " [250.0]\n",
      " [100.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [200.0]\n",
      " [800.0]\n",
      " [0.0]\n",
      " [250.0]\n",
      " [450.0]\n",
      " [300.0]\n",
      " [0.0]]\n",
      "[[0.0]\n",
      " [50.0]\n",
      " [300.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [250.0]\n",
      " [400.0]\n",
      " [0.0]\n",
      " [50.0]\n",
      " [300.0]\n",
      " [1000.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [200.0]\n",
      " [0.0]\n",
      " [350.0]\n",
      " [300.0]\n",
      " [100.0]\n",
      " [0.0]\n",
      " [150.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [150.0]\n",
      " [500.0]\n",
      " [0.0]\n",
      " [200.0]\n",
      " [200.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [250.0]\n",
      " [200.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [200.0]\n",
      " [250.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [200.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [250.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [50.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [150.0]\n",
      " [500.0]\n",
      " [0.0]\n",
      " [250.0]\n",
      " [300.0]\n",
      " [300.0]\n",
      " [0.0]\n",
      " [50.0]\n",
      " [0.0]\n",
      " [300.0]\n",
      " [0.0]]\n",
      "[[200.0]\n",
      " [450.0]\n",
      " [200.0]\n",
      " [0.0]\n",
      " [250.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [0.0]\n",
      " [300.0]\n",
      " [450.0]\n",
      " [200.0]\n",
      " [0.0]\n",
      " [350.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [16100.0]\n",
      " [150.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [3400.0]\n",
      " [250.0]\n",
      " [250.0]\n",
      " [0.0]\n",
      " [1000.0]\n",
      " [0.0]\n",
      " [250.0]\n",
      " [0.0]\n",
      " [1700.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [700.0]\n",
      " [300.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [600.0]\n",
      " [900.0]\n",
      " [400.0]\n",
      " [50.0]\n",
      " [1000.0]\n",
      " [1000.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [900.0]\n",
      " [300.0]\n",
      " [0.0]\n",
      " [550.0]\n",
      " [600.0]\n",
      " [200.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [700.0]\n",
      " [300.0]\n",
      " [400.0]\n",
      " [250.0]\n",
      " [500.0]\n",
      " [1400.0]\n",
      " [500.0]\n",
      " [100.0]\n",
      " [900.0]\n",
      " [200.0]\n",
      " [450.0]\n",
      " [550.0]\n",
      " [100.0]\n",
      " [900.0]]\n",
      "[[100.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [500.0]\n",
      " [100.0]\n",
      " [0.0]\n",
      " [300.0]\n",
      " [150.0]\n",
      " [50.0]\n",
      " [400.0]\n",
      " [700.0]\n",
      " [300.0]\n",
      " [250.0]\n",
      " [50.0]\n",
      " [400.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [400.0]\n",
      " [400.0]\n",
      " [50.0]\n",
      " [300.0]\n",
      " [50.0]\n",
      " [200.0]\n",
      " [250.0]\n",
      " [150.0]\n",
      " [250.0]\n",
      " [100.0]\n",
      " [500.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [300.0]\n",
      " [150.0]\n",
      " [200.0]\n",
      " [350.0]\n",
      " [1300.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [50.0]\n",
      " [900.0]\n",
      " [150.0]\n",
      " [350.0]\n",
      " [350.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [300.0]\n",
      " [250.0]\n",
      " [500.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [300.0]\n",
      " [1200.0]\n",
      " [250.0]\n",
      " [300.0]\n",
      " [600.0]\n",
      " [400.0]\n",
      " [200.0]\n",
      " [50.0]\n",
      " [700.0]\n",
      " [400.0]\n",
      " [150.0]\n",
      " [150.0]\n",
      " [500.0]\n",
      " [500.0]]\n",
      "[[0.0]\n",
      " [50.0]\n",
      " [200.0]\n",
      " [500.0]\n",
      " [200.0]\n",
      " [350.0]\n",
      " [650.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [0.0]\n",
      " [550.0]\n",
      " [200.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [300.0]\n",
      " [150.0]\n",
      " [250.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [200.0]\n",
      " [300.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [300.0]\n",
      " [100.0]\n",
      " [0.0]\n",
      " [150.0]\n",
      " [350.0]\n",
      " [400.0]\n",
      " [300.0]\n",
      " [0.0]\n",
      " [550.0]\n",
      " [100.0]\n",
      " [150.0]\n",
      " [100.0]\n",
      " [1050.0]\n",
      " [200.0]\n",
      " [600.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [300.0]\n",
      " [250.0]\n",
      " [200.0]\n",
      " [650.0]\n",
      " [200.0]\n",
      " [200.0]\n",
      " [50.0]\n",
      " [850.0]\n",
      " [500.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [450.0]\n",
      " [300.0]\n",
      " [150.0]\n",
      " [50.0]\n",
      " [350.0]\n",
      " [100.0]\n",
      " [150.0]\n",
      " [50.0]\n",
      " [0.0]\n",
      " [200.0]]\n",
      "[[50.0]\n",
      " [250.0]\n",
      " [500.0]\n",
      " [100.0]\n",
      " [200.0]\n",
      " [50.0]\n",
      " [1250.0]\n",
      " [100.0]\n",
      " [250.0]\n",
      " [0.0]\n",
      " [1750.0]\n",
      " [400.0]\n",
      " [350.0]\n",
      " [0.0]\n",
      " [0.0]\n",
      " [400.0]\n",
      " [300.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [300.0]\n",
      " [300.0]\n",
      " [100.0]\n",
      " [950.0]\n",
      " [200.0]\n",
      " [0.0]\n",
      " [50.0]\n",
      " [400.0]\n",
      " [0.0]\n",
      " [300.0]\n",
      " [100.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [250.0]\n",
      " [50.0]\n",
      " [50.0]\n",
      " [200.0]\n",
      " [400.0]\n",
      " [100.0]\n",
      " [700.0]\n",
      " [500.0]\n",
      " [300.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [400.0]\n",
      " [50.0]\n",
      " [200.0]\n",
      " [500.0]\n",
      " [200.0]\n",
      " [200.0]\n",
      " [50.0]\n",
      " [500.0]\n",
      " [400.0]\n",
      " [200.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [200.0]\n",
      " [150.0]\n",
      " [100.0]\n",
      " [350.0]\n",
      " [500.0]\n",
      " [150.0]\n",
      " [100.0]\n",
      " [250.0]\n",
      " [800.0]]\n",
      "[[300.0]\n",
      " [0.0]\n",
      " [600.0]\n",
      " [700.0]\n",
      " [300.0]\n",
      " [200.0]\n",
      " [350.0]\n",
      " [800.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [300.0]\n",
      " [400.0]\n",
      " [450.0]\n",
      " [400.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [50.0]\n",
      " [200.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [550.0]\n",
      " [900.0]\n",
      " [50.0]\n",
      " [150.0]\n",
      " [50.0]\n",
      " [600.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [300.0]\n",
      " [50.0]\n",
      " [50.0]\n",
      " [550.0]\n",
      " [300.0]\n",
      " [250.0]\n",
      " [50.0]\n",
      " [300.0]\n",
      " [300.0]\n",
      " [350.0]\n",
      " [0.0]\n",
      " [50.0]\n",
      " [1600.0]\n",
      " [50.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [400.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [200.0]\n",
      " [150.0]\n",
      " [300.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [150.0]\n",
      " [50.0]\n",
      " [0.0]\n",
      " [400.0]\n",
      " [300.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [100.0]]\n",
      "[[250.0]\n",
      " [50.0]\n",
      " [200.0]\n",
      " [400.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [600.0]\n",
      " [300.0]\n",
      " [400.0]\n",
      " [200.0]\n",
      " [850.0]\n",
      " [400.0]\n",
      " [200.0]\n",
      " [150.0]\n",
      " [1750.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [2250.0]\n",
      " [100.0]\n",
      " [150.0]\n",
      " [200.0]\n",
      " [1300.0]\n",
      " [400.0]\n",
      " [0.0]\n",
      " [300.0]\n",
      " [1100.0]\n",
      " [300.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [250.0]\n",
      " [1200.0]\n",
      " [200.0]\n",
      " [50.0]\n",
      " [700.0]\n",
      " [100.0]\n",
      " [0.0]\n",
      " [100.0]\n",
      " [1200.0]\n",
      " [400.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [800.0]\n",
      " [300.0]\n",
      " [350.0]\n",
      " [150.0]\n",
      " [1450.0]\n",
      " [700.0]\n",
      " [400.0]\n",
      " [50.0]\n",
      " [1150.0]\n",
      " [200.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [100.0]\n",
      " [500.0]\n",
      " [150.0]\n",
      " [100.0]\n",
      " [100.0]\n",
      " [50.0]\n",
      " [150.0]\n",
      " [150.0]\n",
      " [1150.0]\n",
      " [950.0]]\n"
     ]
    }
   ],
   "source": [
    "loader = data_loader(all_stock_data=test_stock_data, batch_size=64, \n",
    "                     pre_data_length=20, pro_data_length=1, \n",
    "                     process_data=process_data)\n",
    "for idx, (x_batch, y_batch) in enumerate(loader):\n",
    "    if idx == 10:\n",
    "        break\n",
    "    print(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[14800.0, 500.0, 15250.0, 15400.0, 14650.0, 89378.0],\n",
       "        [14900.0, 100.0, 14900.0, 15050.0, 14750.0, 23480.0],\n",
       "        [14800.0, 100.0, 15100.0, 15100.0, 14700.0, 28288.0],\n",
       "        ...,\n",
       "        [12650.0, 400.0, 13050.0, 13100.0, 12550.0, 45778.0],\n",
       "        [12650.0, 0.0, 12550.0, 12800.0, 12400.0, 23579.0],\n",
       "        [12900.0, 250.0, 12650.0, 12900.0, 12550.0, 19363.0]], dtype=object),\n",
       " array([[13600.0, 350.0, 13800.0, 13950.0, 13550.0, 38914.0],\n",
       "        [13900.0, 300.0, 13550.0, 13950.0, 13450.0, 44309.0],\n",
       "        [14050.0, 150.0, 13900.0, 14250.0, 13900.0, 59080.0],\n",
       "        ...,\n",
       "        [11750.0, 200.0, 11900.0, 12050.0, 11650.0, 55984.0],\n",
       "        [12000.0, 250.0, 11900.0, 12150.0, 11750.0, 18309.0],\n",
       "        [12150.0, 150.0, 12000.0, 12250.0, 12000.0, 14377.0]], dtype=object),\n",
       " array([[43700.0, 8400.0, 52100.0, 67000.0, 41100.0, 506129.0],\n",
       "        [48000.0, 4300.0, 44300.0, 52700.0, 44150.0, 608556.0],\n",
       "        [54600.0, 6600.0, 49500.0, 56200.0, 47750.0, 258515.0],\n",
       "        ...,\n",
       "        [43650.0, 1250.0, 45000.0, 45000.0, 43300.0, 4663.0],\n",
       "        [44500.0, 850.0, 43650.0, 44700.0, 43650.0, 3427.0],\n",
       "        [44100.0, 400.0, 44550.0, 44600.0, 43150.0, 5300.0]], dtype=object),\n",
       " array([[76000.0, 700.0, 76100.0, 77700.0, 75400.0, 2730.0],\n",
       "        [76000.0, 0.0, 76700.0, 76700.0, 75400.0, 3093.0],\n",
       "        [73500.0, 2500.0, 76700.0, 77100.0, 73300.0, 2183.0],\n",
       "        ...,\n",
       "        [45400.0, 1000.0, 46950.0, 46950.0, 45300.0, 13499.0],\n",
       "        [48000.0, 2600.0, 45700.0, 48700.0, 45400.0, 12647.0],\n",
       "        [49250.0, 1250.0, 48150.0, 49900.0, 47000.0, 7213.0]], dtype=object)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainwave_eeg",
   "language": "python",
   "name": "brainwave_eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, GRU, Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 샘플 데이터 생성\n",
    "## 참조: http://121.140.2.142:8888/notebooks/test_notes/keras/Embedding%20Layer%20%26%20Padding.ipynb 의 샘플 데이터 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설명: Sequence length 10짜리 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 21 64 13 77 66 54 30 81 87]]\n",
      "Shape: (1, 10)\n"
     ]
    }
   ],
   "source": [
    "num_sentence = 1\n",
    "sequence_length = 10\n",
    "max_count_word = 100\n",
    "sentences = np.random.randint(low=1, high=max_count_word, size=(num_sentence, sequence_length), dtype='int32')\n",
    "print(sentences)\n",
    "print('Shape:', sentences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설명: Sequence length 7짜리 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24 52 11 40 46 59 85]]\n",
      "Shape: (1, 7)\n"
     ]
    }
   ],
   "source": [
    "num_sentence = 1\n",
    "sequence_length2 = 7\n",
    "max_count_word = 100\n",
    "sentences2 = np.random.randint(low=1, high=max_count_word, size=(num_sentence, sequence_length2), dtype='int32')\n",
    "print(sentences2)\n",
    "print('Shape:', sentences2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. GRU / LSTM\n",
    "## 참조: https://keras.io/layers/recurrent/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gru_model(hidden_dim, return_sequences, return_state, embedding):\n",
    "    model = Sequential()\n",
    "    if embedding:\n",
    "        model.add(Embedding(input_dim=100, output_dim=1, input_length=10))\n",
    "    model.add(GRU(units=hidden_dim, return_sequences=return_sequences, return_state=return_state))\n",
    "    model.compile(loss='mse', optimizer='rmsprop')\n",
    "    return model\n",
    "\n",
    "def get_lstm_model(hidden_dim, return_sequences, return_state, embedding):\n",
    "    model = Sequential()\n",
    "    if embedding:\n",
    "        model.add(Embedding(input_dim=100, output_dim=1, input_length=10))\n",
    "    model.add(LSTM(units=hidden_dim, return_sequences=return_sequences, return_state=return_state))\n",
    "    model.compile(loss='mse', optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(name, model, sentences, embedding):\n",
    "    print('#### %s Model Test with embedding=%s ####' %(name, str(embedding)))\n",
    "    if not embedding: # if embedding not used, 2d -> 3d\n",
    "        _sentences = list()\n",
    "        for sentence in sentences:\n",
    "            _sentence = list()\n",
    "            for s in sentence:\n",
    "                _sentence.append([s])\n",
    "            _sentences.append(_sentence)\n",
    "    else:\n",
    "        _sentences = sentences\n",
    "\n",
    "    print('Change to correct format for RNN')\n",
    "    print('sentences -> _sentences')\n",
    "    print(sentences, '->', _sentences)\n",
    "    _sentences = np.array(_sentences) # need to be numpy array type ...\n",
    "    predicted = model.predict(_sentences)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. 마지막 시퀀스 output만 가져옴 (default 파라미터 사용시)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU와 LSTM 셀을 활용하며, embedding을 활용한 버전과 활용하지 않은 버전 두 가지를 적용하여 총 4개의 테스트 케이스가 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 1\n",
    "return_sequences = False # Default\n",
    "return_state = False # Default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: GRU / Embedding = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### GRU Model Test with embedding=False ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[[4], [21], [64], [13], [77], [66], [54], [30], [81], [87]]]\n",
      "\n",
      "GRU Output:\n",
      "[[-1.]]\n",
      "Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: GRU / Embedding = False\n",
    "\"\"\"\n",
    "embedding = False\n",
    "predicted = test_model(name='GRU', \n",
    "                       model=get_gru_model(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('GRU Output:')\n",
    "print(predicted)\n",
    "print('Shape:', predicted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: GRU / Embedding = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### GRU Model Test with embedding=True ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[ 4 21 64 13 77 66 54 30 81 87]]\n",
      "\n",
      "GRU Output:\n",
      "[[-0.00632277]]\n",
      "Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: GRU / Embedding = True\n",
    "\"\"\"\n",
    "embedding = True\n",
    "predicted = test_model(name='GRU', \n",
    "                       model=get_gru_model(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('GRU Output:')\n",
    "print(predicted)\n",
    "print('Shape:', predicted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: LSTM / Embedding = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### LSTM Model Test with embedding=False ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[[4], [21], [64], [13], [77], [66], [54], [30], [81], [87]]]\n",
      "\n",
      "LSTM Output:\n",
      "[[1.]]\n",
      "Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: LSTM / Embedding = False\n",
    "\"\"\"\n",
    "embedding = False\n",
    "predicted = test_model(name='LSTM', \n",
    "                       model=get_lstm_model(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('LSTM Output:')\n",
    "print(predicted)\n",
    "print('Shape:', predicted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: LSTM / Embedding = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### LSTM Model Test with embedding=True ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[ 4 21 64 13 77 66 54 30 81 87]]\n",
      "\n",
      "LSTM Output:\n",
      "[[0.02648621]]\n",
      "Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: GRU / Embedding = True\n",
    "\"\"\"\n",
    "embedding = True\n",
    "predicted = test_model(name='LSTM', \n",
    "                       model=get_lstm_model(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('LSTM Output:')\n",
    "print(predicted)\n",
    "print('Shape:', predicted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코멘트: GRU와 LSTM 모두 last output만을 사용할 때에는 똑같은 형태의 input과 output 데이터를 가진다. 각각의 메카니즘 또는 embedding의 여부에 따라 output 값은 달라진다. embedding이 있고 없고에 따라 input data의 shape은 변경되어야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. 모든 시퀀스 output을 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 1\n",
    "return_sequences = True # Changed\n",
    "return_state = False # Default\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: GRU / Embedding = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### GRU Model Test with embedding=False ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[[4], [21], [64], [13], [77], [66], [54], [30], [81], [87]]]\n",
      "\n",
      "GRU Output:\n",
      "[[[0.9978595]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]]]\n",
      "Shape: (1, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: GRU / Embedding = False\n",
    "\"\"\"\n",
    "embedding = False\n",
    "predicted = test_model(name='GRU', \n",
    "                       model=get_gru_model(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('GRU Output:')\n",
    "print(predicted)\n",
    "print('Shape:', predicted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: GRU / Embedding = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### GRU Model Test with embedding=True ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[ 4 21 64 13 77 66 54 30 81 87]]\n",
      "\n",
      "GRU Output:\n",
      "[[[ 0.02192867]\n",
      "  [ 0.02025646]\n",
      "  [-0.00353545]\n",
      "  [-0.01354325]\n",
      "  [-0.03200561]\n",
      "  [-0.02812015]\n",
      "  [ 0.00748733]\n",
      "  [-0.00540804]\n",
      "  [-0.0123355 ]\n",
      "  [ 0.00106698]]]\n",
      "Shape: (1, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: GRU / Embedding = True\n",
    "\"\"\"\n",
    "embedding = True\n",
    "predicted = test_model(name='GRU', \n",
    "                       model=get_gru_model(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('GRU Output:')\n",
    "print(predicted)\n",
    "print('Shape:', predicted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: LSTM / Embedding = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### LSTM Model Test with embedding=False ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[[4], [21], [64], [13], [77], [66], [54], [30], [81], [87]]]\n",
      "\n",
      "LSTM Output:\n",
      "[[[-0.6443548 ]\n",
      "  [-0.91914594]\n",
      "  [-0.984043  ]\n",
      "  [-0.9923044 ]\n",
      "  [-0.9984626 ]\n",
      "  [-0.9995651 ]\n",
      "  [-0.99981004]\n",
      "  [-0.9998179 ]\n",
      "  [-0.9999579 ]\n",
      "  [-0.9999913 ]]]\n",
      "Shape: (1, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: LSTM / Embedding = False\n",
    "\"\"\"\n",
    "embedding = False\n",
    "predicted = test_model(name='LSTM', \n",
    "                       model=get_lstm_model(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('LSTM Output:')\n",
    "print(predicted)\n",
    "print('Shape:', predicted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: LSTM / Embedding = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### LSTM Model Test with embedding=True ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[ 4 21 64 13 77 66 54 30 81 87]]\n",
      "\n",
      "LSTM Output:\n",
      "[[[ 0.00607819]\n",
      "  [-0.00538075]\n",
      "  [ 0.00434323]\n",
      "  [-0.00093756]\n",
      "  [ 0.00690822]\n",
      "  [ 0.00408977]\n",
      "  [-0.00678301]\n",
      "  [-0.00384558]\n",
      "  [-0.00766471]\n",
      "  [-0.00183106]]]\n",
      "Shape: (1, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: LSTM / Embedding = True\n",
    "\"\"\"\n",
    "embedding = True\n",
    "predicted = test_model(name='LSTM', \n",
    "                       model=get_lstm_model(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('LSTM Output:')\n",
    "print(predicted)\n",
    "print('Shape:', predicted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코멘트: return_sequences 또한 GRU<->LSTM비교시 input과 output의 형태는 차이가 없다. 단지 embedding을 할 경우와 하지 않을 경우 input data의 shape은 달라진다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. 모든 시퀀스 output과 last output(+last hidden state)을 함께 가지고 옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 1\n",
    "return_sequences = True # Changed\n",
    "return_state = True # Changed\n",
    "\n",
    "def get_gru_model2(hidden_dim, return_sequences, return_state, embedding):\n",
    "    \n",
    "    if embedding:\n",
    "        inputs = Input(shape=(10, ))\n",
    "        _inputs = Embedding(input_dim=100, output_dim=1, input_length=10)(inputs)\n",
    "    else:\n",
    "        inputs = Input(shape=(10, 1))\n",
    "        _inputs = inputs\n",
    "    outputs, last_output = GRU(units=hidden_dim, return_sequences=return_sequences, return_state=return_state)(_inputs)\n",
    "    outputs = [outputs, last_output]\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='mse', optimizer='rmsprop')\n",
    "    return model\n",
    "\n",
    "def get_lstm_model2(hidden_dim, return_sequences, return_state, embedding):\n",
    "    if embedding:\n",
    "        inputs = Input(shape=(10, ))\n",
    "        _inputs = Embedding(input_dim=100, output_dim=1, input_length=10)(inputs)\n",
    "    else:\n",
    "        inputs = Input(shape=(10, 1))\n",
    "        _inputs = inputs\n",
    "    outputs, state_h, state_c = LSTM(units=hidden_dim, return_sequences=return_sequences, return_state=return_state)(_inputs)\n",
    "    outputs = [outputs, state_h, state_c]\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='mse', optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: GRU / Embedding = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### GRU Model Test with embedding=False ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[[4], [21], [64], [13], [77], [66], [54], [30], [81], [87]]]\n",
      "\n",
      "GRU Output:\n",
      "[[[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]]\n",
      "\n",
      "GRU Last Output by return_state:\n",
      "[[0.]]\n",
      "\n",
      "Sequence Output Shape: (1, 10, 1)\n",
      "Last Output Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: GRU / Embedding = False\n",
    "\"\"\"\n",
    "embedding = False\n",
    "predicted = test_model(name='GRU', \n",
    "                       model=get_gru_model2(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('GRU Output:')\n",
    "print(predicted[0])\n",
    "print('')\n",
    "print('GRU Last Output by return_state:')\n",
    "print(predicted[1])\n",
    "\n",
    "print('')\n",
    "print('Sequence Output Shape:', predicted[0].shape)\n",
    "print('Last Output Shape:', predicted[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: GRU / Embedding = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### GRU Model Test with embedding=True ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[ 4 21 64 13 77 66 54 30 81 87]]\n",
      "\n",
      "GRU Output:\n",
      "[[[ 3.6939475e-04]\n",
      "  [-3.5797853e-03]\n",
      "  [ 3.2458536e-03]\n",
      "  [-2.9120129e-06]\n",
      "  [ 5.0567961e-03]\n",
      "  [ 4.5182616e-03]\n",
      "  [-6.6371402e-03]\n",
      "  [ 6.4807045e-03]\n",
      "  [ 9.0500861e-03]\n",
      "  [ 1.2209806e-02]]]\n",
      "\n",
      "GRU Last Output by return_state:\n",
      "[[0.01220981]]\n",
      "\n",
      "Sequence Output Shape: (1, 10, 1)\n",
      "Last Output Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: GRU / Embedding = True\n",
    "\"\"\"\n",
    "embedding = True\n",
    "predicted = test_model(name='GRU', \n",
    "                       model=get_gru_model2(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('GRU Output:')\n",
    "print(predicted[0])\n",
    "print('')\n",
    "print('GRU Last Output by return_state:')\n",
    "print(predicted[1])\n",
    "\n",
    "print('')\n",
    "print('Sequence Output Shape:', predicted[0].shape)\n",
    "print('Last Output Shape:', predicted[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: LSTM / Embedding = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### LSTM Model Test with embedding=False ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[[4], [21], [64], [13], [77], [66], [54], [30], [81], [87]]]\n",
      "\n",
      "LSTM Output:\n",
      "[[[0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]\n",
      "  [0.]]]\n",
      "\n",
      "LSTM Last Output by return_state:\n",
      "[[0.]]\n",
      "\n",
      "LSTM Last hidden_state by return_state:\n",
      "[[0.]]\n",
      "\n",
      "Sequence Output Shape: (1, 10, 1)\n",
      "Last Output Shape: (1, 1)\n",
      "Last Hidden State Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: LSTM / Embedding = False\n",
    "\"\"\"\n",
    "embedding = False\n",
    "predicted = test_model(name='LSTM', \n",
    "                       model=get_lstm_model2(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('LSTM Output:')\n",
    "print(predicted[0])\n",
    "print('')\n",
    "print('LSTM Last Output by return_state:')\n",
    "print(predicted[1])\n",
    "print('')\n",
    "print('LSTM Last hidden_state by return_state:')\n",
    "print(predicted[2])\n",
    "\n",
    "print('')\n",
    "print('Sequence Output Shape:', predicted[0].shape)\n",
    "print('Last Output Shape:', predicted[1].shape)\n",
    "print('Last Hidden State Shape:', predicted[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case: LSTM / Embedding = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### LSTM Model Test with embedding=True ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[ 4 21 64 13 77 66 54 30 81 87]]\n",
      "\n",
      "LSTM Output:\n",
      "[[[-0.00191574]\n",
      "  [-0.01311182]\n",
      "  [-0.0142023 ]\n",
      "  [-0.01597268]\n",
      "  [-0.01081148]\n",
      "  [-0.00324047]\n",
      "  [-0.0098202 ]\n",
      "  [-0.00839193]\n",
      "  [ 0.00266636]\n",
      "  [-0.00498142]]]\n",
      "\n",
      "LSTM Last Output by return_state:\n",
      "[[-0.00498142]]\n",
      "\n",
      "LSTM Last hidden_state by return_state:\n",
      "[[-0.00986878]]\n",
      "\n",
      "Sequence Output Shape: (1, 10, 1)\n",
      "Last Output Shape: (1, 1)\n",
      "Last Hidden State Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: LSTM / Embedding = False\n",
    "\"\"\"\n",
    "embedding = True\n",
    "predicted = test_model(name='LSTM', \n",
    "                       model=get_lstm_model2(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('LSTM Output:')\n",
    "print(predicted[0])\n",
    "print('')\n",
    "print('LSTM Last Output by return_state:')\n",
    "print(predicted[1])\n",
    "print('')\n",
    "print('LSTM Last hidden_state by return_state:')\n",
    "print(predicted[2])\n",
    "\n",
    "print('')\n",
    "print('Sequence Output Shape:', predicted[0].shape)\n",
    "print('Last Output Shape:', predicted[1].shape)\n",
    "print('Last Hidden State Shape:', predicted[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코멘트: Embedding의 유무는 output의 형태와 아무런 관련이 없다. GRU와 LSTM은 return_state와 return_sequences를 했을 때 결과의 갯수가 다르다. GRU는 last output만 반환하고 LSTM은 last cell state 또한 반환하기 때문이다. 이것은 두 셀 구조를 들여다 봄으로써 이해하길 권장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4. Return sequences=False, return state=True일 때"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding 레이어의 존재 유무는 지금부터는 default로 True로 놓고 볼 예정이다. 위에서 output shape은 동일함을 몇 번이나 확인했기 때문이다. 또한 Embedding 값이 True일 때 더 풍부한 값의 변화를 볼 수 있다. 이번에는 GRU와 LSTM의 return_sequences=False, return_state=True 상태일 때 나오는 값을 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 1\n",
    "return_sequences = False # Default\n",
    "return_state = True # Changed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### GRU Model Test with embedding=True ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[ 4 21 64 13 77 66 54 30 81 87]]\n",
      "\n",
      "GRU Output:\n",
      "[[0.00016529]]\n",
      "\n",
      "GRU Last Output by return_state:\n",
      "[[0.00016529]]\n",
      "\n",
      "Sequence Output Shape: (1, 1)\n",
      "Last Output Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: GRU / Embedding = False\n",
    "\"\"\"\n",
    "embedding = True\n",
    "predicted = test_model(name='GRU', \n",
    "                       model=get_gru_model2(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('GRU Output:')\n",
    "print(predicted[0])\n",
    "print('')\n",
    "print('GRU Last Output by return_state:')\n",
    "print(predicted[1])\n",
    "\n",
    "print('')\n",
    "print('Sequence Output Shape:', predicted[0].shape)\n",
    "print('Last Output Shape:', predicted[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### LSTM Model Test with embedding=True ####\n",
      "Change to correct format for RNN\n",
      "sentences -> _sentences\n",
      "[[ 4 21 64 13 77 66 54 30 81 87]] -> [[ 4 21 64 13 77 66 54 30 81 87]]\n",
      "\n",
      "LSTM Output:\n",
      "[[0.00025799]]\n",
      "\n",
      "LSTM Last Output by return_state:\n",
      "[[0.00025799]]\n",
      "\n",
      "LSTM Last hidden_state by return_state:\n",
      "[[0.00051868]]\n",
      "\n",
      "Sequence Output Shape: (1, 1)\n",
      "Last Output Shape: (1, 1)\n",
      "Last Hidden State Shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test Case: LSTM / Embedding = False\n",
    "\"\"\"\n",
    "embedding = True\n",
    "predicted = test_model(name='LSTM', \n",
    "                       model=get_lstm_model3(hidden_dim=hidden_dim, return_sequences=return_sequences, \n",
    "                                           return_state=return_state, embedding=embedding),\n",
    "                       sentences=sentences,\n",
    "                       embedding=embedding\n",
    "                      )\n",
    "\n",
    "print('')\n",
    "print('LSTM Output:')\n",
    "print(predicted[0])\n",
    "print('')\n",
    "print('LSTM Last Output by return_state:')\n",
    "print(predicted[1])\n",
    "print('')\n",
    "print('LSTM Last hidden_state by return_state:')\n",
    "print(predicted[2])\n",
    "\n",
    "print('')\n",
    "print('Sequence Output Shape:', predicted[0].shape)\n",
    "print('Last Output Shape:', predicted[1].shape)\n",
    "print('Last Hidden State Shape:', predicted[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainwave_eeg",
   "language": "python",
   "name": "brainwave_eeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

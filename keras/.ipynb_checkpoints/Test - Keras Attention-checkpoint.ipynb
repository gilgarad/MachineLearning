{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이 쥬피터 노트북은 Keras의 기능을 정확히 알고 이해하기 위해 테스트하기 위해 생성되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.backend.tensorflow_backend as K\n",
    "from keras.layers import Dense, Input, Lambda, GRU, Concatenate, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple test for GRU(or LSTM) outputs, hidden states..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n",
      "[[[0 2]\n",
      "  [2 6]\n",
      "  [5 3]]]\n",
      "\n",
      "(1, 5, 2)\n",
      "[[[3 3]\n",
      "  [6 7]\n",
      "  [7 4]\n",
      "  [6 3]\n",
      "  [0 2]]]\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "enc_seq_length = 3\n",
    "dec_seq_length = 5\n",
    "\n",
    "enc_input = np.random.randint(10, size=(1, enc_seq_length, latent_dim))\n",
    "dec_input = np.random.randint(10, size=(1, dec_seq_length, latent_dim))\n",
    "dec_output = np.random.randint(10, size=(1, 1))\n",
    "\n",
    "print(enc_input.shape)\n",
    "print(enc_input)\n",
    "\n",
    "print('')\n",
    "\n",
    "print(dec_input.shape)\n",
    "print(dec_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  [(None, 3, 2), (None, 2)] 30        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "enc_inputs = Input(shape=(enc_seq_length, latent_dim))\n",
    "\n",
    "encoder = GRU(latent_dim, return_state=True, return_sequences=True)\n",
    "encoder_outputs, encoder_states = encoder(enc_inputs)\n",
    "\n",
    "outputs = [encoder_outputs, encoder_states]\n",
    "\n",
    "enc_model = Model(inputs=enc_inputs, outputs=outputs)\n",
    "enc_model.compile(optimizer='rmsprop', loss='mse')\n",
    "print(enc_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[-0.46849972, -0.16795884],\n",
       "         [-0.964507  , -0.16795884],\n",
       "         [-0.9670544 , -0.52285415]]], dtype=float32),\n",
       " array([[-0.9670544 , -0.52285415]], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_model.predict(enc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                [(None, 3, 2), (None, 2), 40        \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "enc_inputs = Input(shape=(enc_seq_length, latent_dim))\n",
    "\n",
    "encoder = LSTM(latent_dim, return_state=True, return_sequences=True)\n",
    "encoder_outputs, encoder_state_h, encoder_state_c = encoder(enc_inputs)\n",
    "# encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "outputs = [encoder_outputs, encoder_state_h, encoder_state_c]\n",
    "\n",
    "enc_model = Model(inputs=enc_inputs, outputs=outputs)\n",
    "enc_model.compile(optimizer='rmsprop', loss='mse')\n",
    "print(enc_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 0.0854265 ,  0.05885421],\n",
       "         [ 0.17130549,  0.        ],\n",
       "         [-0.21622829,  0.23644088]]], dtype=float32),\n",
       " array([[-0.21622829,  0.23644088]], dtype=float32),\n",
       " array([[-0.219696  ,  0.54099584]], dtype=float32)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_model.predict(enc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 3, 2)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, 3, 2), (None 40          input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 5, 2)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, 5, 2), (None 40          input_11[0][0]                   \n",
      "                                                                 lstm_10[0][1]                    \n",
      "                                                                 lstm_10[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  [(None, 5, 2), (None 40          input_11[0][0]                   \n",
      "                                                                 lstm_10[0][1]                    \n",
      "                                                                 lstm_10[0][2]                    \n",
      "==================================================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "enc_inputs = Input(shape=(enc_seq_length, latent_dim))\n",
    "dec_inputs = Input(shape=(dec_seq_length, latent_dim))\n",
    "\n",
    "encoder = LSTM(latent_dim, return_state=True, return_sequences=True)\n",
    "encoder_outputs, encoder_state_h, encoder_state_c = encoder(enc_inputs)\n",
    "# encoder_states = [encoder_state_h, encoder_state_c]\n",
    "\n",
    "decoder1 = LSTM(latent_dim, return_state=True, return_sequences=True)\n",
    "decoder_outputs, decoder_state_h, decoder_state_c = decoder1(dec_inputs, initial_state=[encoder_state_h, encoder_state_c])\n",
    "\n",
    "decoder2 = LSTM(latent_dim, return_state=True, return_sequences=True)\n",
    "decoder_outputs2, decoder_state_h2, decoder_state_c2 = decoder2(dec_inputs, initial_state=[encoder_state_h, encoder_state_c])\n",
    "\n",
    "outputs = [encoder_outputs, encoder_state_h, encoder_state_c, decoder_outputs, decoder_state_h, decoder_state_c,\n",
    "          decoder_outputs2, decoder_state_h2, decoder_state_c2]\n",
    "\n",
    "enc_model = Model(inputs=[enc_inputs, dec_inputs], outputs=outputs)\n",
    "enc_model.compile(optimizer='rmsprop', loss='mse')\n",
    "print(enc_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 0.12602474, -0.11073221],\n",
       "         [ 0.        , -0.02346477],\n",
       "         [-0.04158545,  0.08337524]]], dtype=float32),\n",
       " array([[-0.04158545,  0.08337524]], dtype=float32),\n",
       " array([[-0.10542868,  0.33409706]], dtype=float32),\n",
       " array([[[-0.23210803,  0.17166544],\n",
       "         [-0.2602268 ,  0.16050757],\n",
       "         [-0.11689018,  0.05366934],\n",
       "         [-0.11317842,  0.01821852],\n",
       "         [-0.16554847,  0.03445369]]], dtype=float32),\n",
       " array([[-0.16554847,  0.03445369]], dtype=float32),\n",
       " array([[-0.5616043 ,  0.05377926]], dtype=float32),\n",
       " array([[[-0.        ,  0.2971657 ],\n",
       "         [ 0.        ,  0.29141217],\n",
       "         [ 0.        ,  0.4596558 ],\n",
       "         [ 0.        ,  0.4899067 ],\n",
       "         [ 0.03371994,  0.32732704]]], dtype=float32),\n",
       " array([[0.03371994, 0.32732704]], dtype=float32),\n",
       " array([[0.19804108, 1.0452218 ]], dtype=float32)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_model.predict([enc_input, dec_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아하, return_state는 encoder_outputs의 마지막 시퀀스 데이터를 가지고 오는구나? 그런데 만약 패딩한 데이터라면, 저걸 그대로 써도 되는 걸까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 4]\n",
      "  [0 0]\n",
      "  [0 0]]]\n"
     ]
    }
   ],
   "source": [
    "new_enc_input = np.copy(enc_input)\n",
    "new_enc_input[:, enc_seq_length - 2] = [0, 0]\n",
    "new_enc_input[:, enc_seq_length - 1] = [0, 0]\n",
    "print(new_enc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 0.992243  , -0.6890673 ],\n",
       "         [ 0.64822954, -0.49443895],\n",
       "         [ 0.42478132, -0.3401747 ]]], dtype=float32),\n",
       " array([[ 0.42478132, -0.3401747 ]], dtype=float32)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_model.predict(new_enc_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 위의 케이스에서 알 수 있듯이, return_state를 그대로 활용하면, 원래 예상하던 encoder의 output과는 다른 값을 활용하게 된다. 두 번째 케이스에서는 output의 1번째 데이터를 활용해야 한다. 따라서 아래와 같은 과정이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample: 진짜 sequence 길이에 따라 마지막 output index를 찾는 로직 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_119 (InputLayer)       (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "gru_111 (GRU)                [(None, 3, 2), (None, 2)] 30        \n",
      "_________________________________________________________________\n",
      "lambda_389 (Lambda)          (None, 1, 2)              0         \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Example from: http://lancerous.com/detail/46526869/46527020\n",
    "\n",
    "enc_inputs = Input(shape=(enc_seq_length, latent_dim))\n",
    "\n",
    "enc_pad_index = get_pad_index()(enc_inputs)\n",
    "seq_index = Lambda(lambda x: K.sum(x, axis=-2) - 1)(enc_pad_index)\n",
    "\n",
    "\n",
    "encoder = GRU(latent_dim, return_state=True, return_sequences=True)\n",
    "encoder_outputs, encoder_states = encoder(enc_inputs)\n",
    "\n",
    "# encoder_outputs = Multiply()([enc_pad_index, encoder_outputs])\n",
    "# encoder_outputs2 = Multiply()([encoder_outputs, seq_index])\n",
    "# encoder_outputs = encoder_outputs[seq_index]\n",
    "# seq_index2 = Lambda(lambda x: K.cast(x, 'int32'))(seq_index)\n",
    "# values = Lambda(lambda x: K.tf.gather_nd(x, seq_index2 - 1))(encoder_outputs)\n",
    "# values = Lambda(lambda x: x[seq_index2 - 1, :])(encoder_outputs)\n",
    "\n",
    "print(seq_index2.shape)\n",
    "# LAST RELEVANT OUTPUT\n",
    "# create the row index with tf.range\n",
    "row_idx = Lambda(lambda x: tf.reshape(tf.range(tf.shape(x)[0]), (-1,1)))(seq_index)\n",
    "\n",
    "# stack with column index\n",
    "idx = Lambda(lambda x: tf.stack([row_idx, K.cast(x, 'int32')], axis=-1))(seq_index)\n",
    "# extract the elements with gather_nd\n",
    "values = Lambda(lambda x: tf.gather_nd(x, idx))(encoder_outputs)\n",
    "\n",
    "outputs = [encoder_outputs, encoder_states, values]\n",
    "# outputs = [encoder_outputs, encoder_states, row_idx]\n",
    "\n",
    "enc_model = Model(inputs=enc_inputs, outputs=outputs)\n",
    "enc_model.compile(optimizer='rmsprop', loss='mse')\n",
    "print(enc_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 4]\n",
      "  [0 0]\n",
      "  [0 0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[[-0.15122743, -0.57640064],\n",
       "         [-0.0673607 , -0.26010168],\n",
       "         [-0.03089126, -0.10822966]]], dtype=float32),\n",
       " array([[-0.03089126, -0.10822966]], dtype=float32),\n",
       " array([[[-0.15122743, -0.57640064]]], dtype=float32)]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new_enc_input)\n",
    "enc_model.predict(new_enc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[5 2]\n",
      "  [5 9]\n",
      "  [0 0]]\n",
      "\n",
      " [[3 1]\n",
      "  [5 1]\n",
      "  [0 0]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[[-0.08232233,  0.        ],\n",
       "         [-0.08232233, -0.2970863 ],\n",
       "         [-0.03749942, -0.1245542 ]],\n",
       " \n",
       "        [[-0.05926357,  0.12103889],\n",
       "         [-0.03514289,  0.12103889],\n",
       "         [-0.01499547,  0.05193049]]], dtype=float32),\n",
       " array([[-0.03749942, -0.1245542 ],\n",
       "        [-0.01499547,  0.05193049]], dtype=float32),\n",
       " array([[[-0.08232233, -0.2970863 ]],\n",
       " \n",
       "        [[-0.03514289,  0.12103889]]], dtype=float32)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_input = np.random.randint(10, size=(2, enc_seq_length, latent_dim))\n",
    "enc_input[:, 2] = [0, 0]\n",
    "print(enc_input)\n",
    "\n",
    "enc_model.predict(enc_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention layer에 적용하여 테스트한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Multiply, Reshape, Flatten, Embedding\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n",
      "[[[2 4]\n",
      "  [3 6]\n",
      "  [0 8]]]\n",
      "\n",
      "(1, 5, 2)\n",
      "[[[4 4]\n",
      "  [7 7]\n",
      "  [9 5]\n",
      "  [4 7]\n",
      "  [2 2]]]\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "enc_seq_length = 3\n",
    "dec_seq_length = 5\n",
    "\n",
    "enc_input = np.random.randint(10, size=(1, enc_seq_length, latent_dim))\n",
    "dec_input = np.random.randint(10, size=(1, dec_seq_length, latent_dim))\n",
    "dec_output = np.random.randint(10, size=(1, 1))\n",
    "\n",
    "print(enc_input.shape)\n",
    "print(enc_input)\n",
    "\n",
    "print('')\n",
    "\n",
    "print(dec_input.shape)\n",
    "print(dec_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_vector(seq_length, axis):\n",
    "    return Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), seq_length, axis))\n",
    "\n",
    "# Sum of last dimension is 0, then that means it is padded !\n",
    "def get_pad_index():\n",
    "    return Lambda(lambda x: K.cast(K.not_equal(K.sum(x, axis=-1, keepdims=True), 0), 'float32'))\n",
    "\n",
    "def get_last_outputs(inputs, outputs, dimension, seq_length):\n",
    "    if dimension == 2:\n",
    "        new_inputs = Reshape((seq_length, 1))(inputs)\n",
    "    else:\n",
    "        new_inputs = inputs\n",
    "    pad_index = get_pad_index()(new_inputs)\n",
    "    last_index = Lambda(lambda x: K.sum(x, axis=-2) - 1)(pad_index)\n",
    "\n",
    "    # LAST RELEVANT OUTPUT\n",
    "    # create the row index with tf.range\n",
    "    row_idx = Lambda(lambda x: tf.reshape(tf.range(tf.shape(x)[0]), (-1,1)))(last_index)\n",
    "\n",
    "    # stack with column index\n",
    "    idx = Lambda(lambda x: tf.stack([row_idx, K.cast(x, 'int32')], axis=-1))(last_index)\n",
    "    # extract the elements with gather_nd\n",
    "    last_outputs = Lambda(lambda x: tf.gather_nd(x, idx))(outputs)\n",
    "    \n",
    "    last_outputs = Reshape((latent_dim, ))(last_outputs)\n",
    "    return pad_index, last_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 패딩된 위치의 output 찾기 with 3d input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_74 (InputLayer)           (None, 3, 2)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_37 (GRU)                    [(None, 3, 2), (None 30          input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 1, 2)         0           gru_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 3, 1)         0           input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_13 (Reshape)            (None, 2)            0           lambda_79[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enc_inputs = Input(shape=(enc_seq_length, latent_dim))\n",
    "dec_inputs = Input(shape=(dec_seq_length, latent_dim))\n",
    "\n",
    "encoder = GRU(latent_dim, return_state=True, return_sequences=True)\n",
    "encoder_outputs, encoder_states = encoder(enc_inputs)\n",
    "\n",
    "pad_index, last_outputs = get_last_outputs(enc_inputs, encoder_outputs, dimension=3, seq_length=enc_seq_length)\n",
    "\n",
    "# decoder = GRU(latent_dim, return_state=True, return_sequences=True)\n",
    "# decoder_outputs, decoder_states = decoder(dec_inputs, initial_state=last_outputs)\n",
    "\n",
    "\n",
    "# Attention Layer\n",
    "# repeat_d = repeat_vector(enc_seq_length, 2)(decoder_outputs)\n",
    "# repeat_e = repeat_vector(dec_seq_length, 1)(encoder_outputs)\n",
    "\n",
    "\n",
    "# concat_v = Concatenate()([repeat_d, repeat_e])\n",
    "# dense_score_layer = Dense(latent_dim, activation='tanh')\n",
    "# dense_score = dense_score_layer(concat_v)\n",
    "# dense2_score = Dense(1)(dense_score)\n",
    "# dense2_score = Reshape((dec_seq_length, enc_seq_length))(dense2_score)\n",
    "\n",
    "# softmax_score = Activation('softmax')(dense2_score)\n",
    "\n",
    "# Make Context Vector\n",
    "\n",
    "# outputs = [repeat_d, repeat_e]\n",
    "# outputs = [repeat_e]\n",
    "outputs = [pad_index, last_outputs, encoder_outputs]\n",
    "\n",
    "model = Model(inputs=[enc_inputs, dec_inputs], outputs=outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "print(model.summary())\n",
    "# output_array = model.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[1.],\n",
       "         [1.],\n",
       "         [0.]]], dtype=float32),\n",
       " array([[ 0.9745162, -0.7309223]], dtype=float32),\n",
       " array([[[ 0.85658723, -0.4007408 ],\n",
       "         [ 0.9745162 , -0.7309223 ],\n",
       "         [ 0.45146894, -0.35265613]]], dtype=float32)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_enc_input = np.copy(enc_input)\n",
    "new_enc_input[:, 2] = [0, 0]\n",
    "model.predict([new_enc_input, dec_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 패딩된 위치의 output 찾기 with 2d input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_76 (InputLayer)           (None, 3)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, 3, 2)         20          input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "gru_38 (GRU)                    [(None, 3, 2), (None 30          embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 3, 1)         0           input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 1, 2)         0           gru_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 3, 1)         0           reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 2)            0           lambda_84[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 50\n",
      "Trainable params: 50\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enc_inputs = Input(shape=(enc_seq_length, ))\n",
    "dec_inputs = Input(shape=(dec_seq_length, latent_dim))\n",
    "\n",
    "enc_inputs_embed = Embedding(10, latent_dim)(enc_inputs)\n",
    "\n",
    "encoder = GRU(latent_dim, return_state=True, return_sequences=True)\n",
    "encoder_outputs, encoder_states = encoder(enc_inputs_embed)\n",
    "\n",
    "pad_index, last_outputs = get_last_outputs(enc_inputs, encoder_outputs, dimension=2, seq_length=enc_seq_length)\n",
    "\n",
    "# decoder = GRU(latent_dim, return_state=True, return_sequences=True)\n",
    "# decoder_outputs, decoder_states = decoder(dec_inputs, initial_state=last_outputs)\n",
    "\n",
    "\n",
    "# Attention Layer\n",
    "# repeat_d = repeat_vector(enc_seq_length, 2)(decoder_outputs)\n",
    "# repeat_e = repeat_vector(dec_seq_length, 1)(encoder_outputs)\n",
    "\n",
    "\n",
    "# concat_v = Concatenate()([repeat_d, repeat_e])\n",
    "# dense_score_layer = Dense(latent_dim, activation='tanh')\n",
    "# dense_score = dense_score_layer(concat_v)\n",
    "# dense2_score = Dense(1)(dense_score)\n",
    "# dense2_score = Reshape((dec_seq_length, enc_seq_length))(dense2_score)\n",
    "\n",
    "# softmax_score = Activation('softmax')(dense2_score)\n",
    "\n",
    "# Make Context Vector\n",
    "\n",
    "# outputs = [repeat_d, repeat_e]\n",
    "# outputs = [repeat_e]\n",
    "outputs = [pad_index, last_outputs, encoder_outputs]\n",
    "# outputs = encoder_outputs\n",
    "\n",
    "model = Model(inputs=[enc_inputs, dec_inputs], outputs=outputs)\n",
    "# model = Model(inputs=enc_inputs, outputs=outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "print(model.summary())\n",
    "# output_array = model.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 0 0]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[[1.],\n",
       "         [0.],\n",
       "         [0.]]], dtype=float32),\n",
       " array([[ 0.00588792, -0.00853912]], dtype=float32),\n",
       " array([[[ 0.00588792, -0.00853912],\n",
       "         [ 0.00971485, -0.01169102],\n",
       "         [ 0.01161896, -0.0128266 ]]], dtype=float32)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_enc_input = np.random.randint(10, size=(1, enc_seq_length))\n",
    "new_enc_input[:, 1:] = 0\n",
    "print(new_enc_input)\n",
    "print('')\n",
    "model.predict([new_enc_input, dec_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  [(None, 3, 2), (None, 2)] 30        \n",
      "_________________________________________________________________\n",
      "lambda_16 (Lambda)           (None, 5, 3, 2)           0         \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "enc_inputs = Input(shape=(enc_seq_length, latent_dim))\n",
    "dec_inputs = Input(shape=(dec_seq_length, latent_dim))\n",
    "\n",
    "encoder = GRU(latent_dim, return_state=True, return_sequences=True)\n",
    "encoder_outputs, encoder_states = encoder(enc_inputs)\n",
    "\n",
    "pad_index, last_outputs = get_last_outputs(enc_inputs, encoder_outputs)\n",
    "\n",
    "# decoder = GRU(latent_dim, return_state=True, return_sequences=True)\n",
    "# decoder_outputs, decoder_states = decoder(dec_inputs, initial_state=last_outputs)\n",
    "\n",
    "\n",
    "# Attention Layer\n",
    "# repeat_d = repeat_vector(enc_seq_length, 2)(decoder_outputs)\n",
    "repeat_e = repeat_vector(dec_seq_length, 1)(encoder_outputs)\n",
    "\n",
    "\n",
    "# concat_v = Concatenate()([repeat_d, repeat_e])\n",
    "# dense_score_layer = Dense(latent_dim, activation='tanh')\n",
    "# dense_score = dense_score_layer(concat_v)\n",
    "# dense2_score = Dense(1)(dense_score)\n",
    "# dense2_score = Reshape((dec_seq_length, enc_seq_length))(dense2_score)\n",
    "\n",
    "# softmax_score = Activation('softmax')(dense2_score)\n",
    "\n",
    "# Make Context Vector\n",
    "\n",
    "# outputs = [repeat_d, repeat_e]\n",
    "outputs = [repeat_e]\n",
    "\n",
    "model = Model(inputs=[enc_inputs, dec_inputs], outputs=outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "print(model.summary())\n",
    "# output_array = model.predict(input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.33879137, -0.42596382],\n",
       "          [ 0.33879137, -0.42596382],\n",
       "          [ 0.33879137, -0.42596382]],\n",
       " \n",
       "         [[ 0.1054918 , -0.8267227 ],\n",
       "          [ 0.1054918 , -0.8267227 ],\n",
       "          [ 0.1054918 , -0.8267227 ]],\n",
       " \n",
       "         [[-0.6399848 , -0.9956191 ],\n",
       "          [-0.6399848 , -0.9956191 ],\n",
       "          [-0.6399848 , -0.9956191 ]],\n",
       " \n",
       "         [[-0.6399848 , -0.13997185],\n",
       "          [-0.6399848 , -0.13997185],\n",
       "          [-0.6399848 , -0.13997185]],\n",
       " \n",
       "         [[-0.54603815, -0.24638326],\n",
       "          [-0.54603815, -0.24638326],\n",
       "          [-0.54603815, -0.24638326]]]], dtype=float32),\n",
       " array([[[[ 0.1296094 , -0.27320027],\n",
       "          [ 0.32684386, -0.4980604 ],\n",
       "          [ 0.7306807 ,  0.39620203]],\n",
       " \n",
       "         [[ 0.1296094 , -0.27320027],\n",
       "          [ 0.32684386, -0.4980604 ],\n",
       "          [ 0.7306807 ,  0.39620203]],\n",
       " \n",
       "         [[ 0.1296094 , -0.27320027],\n",
       "          [ 0.32684386, -0.4980604 ],\n",
       "          [ 0.7306807 ,  0.39620203]],\n",
       " \n",
       "         [[ 0.1296094 , -0.27320027],\n",
       "          [ 0.32684386, -0.4980604 ],\n",
       "          [ 0.7306807 ,  0.39620203]],\n",
       " \n",
       "         [[ 0.1296094 , -0.27320027],\n",
       "          [ 0.32684386, -0.4980604 ],\n",
       "          [ 0.7306807 ,  0.39620203]]]], dtype=float32)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([enc_input, dec_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 3, 2)              0         \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 [(None, 3, 2), (None, 2)] 30        \n",
      "=================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "seq_length = 3\n",
    "inputs = Input(shape=(seq_length, latent_dim))\n",
    "outputs, last_output = GRU(latent_dim, return_state=True, return_sequences=True)(inputs)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can not convert a list into a Tensor or Operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-7d7a6c508674>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlayer_outputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m get_3rd_layer_output = K.function([model.layers[0].input],\n\u001b[1;32m----> 7\u001b[1;33m                                   layer_outputs)\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_3rd_layer_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menc_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\igs_projects\\nlp_nlu\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m   2742\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Invalid argument \"%s\" passed to K.function with TensorFlow backend'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2743\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2744\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\igs_projects\\nlp_nlu\\venv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, updates, name, **session_kwargs)\u001b[0m\n\u001b[0;32m   2544\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2545\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2546\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2547\u001b[0m             \u001b[0mupdates_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2548\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mupdate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\igs_projects\\nlp_nlu\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[1;34m(control_inputs)\u001b[0m\n\u001b[0;32m   5002\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_NullContextmanager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5003\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5004\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\igs_projects\\nlp_nlu\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcontrol_dependencies\u001b[1;34m(self, control_inputs)\u001b[0m\n\u001b[0;32m   4541\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndexedSlices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4542\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4543\u001b[1;33m       \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4544\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4545\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\igs_projects\\nlp_nlu\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3489\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3490\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3492\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\igs_projects\\nlp_nlu\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3577\u001b[0m       \u001b[1;31m# We give up!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3578\u001b[0m       raise TypeError(\"Can not convert a %s into a %s.\" % (type(obj).__name__,\n\u001b[1;32m-> 3579\u001b[1;33m                                                            types_str))\n\u001b[0m\u001b[0;32m   3580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3581\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_operations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Can not convert a list into a Tensor or Operation."
     ]
    }
   ],
   "source": [
    "layer_outputs = list()\n",
    "for idx, l in enumerate(model.layers):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    layer_outputs.append(l.output)\n",
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  layer_outputs)\n",
    "layer_output = get_3rd_layer_output([enc_input])\n",
    "print('')\n",
    "for l_output in layer_output:\n",
    "    print(l_output[0][0])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'layer_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-233-140683eb891a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0ml_output\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'layer_output' is not defined"
     ]
    }
   ],
   "source": [
    "print()\n",
    "for l_output in layer_output:\n",
    "    print(l_output[0][0])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_output[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_nlu",
   "language": "python",
   "name": "nlp_nlu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
